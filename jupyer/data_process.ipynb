{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 原始WOMD文件预处理\n",
    "\n",
    "waymo地图信息定义可以参考[proto文件](https://github.com/waymo-research/waymo-open-dataset/blob/master/src/waymo_open_dataset/protos/map.proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 从proto中提取原始数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save_infos**\n",
    "+ `scenario_id`: *str*, 场景编号\n",
    "+ `timestamps_seconds`: *list[91]*, 时间戳列表\n",
    "+ `current_time_index`: *int*, 当前时间戳\n",
    "+ `sdc_track_index`: *int*, 主车编号\n",
    "+ `objects_of_interest`: *list*, 感兴趣车辆列表（可能为空）\n",
    "+ `tracks_to_predict`: *dict*, 需要被预测的轨迹\n",
    "    - `track_index`: *list*, 代理轨迹编号\n",
    "    - `difficulty`: *list*, 预测难度 **（不确定划分依据）** \n",
    "    - `object_type`: *list*, 代理类型\n",
    "+ `track_infos`: *dict*, 代理轨迹信息\n",
    "    - `object_id`: *list*, 所有代理id\n",
    "    - `object_type`: *list[str]*, 代理类型\n",
    "        > 'TYPE_UNSET', 'TYPE_VEHICLE', 'TYPE_PEDESTRIAN', 'TYPE_CYCLIST', 'TYPE_OTHER'\n",
    "    - `trajs`: *array[NA, NT, 10]*, 代理状态信息\n",
    "        > center_x, center_y, center_z, length, width, height, heading, velocity_x, velocity_y, valid\n",
    "+ `map_infos`: *dict*, 静态地图信息\n",
    "    + `lane`: *list(dict)*, 车道线信息\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `speed_limit_mph`: *float*, 速度限制（单位mph）\n",
    "        - `type`: *int*, 地图元素类型\n",
    "            > 'TYPE_FREEWAY': 1, 'TYPE_SURFACE_STREET': 2, 'TYPE_BIKE_LANE': 3,\n",
    "        - `left_neighbors`: *list(int)*, 车道左侧车道\n",
    "        - `right_neighbors`: *list(int)*, 车道右侧车道\n",
    "        - `interpolating`: *bool*, 是否差值\n",
    "        - `entry_lanes`: *list(int)*, 上游车道\n",
    "        - `exit_lanes`: *list(int)*, 下游车道线\n",
    "        - `left_boundary_type`: *list(int)*, 左侧边界线类型\n",
    "        - `right_boundary_type`: *list(int)*, 右侧边界线类型\n",
    "        - `left_boundary`: *list(int)*, 左侧边界线id\n",
    "        - `right_boundary`: *list(int)*, 右侧边界线id\n",
    "        - `left_boundary_start_index`: *list(int)*\n",
    "        - `left_boundary_end_index`: *list(int)*\n",
    "        - `right_boundary_start_index`: *list(int)*\n",
    "        - `right_boundary_end_index`: *list(int)*\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `lane_dict`: *dict*, 根据地图元素id获取车道信息\n",
    "    + `road_line`: *list(dict)*, 车道分隔线信息\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `type`: *int*, 地图元素类型\n",
    "            > 'TYPE_BROKEN_SINGLE_WHITE': 6, 'TYPE_SOLID_SINGLE_WHITE': 7, 'TYPE_SOLID_DOUBLE_WHITE': 8, 'TYPE_BROKEN_SINGLE_YELLOW': 9, 'TYPE_BROKEN_DOUBLE_YELLOW': 10, 'TYPE_SOLID_SINGLE_YELLOW': 11, 'TYPE_SOLID_DOUBLE_YELLOW': 12, 'TYPE_PASSING_DOUBLE_YELLOW': 13\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `road_edge`: *list(dict)*, 车道边界线信息 \n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `type`: *int*, 地图元素类型\n",
    "            > 'TYPE_ROAD_EDGE_BOUNDARY': 15, 'TYPE_ROAD_EDGE_MEDIAN': 16\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `stop_sign`: *list(dict)*, 停车线信息\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `lane_ids`: *list*, 停车线控制的lane_id\n",
    "        - `position`: *array[3,]*, 停车线坐标\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `crosswalk`: *list(dict)*, 人行横道线\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `speed_bump`: *list(dict)*, 减速带信息 \n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `all_polylines`: *array(n, 5)*, 所有多段线上点的信息（x, y, z, 所属道路元素类型, 所属道路元素id）\n",
    "    + `lane2other_dict`: *dict*, 获取车道与其他地图元素（左右边界线、停车线）的关联列表\n",
    "+ `dynamic_map_infos`: *dict*, 动态地图信息\n",
    "    - `lane_id`: *list(91)*, 每一帧所有信号灯控制的lane_id\n",
    "    - `state`: *list(91)*, 每一帧所有信号灯的状态\n",
    "        > 'LANE_STATE_UNKNOWN', 'LANE_STATE_ARROW_STOP', 'LANE_STATE_ARROW_CAUTION', 'LANE_STATE_ARROW_GO', 'LANE_STATE_STOP', 'LANE_STATE_CAUTION', 'LANE_STATE_GO', 'LANE_STATE_FLASHING_STOP', 'LANE_STATE_FLASHING_CAUTION'\n",
    "    - `stop_point`: *list(91)*, 每一帧所有信号灯的控制的停车点信息（x, y, z）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# womd原始文件路径\n",
    "WOMD_DIR = \"/mnt/i/womd_scenario_v_1_2_0/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:23:45.260398: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-17 21:23:45.327437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-17 21:23:45.850523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-17 21:23:46.634294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:46.681533: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:46.684532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:46.691991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:46.694029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:46.695813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:47.544068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:47.544305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:47.544320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-17 21:23:47.544538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-17 21:23:47.544610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20164 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-11-17 21:24:29.726896: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene: 4b60f9400a30ceaf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from waymo_open_dataset.protos import scenario_pb2\n",
    "\n",
    "for tfrecord in os.listdir(WOMD_DIR):\n",
    "    file_path = os.path.join(WOMD_DIR, tfrecord)\n",
    "    dataset = tf.data.TFRecordDataset(file_path, compression_type='', num_parallel_reads=3)\n",
    "    for cnt, data in enumerate(dataset):\n",
    "        scenario = scenario_pb2.Scenario()\n",
    "        scenario.ParseFromString(bytearray(data.numpy()))\n",
    "        print(f\"scene: {scenario.scenario_id}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def decode_tracks_from_proto(tracks):\n",
    "    object_type = {\n",
    "        0: 'TYPE_UNSET',\n",
    "        1: 'TYPE_VEHICLE',\n",
    "        2: 'TYPE_PEDESTRIAN',\n",
    "        3: 'TYPE_CYCLIST',\n",
    "        4: 'TYPE_OTHER'\n",
    "    }\n",
    "\n",
    "    track_infos = {\n",
    "        'object_id': [],  # {0: unset, 1: vehicle, 2: pedestrian, 3: cyclist, 4: others}\n",
    "        'object_type': [],\n",
    "        'trajs': []\n",
    "    }\n",
    "\n",
    "    for cur_data in tracks:  # number of objects\n",
    "        cur_traj = [np.array([x.center_x, x.center_y, x.center_z, x.length, x.width, x.height, x.heading,\n",
    "                              x.velocity_x, x.velocity_y, x.valid], dtype=np.float32) for x in cur_data.states]\n",
    "        cur_traj = np.stack(cur_traj, axis=0)  # (num_timestamp, 10)\n",
    "\n",
    "        track_infos['object_id'].append(cur_data.id)\n",
    "        track_infos['object_type'].append(object_type[cur_data.object_type])\n",
    "        track_infos['trajs'].append(cur_traj)\n",
    "\n",
    "    track_infos['trajs'] = np.stack(track_infos['trajs'], axis=0)  # (num_objects, num_timestamp, 9)\n",
    "    return track_infos\n",
    "\n",
    "def decode_map_features_from_proto(map_features):\n",
    "    polyline_type = {\n",
    "        # for lane\n",
    "        'TYPE_UNDEFINED': -1,\n",
    "        'TYPE_FREEWAY': 1,\n",
    "        'TYPE_SURFACE_STREET': 2,\n",
    "        'TYPE_BIKE_LANE': 3,\n",
    "\n",
    "        # for roadline\n",
    "        'TYPE_UNKNOWN': -1,\n",
    "        'TYPE_BROKEN_SINGLE_WHITE': 6,\n",
    "        'TYPE_SOLID_SINGLE_WHITE': 7,\n",
    "        'TYPE_SOLID_DOUBLE_WHITE': 8,\n",
    "        'TYPE_BROKEN_SINGLE_YELLOW': 9,\n",
    "        'TYPE_BROKEN_DOUBLE_YELLOW': 10,\n",
    "        'TYPE_SOLID_SINGLE_YELLOW': 11,\n",
    "        'TYPE_SOLID_DOUBLE_YELLOW': 12,\n",
    "        'TYPE_PASSING_DOUBLE_YELLOW': 13,\n",
    "\n",
    "        # for roadedge\n",
    "        'TYPE_ROAD_EDGE_BOUNDARY': 15,\n",
    "        'TYPE_ROAD_EDGE_MEDIAN': 16,\n",
    "\n",
    "        # for stopsign\n",
    "        'TYPE_STOP_SIGN': 17,\n",
    "\n",
    "        # for crosswalk\n",
    "        'TYPE_CROSSWALK': 18,\n",
    "\n",
    "        # for speed bump\n",
    "        'TYPE_SPEED_BUMP': 19\n",
    "    }\n",
    "\n",
    "    map_infos = {\n",
    "        'lane': [],\n",
    "        'road_line': [],\n",
    "        'road_edge': [],\n",
    "        'stop_sign': [],\n",
    "        'crosswalk': [],\n",
    "        'speed_bump': [],\n",
    "        'lane_dict': {},\n",
    "        'lane2other_dict': {}\n",
    "    }\n",
    "    polylines = []\n",
    "\n",
    "    point_cnt = 0\n",
    "    lane2other_dict = defaultdict(list)\n",
    "\n",
    "    for cur_data in map_features:\n",
    "        cur_info = {'id': cur_data.id}\n",
    "\n",
    "        if cur_data.lane.ByteSize() > 0:\n",
    "            cur_info['speed_limit_mph'] = cur_data.lane.speed_limit_mph\n",
    "            cur_info['type'] = cur_data.lane.type + 1  # 0: undefined, 1: freeway, 2: surface_street, 3: bike_lane\n",
    "            cur_info['left_neighbors'] = [lane.feature_id for lane in cur_data.lane.left_neighbors]\n",
    "\n",
    "            cur_info['right_neighbors'] = [lane.feature_id for lane in cur_data.lane.right_neighbors]\n",
    "\n",
    "            cur_info['interpolating'] = cur_data.lane.interpolating\n",
    "            cur_info['entry_lanes'] = list(cur_data.lane.entry_lanes)\n",
    "            cur_info['exit_lanes'] = list(cur_data.lane.exit_lanes)\n",
    "\n",
    "            cur_info['left_boundary_type'] = [x.boundary_type + 5 for x in cur_data.lane.left_boundaries]\n",
    "            cur_info['right_boundary_type'] = [x.boundary_type + 5 for x in cur_data.lane.right_boundaries]\n",
    "\n",
    "            cur_info['left_boundary'] = [x.boundary_feature_id for x in cur_data.lane.left_boundaries]\n",
    "            cur_info['right_boundary'] = [x.boundary_feature_id for x in cur_data.lane.right_boundaries]\n",
    "            cur_info['left_boundary_start_index'] = [lane.lane_start_index for lane in cur_data.lane.left_boundaries]\n",
    "            cur_info['left_boundary_end_index'] = [lane.lane_end_index for lane in cur_data.lane.left_boundaries]\n",
    "            cur_info['right_boundary_start_index'] = [lane.lane_start_index for lane in cur_data.lane.right_boundaries]\n",
    "            cur_info['right_boundary_end_index'] = [lane.lane_end_index for lane in cur_data.lane.right_boundaries]\n",
    "\n",
    "            lane2other_dict[cur_data.id].extend(cur_info['left_boundary'])\n",
    "            lane2other_dict[cur_data.id].extend(cur_info['right_boundary'])\n",
    "\n",
    "            global_type = cur_info['type']\n",
    "            cur_polyline = np.stack(\n",
    "                [np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in cur_data.lane.polyline],\n",
    "                axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['lane'].append(cur_info)\n",
    "            map_infos['lane_dict'][cur_data.id] = cur_info\n",
    "\n",
    "        elif cur_data.road_line.ByteSize() > 0:\n",
    "            cur_info['type'] = cur_data.road_line.type + 5\n",
    "\n",
    "            global_type = cur_info['type']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.road_line.polyline], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['road_line'].append(cur_info)\n",
    "\n",
    "        elif cur_data.road_edge.ByteSize() > 0:\n",
    "            cur_info['type'] = cur_data.road_edge.type + 14\n",
    "\n",
    "            global_type = cur_info['type']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.road_edge.polyline], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['road_edge'].append(cur_info)\n",
    "\n",
    "        elif cur_data.stop_sign.ByteSize() > 0:\n",
    "            cur_info['lane_ids'] = list(cur_data.stop_sign.lane)\n",
    "            for i in cur_info['lane_ids']:\n",
    "                lane2other_dict[i].append(cur_data.id)\n",
    "            point = cur_data.stop_sign.position\n",
    "            cur_info['position'] = np.array([point.x, point.y, point.z])\n",
    "\n",
    "            global_type = polyline_type['TYPE_STOP_SIGN']\n",
    "            cur_polyline = np.array([point.x, point.y, point.z, global_type, cur_data.id]).reshape(1, 5)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['stop_sign'].append(cur_info)\n",
    "        elif cur_data.crosswalk.ByteSize() > 0:\n",
    "            global_type = polyline_type['TYPE_CROSSWALK']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.crosswalk.polygon], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['crosswalk'].append(cur_info)\n",
    "\n",
    "        elif cur_data.speed_bump.ByteSize() > 0:\n",
    "            global_type = polyline_type['TYPE_SPEED_BUMP']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.speed_bump.polygon], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['speed_bump'].append(cur_info)\n",
    "\n",
    "        else:\n",
    "            # print(cur_data)\n",
    "            continue\n",
    "        polylines.append(cur_polyline)\n",
    "        cur_info['polyline_index'] = (point_cnt, point_cnt + len(cur_polyline))\n",
    "        point_cnt += len(cur_polyline)\n",
    "\n",
    "    # try:\n",
    "    polylines = np.concatenate(polylines, axis=0).astype(np.float32)\n",
    "    # except:\n",
    "    #     polylines = np.zeros((0, 8), dtype=np.float32)\n",
    "    #     print('Empty polylines: ')\n",
    "    map_infos['all_polylines'] = polylines\n",
    "    map_infos['lane2other_dict'] = lane2other_dict\n",
    "    return map_infos\n",
    "\n",
    "def decode_dynamic_map_states_from_proto(dynamic_map_states):\n",
    "    signal_state = {\n",
    "        0: 'LANE_STATE_UNKNOWN',\n",
    "\n",
    "        # // States for traffic signals with arrows.\n",
    "        1: 'LANE_STATE_ARROW_STOP',\n",
    "        2: 'LANE_STATE_ARROW_CAUTION',\n",
    "        3: 'LANE_STATE_ARROW_GO',\n",
    "\n",
    "        # // Standard round traffic signals.\n",
    "        4: 'LANE_STATE_STOP',\n",
    "        5: 'LANE_STATE_CAUTION',\n",
    "        6: 'LANE_STATE_GO',\n",
    "\n",
    "        # // Flashing light signals.\n",
    "        7: 'LANE_STATE_FLASHING_STOP',\n",
    "        8: 'LANE_STATE_FLASHING_CAUTION'\n",
    "    }\n",
    "\n",
    "    dynamic_map_infos = {\n",
    "        'lane_id': [],\n",
    "        'state': [],\n",
    "        'stop_point': []\n",
    "    }\n",
    "    for cur_data in dynamic_map_states:  # (num_timestamp)\n",
    "        lane_id, state, stop_point = [], [], []\n",
    "        for cur_signal in cur_data.lane_states:  # (num_observed_signals)\n",
    "            lane_id.append(cur_signal.lane)\n",
    "            state.append(signal_state[cur_signal.state])\n",
    "            stop_point.append([cur_signal.stop_point.x, cur_signal.stop_point.y, cur_signal.stop_point.z])\n",
    "\n",
    "        dynamic_map_infos['lane_id'].append(np.array([lane_id]))\n",
    "        dynamic_map_infos['state'].append(np.array([state]))\n",
    "        dynamic_map_infos['stop_point'].append(np.array([stop_point]))\n",
    "\n",
    "    return dynamic_map_infos\n",
    "\n",
    "def process_single_data(scenario):\n",
    "    info = {}\n",
    "    info['scenario_id'] = scenario.scenario_id\n",
    "    info['timestamps_seconds'] = list(scenario.timestamps_seconds)  # list of int of shape (91)\n",
    "    info['current_time_index'] = scenario.current_time_index  # int, 10\n",
    "    info['sdc_track_index'] = scenario.sdc_track_index  # int\n",
    "    info['objects_of_interest'] = list(scenario.objects_of_interest)  # list, could be empty list\n",
    "\n",
    "    info['tracks_to_predict'] = {\n",
    "        'track_index': [cur_pred.track_index for cur_pred in scenario.tracks_to_predict],\n",
    "        'difficulty': [cur_pred.difficulty for cur_pred in scenario.tracks_to_predict]\n",
    "    }  # for training: suggestion of objects to train on, for val/test: need to be predicted\n",
    "\n",
    "    track_infos = decode_tracks_from_proto(scenario.tracks)\n",
    "    info['tracks_to_predict']['object_type'] = [track_infos['object_type'][cur_idx] for cur_idx in\n",
    "                                                info['tracks_to_predict']['track_index']]\n",
    "\n",
    "    # decode map related data\n",
    "    map_infos = decode_map_features_from_proto(scenario.map_features)\n",
    "    dynamic_map_infos = decode_dynamic_map_states_from_proto(scenario.dynamic_map_states)\n",
    "\n",
    "    save_infos = {\n",
    "        'track_infos': track_infos,\n",
    "        'dynamic_map_infos': dynamic_map_infos,\n",
    "        'map_infos': map_infos\n",
    "    }\n",
    "    save_infos.update(info)\n",
    "    return save_infos\n",
    "\n",
    "save_infos = process_single_data(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 获取信控信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf_lights`: *array(n \\* 3)*, 每个信号灯每时刻的状态（lane_id, time_step, state）\n",
    "> LANE_STATE_STOP, LANE_STATE_GO, LANE_STATE_CAUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Any, Dict, List, Optional\n",
    "import easydict\n",
    "import pandas as pd\n",
    "\n",
    "def process_dynamic_map(dynamic_map_infos):\n",
    "    lane_ids = dynamic_map_infos[\"lane_id\"]\n",
    "    tf_lights = []\n",
    "    for t in range(len(lane_ids)):\n",
    "        lane_id = lane_ids[t]\n",
    "        time = np.ones_like(lane_id) * t\n",
    "        state = dynamic_map_infos[\"state\"][t]\n",
    "        tf_light = np.concatenate([lane_id, time, state], axis=0)\n",
    "        tf_lights.append(tf_light)\n",
    "    tf_lights = np.concatenate(tf_lights, axis=1).transpose(1, 0)\n",
    "    tf_lights = pd.DataFrame(data=tf_lights, columns=[\"lane_id\", \"time_step\", \"state\"])\n",
    "    tf_lights[\"time_step\"] = tf_lights[\"time_step\"].astype(\"str\")\n",
    "    tf_lights[\"lane_id\"] = tf_lights[\"lane_id\"].astype(\"str\")\n",
    "    tf_lights[\"state\"] = tf_lights[\"state\"].astype(\"str\")\n",
    "    tf_lights.loc[tf_lights[\"state\"].str.contains(\"STOP\"), [\"state\"] ] = 'LANE_STATE_STOP'\n",
    "    tf_lights.loc[tf_lights[\"state\"].str.contains(\"GO\"), [\"state\"] ] = 'LANE_STATE_GO'\n",
    "    tf_lights.loc[tf_lights[\"state\"].str.contains(\"CAUTION\"), [\"state\"] ] = 'LANE_STATE_CAUTION'\n",
    "    return tf_lights\n",
    "\n",
    "dynamic_map_infos = save_infos[\"dynamic_map_infos\"]\n",
    "tf_lights = process_dynamic_map(dynamic_map_infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 获取地图特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_list_index(ls: List[Any], elem: Any) -> Optional[int]:\n",
    "    try:\n",
    "        return ls.index(elem)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def get_map_features(map_infos, tf_current_light, dim=3):\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    _polygon_types = ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "    _polygon_light_type = ['LANE_STATE_STOP', 'LANE_STATE_GO', 'LANE_STATE_CAUTION', 'LANE_STATE_UNKNOWN']\n",
    "    _polygon_to_polygon_types = ['NONE', 'PRED', 'SUCC', 'LEFT', 'RIGHT']\n",
    "    \n",
    "    Lane_type_hash = {\n",
    "        4: \"BIKE\",\n",
    "        3: \"VEHICLE\",\n",
    "        2: \"VEHICLE\",\n",
    "        1: \"BUS\"\n",
    "    }\n",
    "    boundary_type_hash = {\n",
    "        5: \"UNKNOWN\",\n",
    "        6: \"DASHED_WHITE\",\n",
    "        7: \"SOLID_WHITE\",\n",
    "        8: \"DOUBLE_DASH_WHITE\",\n",
    "        9: \"DASHED_YELLOW\",\n",
    "        10: \"DOUBLE_DASH_YELLOW\",\n",
    "        11: \"SOLID_YELLOW\",\n",
    "        12: \"DOUBLE_SOLID_YELLOW\",\n",
    "        13: \"DASH_SOLID_YELLOW\",\n",
    "        14: \"UNKNOWN\",\n",
    "        15: \"EDGE\",\n",
    "        16: \"EDGE\"\n",
    "    }\n",
    "\n",
    "    lane_segments = map_infos['lane']\n",
    "    all_polylines = map_infos[\"all_polylines\"]\n",
    "    crosswalks = map_infos['crosswalk']\n",
    "    road_edges = map_infos['road_edge']\n",
    "    road_lines = map_infos['road_line']\n",
    "    lane_segment_ids = [info[\"id\"] for info in lane_segments]\n",
    "    cross_walk_ids = [info[\"id\"] for info in crosswalks]\n",
    "    road_edge_ids = [info[\"id\"] for info in road_edges]\n",
    "    road_line_ids = [info[\"id\"] for info in road_lines]\n",
    "    polygon_ids = lane_segment_ids + road_edge_ids + road_line_ids + cross_walk_ids\n",
    "    num_polygons = len(lane_segment_ids) + len(road_edge_ids) + len(road_line_ids) + len(cross_walk_ids)\n",
    "\n",
    "    # 多段线中各点所属多段线类型（对应关系见 _polygon_types）\n",
    "    polygon_type = torch.zeros(num_polygons, dtype=torch.uint8)\n",
    "    # 多段线中各点所属信控信号类型（默认为3未知，对应关系见 _polygon_light_type）\n",
    "    polygon_light_type = torch.ones(num_polygons, dtype=torch.uint8) * 3\n",
    "\n",
    "    # 多段线中点的坐标\n",
    "    point_position: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点对应向量的方向角（以弧度表示）\n",
    "    point_orientation: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点对应向量的大小（即距离）\n",
    "    point_magnitude: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点与下一点之间的高度差\n",
    "    point_height: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点类型（对应关系见 _point_types）\n",
    "    point_type: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "\n",
    "    for lane_segment in lane_segments:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        polyline_index = lane_segment.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(Lane_type_hash[lane_segment.type])\n",
    "\n",
    "        # 查找当前lane是否在当前帧的信控控制的序列中\n",
    "        res = tf_current_light[tf_current_light[\"lane_id\"] == str(lane_segment.id)]\n",
    "        if len(res) != 0:\n",
    "            polygon_light_type[lane_segment_idx] = _polygon_light_type.index(res[\"state\"].item())\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index('CENTERLINE')\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    for lane_segment in road_edges:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        polyline_index = lane_segment.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(\"VEHICLE\")\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index('EDGE')\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    for lane_segment in road_lines:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        polyline_index = lane_segment.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(\"VEHICLE\")\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index(boundary_type_hash[lane_segment.type])\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    for crosswalk in crosswalks:\n",
    "        crosswalk = easydict.EasyDict(crosswalk)\n",
    "        lane_segment_idx = polygon_ids.index(crosswalk.id)\n",
    "        polyline_index = crosswalk.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(\"PEDESTRIAN\")\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index(\"CROSSWALK\")\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    # 每条多段线对应的点数\n",
    "    num_points = torch.tensor([point.size(0) for point in point_position], dtype=torch.long)\n",
    "    # [2, N_points] 点索引与多段线索引之间的关系\n",
    "    point_to_polygon_edge_index = torch.stack(\n",
    "        [torch.arange(num_points.sum(), dtype=torch.long),\n",
    "            torch.arange(num_polygons, dtype=torch.long).repeat_interleave(num_points)], dim=0)\n",
    "    # array([2, N_edge])) 提取车道拓扑关系[车道索引1，车道索引2](不根据顺序区分上下游)\n",
    "    polygon_to_polygon_edge_index = []\n",
    "    # array([N_edge])) 拓扑关系类型，参考 _polygon_to_polygon_types\n",
    "    polygon_to_polygon_type = []\n",
    "    for lane_segment in lane_segments:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        pred_inds = []\n",
    "        for pred in lane_segment.entry_lanes:\n",
    "            pred_idx = _safe_list_index(polygon_ids, pred)\n",
    "            if pred_idx is not None:\n",
    "                pred_inds.append(pred_idx)\n",
    "        if len(pred_inds) != 0:\n",
    "            polygon_to_polygon_edge_index.append(\n",
    "                torch.stack([torch.tensor(pred_inds, dtype=torch.long),\n",
    "                             torch.full((len(pred_inds),), lane_segment_idx, dtype=torch.long)], dim=0))\n",
    "            polygon_to_polygon_type.append(\n",
    "                torch.full((len(pred_inds),), _polygon_to_polygon_types.index('PRED'), dtype=torch.uint8))\n",
    "        succ_inds = []\n",
    "        for succ in lane_segment.exit_lanes:\n",
    "            succ_idx = _safe_list_index(polygon_ids, succ)\n",
    "            if succ_idx is not None:\n",
    "                succ_inds.append(succ_idx)\n",
    "        if len(succ_inds) != 0:\n",
    "            polygon_to_polygon_edge_index.append(\n",
    "                torch.stack([torch.tensor(succ_inds, dtype=torch.long),\n",
    "                             torch.full((len(succ_inds),), lane_segment_idx, dtype=torch.long)], dim=0))\n",
    "            polygon_to_polygon_type.append(\n",
    "                torch.full((len(succ_inds),), _polygon_to_polygon_types.index('SUCC'), dtype=torch.uint8))\n",
    "        if len(lane_segment.left_neighbors) != 0:\n",
    "            left_neighbor_ids = lane_segment.left_neighbors\n",
    "            for left_neighbor_id in left_neighbor_ids:\n",
    "                left_idx = _safe_list_index(polygon_ids, left_neighbor_id)\n",
    "                if left_idx is not None:\n",
    "                    polygon_to_polygon_edge_index.append(\n",
    "                        torch.tensor([[left_idx], [lane_segment_idx]], dtype=torch.long))\n",
    "                    polygon_to_polygon_type.append(\n",
    "                        torch.tensor([_polygon_to_polygon_types.index('LEFT')], dtype=torch.uint8))\n",
    "        if len(lane_segment.right_neighbors) != 0:\n",
    "            right_neighbor_ids = lane_segment.right_neighbors\n",
    "            for right_neighbor_id in right_neighbor_ids:\n",
    "                right_idx = _safe_list_index(polygon_ids, right_neighbor_id)\n",
    "                if right_idx is not None:\n",
    "                    polygon_to_polygon_edge_index.append(\n",
    "                        torch.tensor([[right_idx], [lane_segment_idx]], dtype=torch.long))\n",
    "                    polygon_to_polygon_type.append(\n",
    "                        torch.tensor([_polygon_to_polygon_types.index('RIGHT')], dtype=torch.uint8))\n",
    "    if len(polygon_to_polygon_edge_index) != 0:\n",
    "        polygon_to_polygon_edge_index = torch.cat(polygon_to_polygon_edge_index, dim=1)\n",
    "        polygon_to_polygon_type = torch.cat(polygon_to_polygon_type, dim=0)\n",
    "    else:\n",
    "        polygon_to_polygon_edge_index = torch.tensor([[], []], dtype=torch.long)\n",
    "        polygon_to_polygon_type = torch.tensor([], dtype=torch.uint8)\n",
    "\n",
    "    map_data = {\n",
    "        'map_polygon': {},\n",
    "        'map_point': {},\n",
    "        ('map_point', 'to', 'map_polygon'): {},\n",
    "        ('map_polygon', 'to', 'map_polygon'): {},\n",
    "    }\n",
    "    map_data['map_polygon']['num_nodes'] = num_polygons\n",
    "    map_data['map_polygon']['type'] = polygon_type\n",
    "    map_data['map_polygon']['light_type'] = polygon_light_type\n",
    "    if len(num_points) == 0:\n",
    "        map_data['map_point']['num_nodes'] = 0\n",
    "        map_data['map_point']['position'] = torch.tensor([], dtype=torch.float)\n",
    "        map_data['map_point']['orientation'] = torch.tensor([], dtype=torch.float)\n",
    "        map_data['map_point']['magnitude'] = torch.tensor([], dtype=torch.float)\n",
    "        if dim == 3:\n",
    "            map_data['map_point']['height'] = torch.tensor([], dtype=torch.float)\n",
    "        map_data['map_point']['type'] = torch.tensor([], dtype=torch.uint8)\n",
    "        map_data['map_point']['side'] = torch.tensor([], dtype=torch.uint8)\n",
    "    else:\n",
    "        map_data['map_point']['num_nodes'] = num_points.sum().item()\n",
    "        map_data['map_point']['position'] = torch.cat(point_position, dim=0)\n",
    "        map_data['map_point']['orientation'] = torch.cat(point_orientation, dim=0)\n",
    "        map_data['map_point']['magnitude'] = torch.cat(point_magnitude, dim=0)\n",
    "        if dim == 3:\n",
    "            map_data['map_point']['height'] = torch.cat(point_height, dim=0)\n",
    "        map_data['map_point']['type'] = torch.cat(point_type, dim=0)\n",
    "    map_data['map_point', 'to', 'map_polygon']['edge_index'] = point_to_polygon_edge_index\n",
    "    map_data['map_polygon', 'to', 'map_polygon']['edge_index'] = polygon_to_polygon_edge_index\n",
    "    map_data['map_polygon', 'to', 'map_polygon']['type'] = polygon_to_polygon_type\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # plt.axis('equal')\n",
    "    # plt.scatter(map_data['map_point']['position'][:, 0],\n",
    "    #             map_data['map_point']['position'][:, 1], s=0.2, c='black', edgecolors='none')\n",
    "    # plt.show(dpi=600)\n",
    "    return map_data\n",
    "\n",
    "map_info = save_infos[\"map_infos\"]\n",
    "tf_current_light = tf_lights.loc[tf_lights[\"time_step\"] == \"11\"]\n",
    "map_data = get_map_features(map_info, tf_current_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 获取代理特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**new_agents_array**: *array(num_track, 20)*, 详细记录轨迹相关信息\n",
    "+ `observed`\t    是否观测到该点\n",
    "+ `track_id`\t    物体的唯一轨迹ID\n",
    "+ `object_type`\t    物体类型（vehicle、pedestrian 等）\n",
    "+ `object_category`\t物体类别\n",
    "+ `timestep`\t    当前时间步\n",
    "+ `position_x`\t    x 方向位置坐标\n",
    "+ `position_y`\t    y 方向位置坐标\n",
    "+ `position_z`\t    z 方向位置坐标\n",
    "+ `length`\t        物体长度\n",
    "+ `width`\t        物体宽度\n",
    "+ `height`\t        物体高度\n",
    "+ `heading`\t        物体朝向\n",
    "+ `velocity_x`\t    x 方向速度\n",
    "+ `velocity_y`\t    y 方向速度\n",
    "+ `scenario_id`\t    场景ID\n",
    "+ `start_timestamp`\t起始时间戳\n",
    "+ `end_timestamp`\t结束时间戳\n",
    "+ `num_timestamps`\t时间步总数\n",
    "+ `focal_track_id`\t聚焦轨迹ID\n",
    "+ `city`\t        城市标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_agent(track_info, tracks_to_predict, sdc_track_index, scenario_id, start_timestamp, end_timestamp):\n",
    "    agents_array = track_info[\"trajs\"].transpose(1, 0, 2)   #[NT, NA, 10]\n",
    "    # 代理ID\n",
    "    object_id = np.array(track_info[\"object_id\"])\n",
    "    # 代理类型（str）\n",
    "    object_type = track_info[\"object_type\"]\n",
    "    # 映射关系 {代理ID：代理类型}\n",
    "    id_hash = {object_id[o_idx]: object_type[o_idx] for o_idx in range(len(object_id))}\n",
    "    def type_hash(x):\n",
    "        tp = id_hash[x]\n",
    "        type_re_hash = {\n",
    "            \"TYPE_VEHICLE\": \"vehicle\",\n",
    "            \"TYPE_PEDESTRIAN\": \"pedestrian\",\n",
    "            \"TYPE_CYCLIST\": \"cyclist\",\n",
    "            \"TYPE_OTHER\": \"background\",\n",
    "            \"TYPE_UNSET\": \"background\"\n",
    "        }\n",
    "        return type_re_hash[tp]\n",
    "\n",
    "    columns = ['observed', 'track_id', 'object_type', 'object_category', 'timestep',\n",
    "               'position_x', 'position_y', 'position_z', 'length', 'width', 'height', 'heading', 'velocity_x', 'velocity_y',\n",
    "               'scenario_id', 'start_timestamp', 'end_timestamp', 'num_timestamps',\n",
    "               'focal_track_id', 'city']\n",
    "    new_columns = np.ones((agents_array.shape[0], agents_array.shape[1], 11))\n",
    "    new_columns[:11, :, 0] = True\n",
    "    new_columns[11:, :, 0] = False\n",
    "    for index in range(new_columns.shape[0]):\n",
    "        new_columns[index, :, 4] = int(index)\n",
    "    new_columns[..., 1] = object_id\n",
    "    new_columns[..., 2] = object_id\n",
    "    new_columns[:, tracks_to_predict[\"track_index\"], 3] = 3\n",
    "    new_columns[..., 5] = 11\n",
    "    new_columns[..., 6] = int(start_timestamp)\n",
    "    new_columns[..., 7] = int(end_timestamp)\n",
    "    new_columns[..., 8] = int(91)\n",
    "    new_columns[..., 9] = object_id\n",
    "    new_columns[..., 10] = 10086\n",
    "    new_columns = new_columns\n",
    "    new_agents_array = np.concatenate([new_columns, agents_array], axis=-1)\n",
    "    new_agents_array = new_agents_array[new_agents_array[..., -1] == 1.0].reshape(-1, new_agents_array.shape[-1])\n",
    "    new_agents_array = new_agents_array[..., [0, 1, 2, 3, 4, 11, 12, 13, 14, 15, 16, 17, 18, 19, 5, 6, 7, 8, 9, 10]]\n",
    "    new_agents_array = pd.DataFrame(data=new_agents_array, columns=columns)\n",
    "    new_agents_array[\"object_type\"] = new_agents_array[\"object_type\"].apply(func=type_hash)\n",
    "    new_agents_array[\"start_timestamp\"] = new_agents_array[\"start_timestamp\"].astype(int)\n",
    "    new_agents_array[\"end_timestamp\"] = new_agents_array[\"end_timestamp\"].astype(int)\n",
    "    new_agents_array[\"num_timestamps\"] = new_agents_array[\"num_timestamps\"].astype(int)\n",
    "    new_agents_array[\"scenario_id\"] = scenario_id\n",
    "    return new_agents_array\n",
    "\n",
    "\n",
    "track_info = save_infos['track_infos']\n",
    "tracks_to_predict = save_infos['tracks_to_predict']\n",
    "assert len(tracks_to_predict[\"track_index\"]) >= 1 \n",
    "sdc_track_index = save_infos['sdc_track_index']\n",
    "scenario_id = save_infos['scenario_id']\n",
    "\n",
    "new_agents_array = process_agent(track_info, tracks_to_predict, sdc_track_index, scenario_id, 0, 91) # mtr2argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_unseen_agents = False\n",
    "vector_repr = True\n",
    "split = 'train'\n",
    "\n",
    "def get_agent_features(df: pd.DataFrame, av_id, num_historical_steps=10, dim=3, num_steps=91) -> Dict[str, Any]:\n",
    "    _agent_types = ['vehicle', 'pedestrian', 'cyclist', 'background']\n",
    "    \n",
    "    if not predict_unseen_agents:  # filter out agents that are unseen during the historical time steps\n",
    "        historical_df = df[df['timestep'] == num_historical_steps-1]\n",
    "        agent_ids = list(historical_df['track_id'].unique())\n",
    "        df = df[df['track_id'].isin(agent_ids)]\n",
    "    else:\n",
    "        agent_ids = list(df['track_id'].unique())\n",
    "\n",
    "    num_agents = len(agent_ids)\n",
    "\n",
    "    # 代理是否处在有效状态\n",
    "    valid_mask = torch.zeros(num_agents, num_steps, dtype=torch.bool)\n",
    "    # 代理在当前帧是否有效\n",
    "    current_valid_mask = torch.zeros(num_agents, dtype=torch.bool)\n",
    "    # 是否需要预测\n",
    "    predict_mask = torch.zeros(num_agents, num_steps, dtype=torch.bool)\n",
    "    # 代理ID\n",
    "    agent_id: List[Optional[str]] = [None] * num_agents\n",
    "    # 代理类型：0 'vehicle', 1 'pedestrian', 2 'cyclist', 3 'background'\n",
    "    agent_type = torch.zeros(num_agents, dtype=torch.uint8)\n",
    "    # 代理类别：1 其他代理, 3 应该被预测代理\n",
    "    agent_category = torch.zeros(num_agents, dtype=torch.uint8)\n",
    "    # 代理位置 [NA, NT, 3] (x, y, z)\n",
    "    position = torch.zeros(num_agents, num_steps, dim, dtype=torch.float)\n",
    "    # 代理航向 [NA, NT]\n",
    "    heading = torch.zeros(num_agents, num_steps, dtype=torch.float)\n",
    "    # 代理速度 [NA, NT, 3] (vx, vy, 0)\n",
    "    velocity = torch.zeros(num_agents, num_steps, dim, dtype=torch.float)\n",
    "    # 代理尺寸 [NA, NT, 3] (length, width, height)\n",
    "    shape = torch.zeros(num_agents, num_steps, dim, dtype=torch.float)\n",
    "\n",
    "    for track_id, track_df in df.groupby('track_id'):\n",
    "        agent_idx = agent_ids.index(track_id)\n",
    "        agent_steps = track_df['timestep'].values\n",
    "\n",
    "        # 与tracks中提供的valid一致\n",
    "        valid_mask[agent_idx, agent_steps] = True\n",
    "        # 当前帧是否可用\n",
    "        current_valid_mask[agent_idx] = valid_mask[agent_idx, num_historical_steps - 1]\n",
    "        # 与tracks中提供的valid一致\n",
    "        predict_mask[agent_idx, agent_steps] = True\n",
    "        # 当前时间步 t 的有效性依赖于 t 和 t-1 的有效性。\n",
    "        if vector_repr:  # a time step t is valid only when both t and t-1 are valid\n",
    "            valid_mask[agent_idx, 1: num_historical_steps] = (\n",
    "                valid_mask[agent_idx, :num_historical_steps - 1] &\n",
    "                valid_mask[agent_idx, 1: num_historical_steps])\n",
    "            valid_mask[agent_idx, 0] = False\n",
    "        # 设置历史时间步的预测掩码为无效\n",
    "        predict_mask[agent_idx, :num_historical_steps] = False\n",
    "        # 如果当前帧无效，设置后续时间步的预测掩码为无效\n",
    "        if not current_valid_mask[agent_idx]:\n",
    "            predict_mask[agent_idx, num_historical_steps:] = False\n",
    "\n",
    "        agent_id[agent_idx] = track_id\n",
    "        agent_type[agent_idx] = _agent_types.index(track_df['object_type'].values[0])\n",
    "        agent_category[agent_idx] = track_df['object_category'].values[0]\n",
    "        position[agent_idx, agent_steps, :3] = torch.from_numpy(np.stack([track_df['position_x'].values,\n",
    "                                                                          track_df['position_y'].values,\n",
    "                                                                          track_df['position_z'].values],\n",
    "                                                                         axis=-1)).float()\n",
    "        heading[agent_idx, agent_steps] = torch.from_numpy(track_df['heading'].values).float()\n",
    "        velocity[agent_idx, agent_steps, :2] = torch.from_numpy(np.stack([track_df['velocity_x'].values,\n",
    "                                                                          track_df['velocity_y'].values],\n",
    "                                                                         axis=-1)).float()\n",
    "        shape[agent_idx, agent_steps, :3] = torch.from_numpy(np.stack([track_df['length'].values,\n",
    "                                                                       track_df['width'].values,\n",
    "                                                                       track_df[\"height\"].values],\n",
    "                                                                      axis=-1)).float()\n",
    "    av_idx = agent_id.index(av_id)\n",
    "    if split == 'test':\n",
    "        predict_mask[current_valid_mask\n",
    "                     | (agent_category == 2)\n",
    "                     | (agent_category == 3), num_historical_steps:] = True\n",
    "\n",
    "    return {\n",
    "        'num_nodes': num_agents,\n",
    "        'av_index': av_idx,\n",
    "        'valid_mask': valid_mask,\n",
    "        'predict_mask': predict_mask,\n",
    "        'id': agent_id,\n",
    "        'type': agent_type,\n",
    "        'category': agent_category,\n",
    "        'position': position,\n",
    "        'heading': heading,\n",
    "        'velocity': velocity,\n",
    "        'shape': shape\n",
    "    }\n",
    "\n",
    "av_id = track_info[\"object_id\"][sdc_track_index]\n",
    "agent_features = get_agent_features(new_agents_array, av_id, num_historical_steps=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 组织预处理的data信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data**\n",
    "+ `scenario_id`: *str*, 场景id\n",
    "+ `city`: *float*, 场景所属城市编号（默认10086）\n",
    "+ `agent`: *dict*, 场景中的代理信息\n",
    "    - `num_nodes`: *int*, 代理数量\n",
    "    - `av_index`: *int*, AV对应的代理编号\n",
    "    - `valid_mask`: *array([NA, NT])*, 各代理各时间步是否有效\n",
    "    - `predict_mask`: *array([NA, NT])*, 各代理需要被预测的时间步\n",
    "    - `id`: *list([NA])*, 代理ID \n",
    "    - `type`: *array([NA])*, 代理类型\n",
    "        > 0 'vehicle', 1 'pedestrian', 2 'cyclist', 3 'background'\n",
    "    - `category`: *array([NA])*, 代理类别\n",
    "        > 1 其他代理, 2 感兴趣代理, 3 被预测代理\n",
    "    - `position`: *array([NA, NT, 3])*, 代理位置 (x, y, z)\n",
    "    - `heading`: *array([NA, NT])*, 代理航向\n",
    "    - `velocity`: *array([NA, NT, 3])*, 代理速度 (vx, vy, 0)\n",
    "    - `shape`: *array([NA, NT, 3])*, 代理尺寸 (length, width, height)\n",
    "+ `map_polygon`: *dict*, 地图中多段线信息\n",
    "    - `num_nodes`: *int*, 多段线数量\n",
    "    - `type`: *array([num_nodes])*, 每条多段线对应的类型\n",
    "        > ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "    - `light_type`: *array([num_nodes])*, 每条多段线对应的交通信号状态\n",
    "        > ['LANE_STATE_STOP', 'LANE_STATE_GO', 'LANE_STATE_CAUTION', 'LANE_STATE_UNKNOWN']\n",
    "+ `map_point`: *dict*, 地图中各点信息\n",
    "    - `num_nodes`: *int*, 点数量\n",
    "    - `position`: *array([num_nodes, 3])*, 点的坐标(x, y, z)\n",
    "    - `orientation`: *array([num_nodes])*, 各点对应向量的方向角（以弧度表示）\n",
    "    - `magnitude`: *array([num_nodes])*, 各点对应向量的大小（即距离）\n",
    "    - `height`: *array([num_nodes])*, 各点与下一点之间的高度差 *(dim=3时才存在)*\n",
    "    - `type`: *array([num_nodes])*, 各点所属类型\n",
    "        > [ 'DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "            'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "            'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "            'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "+ `'map_point', 'to', 'map_polygon'`: *dict*, 点与多段线之间的索引映射关系\n",
    "    - `edge_index`: *array([2, num_points])*, [point_idx, polygon_idx]\n",
    "+ `'map_polygon', 'to', 'map_polygon'`: *dict*, 车道与车道之间的拓扑关系\n",
    "    - `edge_index`: *array([2, num_edges])*, [polygon1_idx, polygon2_idx]\n",
    "    - `type`: *array([num_edges])*, 拓扑关系类型-polygon1是polygon2的前驱/后继/左邻居/右邻居\n",
    "        > ['NONE', 'PRED', 'SUCC', 'LEFT', 'RIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['scenario_id'] = new_agents_array['scenario_id'].values[0]\n",
    "data['city'] = new_agents_array['city'].values[0]\n",
    "data['agent'] = agent_features\n",
    "data.update(map_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 数据加载时token化预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**agent_token_data**\n",
    "\n",
    "聚类得到的token信息，即以[0,0]为第一帧中心坐标，五帧为时间间隔到达的终点位置\n",
    "\n",
    "+ `token`: *dict*, 每个token对应的终点位置矩形的四个角点坐标(x, y)，**角点顺序为-左前、右前、右后、左后**\n",
    "    - `veh`: *array([2048, 4, 2])*\n",
    "    - `ped`: *array([2048, 4, 2])*\n",
    "    - `cyc`: *array([2048, 4, 2])*\n",
    "+ `traj`: *dict*, 每个token对应的6帧完整轨迹中心坐标 (x, y ,z)\n",
    "    - `veh`: *array([2048, 6, 3])*\n",
    "    - `ped`: *array([2048, 6, 3])*\n",
    "    - `cyc`: *array([2048, 6, 3])*\n",
    "+ `token_all`: *dict*, 每个token对应的6帧完整轨迹各处矩形四个角点坐标\n",
    "    - `veh`: *array([2048, 6, 4, 2])*\n",
    "    - `ped`: *array([2048, 6, 4, 2])*\n",
    "    - `cyc`: *array([2048, 6, 4, 2])*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "current_step = 10\n",
    "shift = 5\n",
    "noise = True\n",
    "training = False\n",
    "\n",
    "agent_token_path = \"/home/yangyh408/codes/SMART/smart/tokens/cluster_frame_5_2048.pkl\"\n",
    "agent_token_data = pickle.load(open(agent_token_path, 'rb'))\n",
    "trajectory_token = agent_token_data['token']\n",
    "trajectory_token_all = agent_token_data['token_all']\n",
    "# 对所有token依据倒数第二帧的状态为基准状态对最后一帧进行归一化\n",
    "token_last_all = {}\n",
    "\n",
    "for k, v in trajectory_token_all.items():\n",
    "    # 计算每个 agent 的最终 token 朝向\n",
    "    token_last = torch.from_numpy(v[:, -2:]).to(torch.float)    # [2048, 2, 4, 2]\n",
    "    diff_xy = token_last[:, 0, 0] - token_last[:, 0, 3]         # 倒数第二帧 左前-左后\n",
    "    theta = torch.arctan2(diff_xy[:, 1], diff_xy[:, 0])         # 倒数第二帧的航向角\n",
    "    cos, sin = theta.cos(), theta.sin()\n",
    "    # 生成旋转矩阵\n",
    "    rot_mat = theta.new_zeros(token_last.shape[0], 2, 2)\n",
    "    rot_mat[:, 0, 0] = cos\n",
    "    rot_mat[:, 0, 1] = -sin\n",
    "    rot_mat[:, 1, 0] = sin\n",
    "    rot_mat[:, 1, 1] = cos\n",
    "    # 应用旋转矩阵并归一化 token 数据\n",
    "    agent_token = torch.bmm(token_last[:, 1], rot_mat)\n",
    "    agent_token -= token_last[:, 0].mean(1)[:, None, :]\n",
    "    token_last_all[k] = agent_token.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_heading(data):\n",
    "    \"\"\"\n",
    "        这个函数 clean_heading 的主要功能是对“heading” (朝向角度) 进行清理，以修复明显异常或突然变化的朝向角度\n",
    "        （例如，当相邻帧之间的朝向差异超过一定阈值时），从而平滑朝向数据。\n",
    "        具体而言，代码通过对相邻帧的朝向差异进行检测和修正，使得朝向变化更连贯。\n",
    "    \"\"\"\n",
    "    heading = data['agent']['heading']\n",
    "    valid = data['agent']['valid_mask']\n",
    "    pi = torch.tensor(torch.pi)\n",
    "    n_vehicles, n_frames = heading.shape\n",
    "\n",
    "    heading_diff_raw = heading[:, :-1] - heading[:, 1:]\n",
    "    heading_diff = torch.remainder(heading_diff_raw + pi, 2 * pi) - pi\n",
    "    heading_diff[heading_diff > pi] -= 2 * pi\n",
    "    heading_diff[heading_diff < -pi] += 2 * pi\n",
    "\n",
    "    valid_pairs = valid[:, :-1] & valid[:, 1:]\n",
    "\n",
    "    for i in range(n_frames - 1):\n",
    "        change_needed = (torch.abs(heading_diff[:, i:i + 1]) > 1.0) & valid_pairs[:, i:i + 1]\n",
    "\n",
    "        heading[:, i + 1][change_needed.squeeze()] = heading[:, i][change_needed.squeeze()]\n",
    "\n",
    "        if i < n_frames - 2:\n",
    "            heading_diff_raw = heading[:, i + 1] - heading[:, i + 2]\n",
    "            heading_diff[:, i + 1] = torch.remainder(heading_diff_raw + pi, 2 * pi) - pi\n",
    "            heading_diff[heading_diff[:, i + 1] > pi] -= 2 * pi\n",
    "            heading_diff[heading_diff[:, i + 1] < -pi] += 2 * pi\n",
    "\n",
    "def cal_polygon_contour(x, y, theta, width, length):\n",
    "    \"\"\"\n",
    "        函数功能：计算一个矩形多边形的四个顶点坐标（轮廓）\n",
    "        返回值：返回一个形状为 [n, 4, 2] 的数组 polygon_contour，表示每个矩形的四个顶点的坐标，方便后续用作绘制或碰撞检测等应用。\n",
    "    \"\"\"\n",
    "    left_front_x = x + 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_front_y = y + 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_front = np.column_stack((left_front_x, left_front_y))\n",
    "\n",
    "    right_front_x = x + 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_front_y = y + 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_front = np.column_stack((right_front_x, right_front_y))\n",
    "\n",
    "    right_back_x = x - 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_back_y = y - 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_back = np.column_stack((right_back_x, right_back_y))\n",
    "\n",
    "    left_back_x = x - 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_back_y = y - 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_back = np.column_stack((left_back_x, left_back_y))\n",
    "\n",
    "    polygon_contour = np.concatenate(\n",
    "        (left_front[:, None, :], right_front[:, None, :], right_back[:, None, :], left_back[:, None, :]), axis=1)\n",
    "\n",
    "    return polygon_contour\n",
    "\n",
    "def match_token(pos, valid_mask, heading, category, agent_category, extra_mask):\n",
    "    \"\"\"\n",
    "        将轨迹位置和朝向数据与预定义的 token 数据进行匹配，以便在场景中的每个时间步中都能追踪到正确的 token。\n",
    "    \"\"\"\n",
    "    agent_token_src = trajectory_token[category]\n",
    "    token_last = token_last_all[category]\n",
    "    if shift <= 2:\n",
    "        if category == 'veh':\n",
    "            width = 1.0\n",
    "            length = 2.4\n",
    "        elif category == 'cyc':\n",
    "            width = 0.5\n",
    "            length = 1.5\n",
    "        else:\n",
    "            width = 0.5\n",
    "            length = 0.5\n",
    "    else:\n",
    "        if category == 'veh':\n",
    "            width = 2.0\n",
    "            length = 4.8\n",
    "        elif category == 'cyc':\n",
    "            width = 1.0\n",
    "            length = 2.0\n",
    "        else:\n",
    "            width = 1.0\n",
    "            length = 1.0\n",
    "\n",
    "    prev_heading = heading[:, 0]\n",
    "    prev_pos = pos[:, 0]\n",
    "    agent_num, num_step, feat_dim = pos.shape   # [NA, 91, 2]\n",
    "    token_num, token_contour_dim, feat_dim = agent_token_src.shape  # [2048, 4, 2]\n",
    "    agent_token_src = agent_token_src.reshape(1, token_num * token_contour_dim, feat_dim).repeat(agent_num, 0)\n",
    "    token_last = token_last.reshape(1, token_num * token_contour_dim, feat_dim).repeat(extra_mask.sum(), 0)\n",
    "    token_index_list = []\n",
    "    token_contour_list = []\n",
    "    prev_token_idx = None\n",
    "\n",
    "    for i in range(shift, pos.shape[1], shift):\n",
    "        # 上一token所在位置航向角（5帧前）\n",
    "        theta = prev_heading\n",
    "        # 当前航向角和位置\n",
    "        cur_heading = heading[:, i]\n",
    "        cur_pos = pos[:, i]\n",
    "        # 将归一化的原始token信息以上一时刻位置和航向状态为基准调整到全局坐标系\n",
    "        cos, sin = theta.cos(), theta.sin()\n",
    "        rot_mat = theta.new_zeros(agent_num, 2, 2)\n",
    "        rot_mat[:, 0, 0] = cos\n",
    "        rot_mat[:, 0, 1] = sin\n",
    "        rot_mat[:, 1, 0] = -sin\n",
    "        rot_mat[:, 1, 1] = cos\n",
    "        agent_token_world = torch.bmm(torch.from_numpy(agent_token_src).to(torch.float), rot_mat).reshape(agent_num,\n",
    "                                                                                                            token_num,\n",
    "                                                                                                            token_contour_dim,\n",
    "                                                                                                            feat_dim)\n",
    "        agent_token_world += prev_pos[:, None, None, :]\n",
    "\n",
    "        # 获取当前所在位置的矩形四角信息\n",
    "        cur_contour = cal_polygon_contour(cur_pos[:, 0], cur_pos[:, 1], cur_heading, width, length)\n",
    "        # 找出与当前距离最近的token作为匹配对象，记录该tokenid\n",
    "        agent_token_index = torch.from_numpy(np.argmin(\n",
    "            np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)), axis=2),\n",
    "            axis=-1))\n",
    "        if prev_token_idx is not None and noise:\n",
    "            same_idx = prev_token_idx == agent_token_index\n",
    "            same_idx[:] = True\n",
    "            topk_indices = np.argsort(\n",
    "                np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)),\n",
    "                        axis=2), axis=-1)[:, :5]\n",
    "            sample_topk = np.random.choice(range(0, topk_indices.shape[1]), topk_indices.shape[0])\n",
    "            agent_token_index[same_idx] = \\\n",
    "                torch.from_numpy(topk_indices[np.arange(topk_indices.shape[0]), sample_topk])[same_idx]\n",
    "        # 将匹配的tokenid转换为矩形四角坐标\n",
    "        token_contour_select = agent_token_world[torch.arange(agent_num), agent_token_index]\n",
    "\n",
    "        # 将当前帧信息更新为上一帧信息\n",
    "        diff_xy = token_contour_select[:, 0, :] - token_contour_select[:, 3, :]\n",
    "        # 数据集中原航向角\n",
    "        prev_heading = heading[:, i].clone()\n",
    "        # 如果是这一帧被预测的对象，则用当前token所在状态更新航向和位置信息\n",
    "        prev_heading[valid_mask[:, i - shift]] = torch.arctan2(diff_xy[:, 1], diff_xy[:, 0])[\n",
    "            valid_mask[:, i - shift]]\n",
    "\n",
    "        prev_pos = pos[:, i].clone()\n",
    "        prev_pos[valid_mask[:, i - shift]] = token_contour_select.mean(dim=1)[valid_mask[:, i - shift]]\n",
    "        prev_token_idx = agent_token_index\n",
    "        token_index_list.append(agent_token_index[:, None])\n",
    "        token_contour_list.append(token_contour_select[:, None, ...])\n",
    "\n",
    "    token_index = torch.cat(token_index_list, dim=1)\n",
    "    token_contour = torch.cat(token_contour_list, dim=1)\n",
    "\n",
    "    # extra matching（如果在第十一帧存在但第六帧不存在的代理，则根据第十帧的状态来匹配token信息）\n",
    "    if not training:\n",
    "        theta = heading[extra_mask, current_step - 1]\n",
    "        prev_pos = pos[extra_mask, current_step - 1]\n",
    "        cur_pos = pos[extra_mask, current_step]\n",
    "        cur_heading = heading[extra_mask, current_step]\n",
    "        cos, sin = theta.cos(), theta.sin()\n",
    "        rot_mat = theta.new_zeros(extra_mask.sum(), 2, 2)\n",
    "        rot_mat[:, 0, 0] = cos\n",
    "        rot_mat[:, 0, 1] = sin\n",
    "        rot_mat[:, 1, 0] = -sin\n",
    "        rot_mat[:, 1, 1] = cos\n",
    "        agent_token_world = torch.bmm(torch.from_numpy(token_last).to(torch.float), rot_mat).reshape(\n",
    "            extra_mask.sum(), token_num, token_contour_dim, feat_dim)\n",
    "        agent_token_world += prev_pos[:, None, None, :]\n",
    "\n",
    "        cur_contour = cal_polygon_contour(cur_pos[:, 0], cur_pos[:, 1], cur_heading, width, length)\n",
    "        agent_token_index = torch.from_numpy(np.argmin(\n",
    "            np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)), axis=2),\n",
    "            axis=-1))\n",
    "        token_contour_select = agent_token_world[torch.arange(extra_mask.sum()), agent_token_index]\n",
    "\n",
    "        token_index[extra_mask, 1] = agent_token_index\n",
    "        token_contour[extra_mask, 1] = token_contour_select\n",
    "\n",
    "    return token_index, token_contour\n",
    "\n",
    "def tokenize_agent(data):\n",
    "    if data['agent'][\"velocity\"].shape[1] == 90:\n",
    "        print(data['scenario_id'], data['agent'][\"velocity\"].shape)\n",
    "    \n",
    "    # 创建插值掩码 interplote_mask，用于标记那些当前时间步为无效但坐标非零的位置，以确定需要插值的数据点\n",
    "    interplote_mask = (data['agent']['valid_mask'][:, current_step] == False) * (\n",
    "            data['agent']['position'][:, current_step, 0] != 0)\n",
    "    # 通过检查当前时间步中无效但位置非零的轨迹点，将其前一个时间步的位置、速度、航向等信息进行估算和填充，确保轨迹数据连续性\n",
    "    if data['agent'][\"velocity\"].shape[-1] == 2:\n",
    "        data['agent'][\"velocity\"] = torch.cat([data['agent'][\"velocity\"],\n",
    "                                                torch.zeros(data['agent'][\"velocity\"].shape[0],\n",
    "                                                            data['agent'][\"velocity\"].shape[1], 1)], dim=-1)\n",
    "    vel = data['agent'][\"velocity\"][interplote_mask, current_step]\n",
    "    # 插值前一个时间步的位置、航向、速度\n",
    "    data['agent']['position'][interplote_mask, current_step - 1, :3] = data['agent']['position'][\n",
    "                                                                            interplote_mask, current_step,\n",
    "                                                                            :3] - vel * 0.1\n",
    "    data['agent']['heading'][interplote_mask, current_step - 1] = data['agent']['heading'][\n",
    "        interplote_mask, current_step]\n",
    "    data['agent'][\"velocity\"][interplote_mask, current_step - 1] = data['agent'][\"velocity\"][\n",
    "        interplote_mask, current_step]\n",
    "    data['agent']['valid_mask'][interplote_mask, current_step - 1:current_step + 1] = True\n",
    "\n",
    "    data['agent']['type'] = data['agent']['type'].to(torch.uint8)\n",
    "\n",
    "    clean_heading(data)\n",
    "    matching_extra_mask = (data['agent']['valid_mask'][:, current_step] == True) * (\n",
    "            data['agent']['valid_mask'][:, current_step - 5] == False)\n",
    "\n",
    "    interplote_mask_first = (data['agent']['valid_mask'][:, 0] == False) * (data['agent']['position'][:, 0, 0] != 0)\n",
    "    data['agent']['valid_mask'][interplote_mask_first, 0] = True\n",
    "\n",
    "    agent_pos = data['agent']['position'][:, :, :2]\n",
    "    valid_mask = data['agent']['valid_mask']\n",
    "    # 以下标1为起点，长度为6，间隔为5创建滑动窗口\n",
    "    valid_mask_shift = valid_mask.unfold(1, shift + 1, shift)         # [NA, 18, 6]\n",
    "    # 每个滑动窗口的起止都为true时窗口才有效\n",
    "    token_valid_mask = valid_mask_shift[:, :, 0] * valid_mask_shift[:, :, -1]   # [NA, 18]\n",
    "    agent_type = data['agent']['type']\n",
    "    agent_category = data['agent']['category']\n",
    "    agent_heading = data['agent']['heading']\n",
    "    vehicle_mask = agent_type == 0\n",
    "    cyclist_mask = agent_type == 2\n",
    "    ped_mask = agent_type == 1\n",
    "\n",
    "    veh_pos = agent_pos[vehicle_mask, :, :]\n",
    "    veh_valid_mask = valid_mask[vehicle_mask, :]\n",
    "    cyc_pos = agent_pos[cyclist_mask, :, :]\n",
    "    cyc_valid_mask = valid_mask[cyclist_mask, :]\n",
    "    ped_pos = agent_pos[ped_mask, :, :]\n",
    "    ped_valid_mask = valid_mask[ped_mask, :]\n",
    "\n",
    "    veh_token_index, veh_token_contour = match_token(veh_pos, veh_valid_mask, agent_heading[vehicle_mask],\n",
    "                                                            'veh', agent_category[vehicle_mask],\n",
    "                                                            matching_extra_mask[vehicle_mask])\n",
    "    ped_token_index, ped_token_contour = match_token(ped_pos, ped_valid_mask, agent_heading[ped_mask], 'ped',\n",
    "                                                            agent_category[ped_mask], matching_extra_mask[ped_mask])\n",
    "    cyc_token_index, cyc_token_contour = match_token(cyc_pos, cyc_valid_mask, agent_heading[cyclist_mask],\n",
    "                                                            'cyc', agent_category[cyclist_mask],\n",
    "                                                            matching_extra_mask[cyclist_mask])\n",
    "\n",
    "    # token_index: [NA, 18(90/5)] 每个代理在90帧中匹配到的18个token索引\n",
    "    token_index = torch.zeros((agent_pos.shape[0], veh_token_index.shape[1])).to(torch.int64)\n",
    "    token_index[vehicle_mask] = veh_token_index\n",
    "    token_index[ped_mask] = ped_token_index\n",
    "    token_index[cyclist_mask] = cyc_token_index\n",
    "\n",
    "    # token_contour: [NA, 18, 4, 2] 每个代理在90帧中匹配到的18个token对应的矩形信息\n",
    "    token_contour = torch.zeros((agent_pos.shape[0], veh_token_contour.shape[1],\n",
    "                                    veh_token_contour.shape[2], veh_token_contour.shape[3]))\n",
    "    token_contour[vehicle_mask] = veh_token_contour\n",
    "    token_contour[ped_mask] = ped_token_contour\n",
    "    token_contour[cyclist_mask] = cyc_token_contour\n",
    "\n",
    "    # trajectory_token_veh = torch.from_numpy(trajectory_token['veh']).clone().to(torch.float)\n",
    "    # trajectory_token_ped = torch.from_numpy(trajectory_token['ped']).clone().to(torch.float)\n",
    "    # trajectory_token_cyc = torch.from_numpy(trajectory_token['cyc']).clone().to(torch.float)\n",
    "\n",
    "    # agent_token_traj = torch.zeros((agent_pos.shape[0], trajectory_token_veh.shape[0], 4, 2))\n",
    "    # agent_token_traj[vehicle_mask] = trajectory_token_veh\n",
    "    # agent_token_traj[ped_mask] = trajectory_token_ped\n",
    "    # agent_token_traj[cyclist_mask] = trajectory_token_cyc\n",
    "\n",
    "    if not training:\n",
    "        token_valid_mask[matching_extra_mask, 1] = True\n",
    "\n",
    "    data['agent']['token_idx'] = token_index            # [NA, 18]\n",
    "    data['agent']['token_contour'] = token_contour      # [NA, 18, 4, 2]\n",
    "    token_pos = token_contour.mean(dim=2)               \n",
    "    data['agent']['token_pos'] = token_pos              # [NA, 18, 2]\n",
    "    diff_xy = token_contour[:, :, 0, :] - token_contour[:, :, 3, :]\n",
    "    data['agent']['token_heading'] = torch.arctan2(diff_xy[:, :, 1], diff_xy[:, :, 0])  # [NA, 18]\n",
    "    data['agent']['agent_valid_mask'] = token_valid_mask                                # [NA, 18]\n",
    "\n",
    "    vel = torch.cat([token_pos.new_zeros(data['agent']['num_nodes'], 1, 2),\n",
    "                        ((token_pos[:, 1:] - token_pos[:, :-1]) / (0.1 * shift))], dim=1)\n",
    "    vel_valid_mask = torch.cat([torch.zeros(token_valid_mask.shape[0], 1, dtype=torch.bool),\n",
    "                                (token_valid_mask * token_valid_mask.roll(shifts=1, dims=1))[:, 1:]], dim=1)\n",
    "    vel[~vel_valid_mask] = 0\n",
    "    vel[data['agent']['valid_mask'][:, current_step], 1] = data['agent']['velocity'][\n",
    "                                                                data['agent']['valid_mask'][:, current_step],\n",
    "                                                                current_step, :2]\n",
    "\n",
    "    data['agent']['token_velocity'] = vel\n",
    "\n",
    "    return data\n",
    "\n",
    "token_data = tokenize_agent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def wrap_angle(\n",
    "        angle: torch.Tensor,\n",
    "        min_val: float = -math.pi,\n",
    "        max_val: float = math.pi) -> torch.Tensor:\n",
    "    return min_val + (angle + max_val) % (max_val - min_val)\n",
    "\n",
    "def interplating_polyline(polylines, heading, distance=0.5, split_distace=5):\n",
    "    # 多段线切分长度为5米，多段线内部点之间距离为2.5米，即每条多段线由3个点构成\n",
    "    # Calculate the cumulative distance along the path, up-sample the polyline to 0.5 meter\n",
    "    dist_along_path_list = [[0]]\n",
    "    polylines_list = [[polylines[0]]]\n",
    "    for i in range(1, polylines.shape[0]):\n",
    "        euclidean_dist = euclidean(polylines[i, :2], polylines[i - 1, :2])\n",
    "        heading_diff = min(abs(max(heading[i], heading[i - 1]) - min(heading[1], heading[i - 1])),\n",
    "                           abs(max(heading[i], heading[i - 1]) - min(heading[1], heading[i - 1]) + math.pi))\n",
    "        if heading_diff > math.pi / 4 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif heading_diff > math.pi / 8 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif heading_diff > 0.1 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif euclidean_dist > 10:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        else:\n",
    "            dist_along_path_list[-1].append(dist_along_path_list[-1][-1] + euclidean_dist)\n",
    "            polylines_list[-1].append(polylines[i])\n",
    "    # plt.plot(polylines[:, 0], polylines[:, 1])\n",
    "    # plt.savefig('tmp.jpg')\n",
    "    new_x_list = []\n",
    "    new_y_list = []\n",
    "    multi_polylines_list = []\n",
    "    for idx in range(len(dist_along_path_list)):\n",
    "        if len(dist_along_path_list[idx]) < 2:\n",
    "            continue\n",
    "        dist_along_path = np.array(dist_along_path_list[idx])\n",
    "        polylines_cur = np.array(polylines_list[idx])\n",
    "        # Create interpolation functions for x and y coordinates\n",
    "        fx = interp1d(dist_along_path, polylines_cur[:, 0])\n",
    "        fy = interp1d(dist_along_path, polylines_cur[:, 1])\n",
    "        # fyaw = interp1d(dist_along_path, heading)\n",
    "\n",
    "        # Create an array of distances at which to interpolate\n",
    "        new_dist_along_path = np.arange(0, dist_along_path[-1], distance)\n",
    "        new_dist_along_path = np.concatenate([new_dist_along_path, dist_along_path[[-1]]])\n",
    "        # Use the interpolation functions to generate new x and y coordinates\n",
    "        new_x = fx(new_dist_along_path)\n",
    "        new_y = fy(new_dist_along_path)\n",
    "        # new_yaw = fyaw(new_dist_along_path)\n",
    "        new_x_list.append(new_x)\n",
    "        new_y_list.append(new_y)\n",
    "\n",
    "        # Combine the new x and y coordinates into a single array\n",
    "        new_polylines = np.vstack((new_x, new_y)).T\n",
    "        polyline_size = int(split_distace / distance)\n",
    "        if new_polylines.shape[0] >= (polyline_size + 1):\n",
    "            padding_size = (new_polylines.shape[0] - (polyline_size + 1)) % polyline_size\n",
    "            final_index = (new_polylines.shape[0] - (polyline_size + 1)) // polyline_size + 1\n",
    "        else:\n",
    "            padding_size = new_polylines.shape[0]\n",
    "            final_index = 0\n",
    "        multi_polylines = None\n",
    "        new_polylines = torch.from_numpy(new_polylines)\n",
    "        new_heading = torch.atan2(new_polylines[1:, 1] - new_polylines[:-1, 1],\n",
    "                                  new_polylines[1:, 0] - new_polylines[:-1, 0])\n",
    "        new_heading = torch.cat([new_heading, new_heading[-1:]], -1)[..., None]\n",
    "        new_polylines = torch.cat([new_polylines, new_heading], -1)\n",
    "        if new_polylines.shape[0] >= (polyline_size + 1):\n",
    "            multi_polylines = new_polylines.unfold(dimension=0, size=polyline_size + 1, step=polyline_size)\n",
    "            multi_polylines = multi_polylines.transpose(1, 2)\n",
    "            multi_polylines = multi_polylines[:, ::5, :]\n",
    "        if padding_size >= 3:\n",
    "            last_polyline = new_polylines[final_index * polyline_size:]\n",
    "            last_polyline = last_polyline[torch.linspace(0, last_polyline.shape[0] - 1, steps=3).long()]\n",
    "            if multi_polylines is not None:\n",
    "                multi_polylines = torch.cat([multi_polylines, last_polyline.unsqueeze(0)], dim=0)\n",
    "            else:\n",
    "                multi_polylines = last_polyline.unsqueeze(0)\n",
    "        if multi_polylines is None:\n",
    "            continue\n",
    "        multi_polylines_list.append(multi_polylines)\n",
    "    if len(multi_polylines_list) > 0:\n",
    "        multi_polylines_list = torch.cat(multi_polylines_list, dim=0)\n",
    "    else:\n",
    "        multi_polylines_list = None\n",
    "    return multi_polylines_list\n",
    "\n",
    "def tokenize_map(data):\n",
    "    data['map_polygon']['type'] = data['map_polygon']['type'].to(torch.uint8)\n",
    "    data['map_point']['type'] = data['map_point']['type'].to(torch.uint8)\n",
    "    pt2pl = data[('map_point', 'to', 'map_polygon')]['edge_index']\n",
    "    pt_type = data['map_point']['type'].to(torch.uint8)\n",
    "    pt_side = torch.zeros_like(pt_type)\n",
    "    pt_pos = data['map_point']['position'][:, :2]\n",
    "    data['map_point']['orientation'] = wrap_angle(data['map_point']['orientation'])\n",
    "    pt_heading = data['map_point']['orientation']\n",
    "    split_polyline_type = []\n",
    "    split_polyline_pos = []\n",
    "    split_polyline_theta = []\n",
    "    split_polyline_side = []\n",
    "    pl_idx_list = []\n",
    "    split_polygon_type = []\n",
    "    data['map_point']['type'].unique()\n",
    "\n",
    "    # 对多段线进行便利\n",
    "    for i in sorted(np.unique(pt2pl[1])):\n",
    "        # 每一条多段线对应的点\n",
    "        index = pt2pl[0, pt2pl[1] == i]\n",
    "        polygon_type = data['map_polygon'][\"type\"][i]\n",
    "        cur_side = pt_side[index]\n",
    "        cur_type = pt_type[index]\n",
    "        cur_pos = pt_pos[index]\n",
    "        cur_heading = pt_heading[index]\n",
    "\n",
    "        for side_val in np.unique(cur_side):\n",
    "            for type_val in np.unique(cur_type):\n",
    "                if type_val == 13:\n",
    "                    continue\n",
    "                indices = np.where((cur_side == side_val) & (cur_type == type_val))[0]\n",
    "                if len(indices) <= 2:\n",
    "                    continue\n",
    "                split_polyline = interplating_polyline(cur_pos[indices].numpy(), cur_heading[indices].numpy())\n",
    "                if split_polyline is None:\n",
    "                    continue\n",
    "                new_cur_type = cur_type[indices][0]\n",
    "                new_cur_side = cur_side[indices][0]\n",
    "                map_polygon_type = polygon_type.repeat(split_polyline.shape[0])\n",
    "                new_cur_type = new_cur_type.repeat(split_polyline.shape[0])\n",
    "                new_cur_side = new_cur_side.repeat(split_polyline.shape[0])\n",
    "                cur_pl_idx = torch.Tensor([i])\n",
    "                new_cur_pl_idx = cur_pl_idx.repeat(split_polyline.shape[0])\n",
    "                split_polyline_pos.append(split_polyline[..., :2])\n",
    "                split_polyline_theta.append(split_polyline[..., 2])\n",
    "                split_polyline_type.append(new_cur_type)\n",
    "                split_polyline_side.append(new_cur_side)\n",
    "                pl_idx_list.append(new_cur_pl_idx)\n",
    "                split_polygon_type.append(map_polygon_type)\n",
    "\n",
    "    split_polyline_pos = torch.cat(split_polyline_pos, dim=0)\n",
    "    split_polyline_theta = torch.cat(split_polyline_theta, dim=0)\n",
    "    split_polyline_type = torch.cat(split_polyline_type, dim=0)\n",
    "    split_polyline_side = torch.cat(split_polyline_side, dim=0)\n",
    "    split_polygon_type = torch.cat(split_polygon_type, dim=0)\n",
    "    pl_idx_list = torch.cat(pl_idx_list, dim=0)\n",
    "    vec = split_polyline_pos[:, 1, :] - split_polyline_pos[:, 0, :]\n",
    "    data['map_save'] = {}\n",
    "    data['pt_token'] = {}\n",
    "    data['map_save']['traj_pos'] = split_polyline_pos\n",
    "    data['map_save']['traj_theta'] = split_polyline_theta[:, 0]  # torch.arctan2(vec[:, 1], vec[:, 0])\n",
    "    data['map_save']['pl_idx_list'] = pl_idx_list\n",
    "    data['pt_token']['type'] = split_polyline_type\n",
    "    data['pt_token']['side'] = split_polyline_side\n",
    "    data['pt_token']['pl_type'] = split_polygon_type\n",
    "    data['pt_token']['num_nodes'] = split_polyline_pos.shape[0]\n",
    "    return data\n",
    "\n",
    "token_data = tokenize_map(token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del token_data['city']\n",
    "if 'polygon_is_intersection' in token_data['map_polygon']:\n",
    "    print(\"delete polygon_is_intersection\")\n",
    "    del token_data['map_polygon']['polygon_is_intersection']\n",
    "if 'route_type' in data['map_polygon']:\n",
    "    print(\"delete route_type\")\n",
    "    del token_data['map_polygon']['route_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 将字典转换成HeteroData类型数据\n",
    "\n",
    "通过dataloader加载数据时，会在批处理时自动添加batch和ptr字段\n",
    "\n",
    "+ `batch` 字段：表示每个节点或边属于哪个样本。对于每个节点（或边），batch 中的值表示该节点所属样本的索引。\n",
    "\n",
    "+ `ptr` 字段：用于记录每个样本的起始索引。这在生成批次时对边的连接（例如跨图连接）很有帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CustomHeteroDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(CustomHeteroDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        batch_data = HeteroData()\n",
    "\n",
    "        for node_type, node_data in self.data_list[idx].items():\n",
    "            if isinstance(node_type, str):  # 处理节点数据\n",
    "                if isinstance(node_data, dict):\n",
    "                    for attr, value in node_data.items():\n",
    "                        batch_data[node_type][attr] = value\n",
    "                else:\n",
    "                    batch_data[node_type] = [node_data]\n",
    "\n",
    "        for edge_type, edge_data in self.data_list[idx].items():\n",
    "            if isinstance(edge_type, tuple) and len(edge_type) == 3:  # 处理边数据\n",
    "                if isinstance(edge_data, dict):\n",
    "                    for attr, value in edge_data.items():\n",
    "                        batch_data[edge_type][attr] = value\n",
    "                else:\n",
    "                    batch_data[edge_type] = edge_data\n",
    "        return batch_data\n",
    "\n",
    "dataset = CustomHeteroDataset([token_data])\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "batch = next(iter(loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 模型内部匹配地图token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data**\n",
    "\n",
    "+ `scenario_id`: *str*, 场景id\n",
    "\n",
    "+ `agent`: *dict*, 场景中的代理信息\n",
    "\n",
    "  - `num_nodes`: *int*, 代理数量\n",
    "\n",
    "  - `av_index`: *int*, AV对应的代理编号\n",
    "\n",
    "  - `valid_mask`: *array([NA, NT])*, 各代理各时间步是否有效\n",
    "\n",
    "  - `predict_mask`: *array([NA, NT])*, 各代理需要被预测的时间步\n",
    "\n",
    "  - `id`: *list([NA])*, 代理ID \n",
    "\n",
    "  - `type`: *array([NA])*, 代理类型\n",
    "\n",
    "    > 0 'vehicle', 1 'pedestrian', 2 'cyclist', 3 'background'\n",
    "\n",
    "  - `category`: *array([NA])*, 代理类别\n",
    "\n",
    "    > 1 其他代理, 2 感兴趣代理, 3 被预测代理\n",
    "\n",
    "  - `position`: *array([NA, NT, 3])*, 代理位置 (x, y, z)\n",
    "\n",
    "  - `heading`: *array([NA, NT])*, 代理航向\n",
    "\n",
    "  - `velocity`: *array([NA, NT, 3])*, 代理速度 (vx, vy, 0)\n",
    "\n",
    "  - `shape`: *array([NA, NT, 3])*, 代理尺寸 (length, width, height)\n",
    "\n",
    "  - `token_idx`: *array([NA, 18])*, 每个代理在90帧中匹配到的18个token索引(5帧为间隔,18=90/5)\n",
    "\n",
    "  - `token_contour`: *array([NA, 18, 4, 2])*, 每个代理在90帧中匹配到的18个token对应的矩形信息\n",
    "\n",
    "  - `token_pos`: *array([NA, 18, 2])*, 每个代理在90帧中匹配到的18个token对应的矩形中心点全局坐标\n",
    "\n",
    "  - `token_heading`: *array([NA, 18])*, 每个代理在90帧中匹配到的18个token处对应的全局航向角\n",
    "\n",
    "  - `token_velocity`: *array([NA, 18, 2])*, 每个代理在90帧中匹配到的18个token处的速度(vx, vy)\n",
    "\n",
    "  - `agent_valid_mask`: *array([NA, 18])*, 每个代理在90帧中匹配到的18个token是否有效\n",
    "\n",
    "+ `map_save`: *dict*, 将多段线按5米进行拆分，多段线内点间距为2.5米重新存图\n",
    "\n",
    "  - `traj_pos`: *array([n_polyline, 3, 2])*, [多段线数量, 每个多段线中有3个点，点坐标xy]\n",
    "\n",
    "  - `traj_theta`: *array([n_polyline])*, 各多段线的朝向（起始段朝向作为代表）\n",
    "  \n",
    "  - `pl_idx_list`: *array([n_polyline])*, 划分后的多段线对应在划分前多段线的索引\n",
    "\n",
    "+ `pt_token`: *dict*, \n",
    "\n",
    "  - `type`: *array([n_polyline])*, 多段线中点的类型\n",
    "\n",
    "    > [ 'DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "    > 'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "    > 'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "    > 'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "\n",
    "  - `side`: *array([n_polyline])*, 多段线在道路哪一侧\n",
    "\n",
    "    > 0: left_side, 1: right_side, 2: center_side\n",
    "\n",
    "  - `pl_type`: *array([n_polyline])*, 多段线类型\n",
    "\n",
    "    > ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "\n",
    "  - `num_nodes`: *int*, 划分后多段线数量\n",
    "\n",
    "  - `position`: *array([n_polyline, 3])*, 各地图多段线的起始点坐标 x,y,z(z=0)\n",
    "\n",
    "  - `orientation`: *array([n_polyline])*, 各地图多段线的起始位置朝向（相对于正 x 轴的弧度值，范围为 [-π, π]）\n",
    "\n",
    "  - `height`: *array([n_polyline])*, 各地图多段线的起始点高度(0)\n",
    "\n",
    "  - `token_idx`: *array([n_polyline])*, 根据map_save['traj_pos']匹配到的地图token索引\n",
    "\n",
    "  - `traj_mask`: *array([n_map_poly, 3, max_token_num])*, 记录每个原始地图多段线在左侧、右侧、中心的轨迹掩码（针对每条多段线，从 0到该条多段线的token数 的下标区间为true，其余为false）\n",
    "\n",
    "  - `pt_valid_mask`: *array([n_polyline])*, 基于traj_mask，从每个原始多段线中随机选取1/3的traj值作为被预测对象掩码掉（置为false）\n",
    "\n",
    "  - `pt_pred_mask`: *array([n_polyline])*, 记录需要预测下一个地图token的索引（哪些点是需要预测的轨迹点）\n",
    "\n",
    "  - `pt_target_mask`: *array([n_polyline])*, 记录真实的下一个地图token的索引\n",
    "\n",
    "+ `map_polygon`: *dict*, 地图中多段线信息\n",
    "\n",
    "  - `num_nodes`: *int*, 多段线数量\n",
    "\n",
    "  - `type`: *array([num_nodes])*, 每条多段线对应的类型\n",
    "\n",
    "    > ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "\n",
    "  - `light_type`: *array([num_nodes])*, 每条多段线对应的交通信号状态\n",
    "\n",
    "    > ['LANE_STATE_STOP', 'LANE_STATE_GO', 'LANE_STATE_CAUTION', 'LANE_STATE_UNKNOWN']\n",
    "\n",
    "+ `map_point`: *dict*, 地图中各点信息\n",
    "\n",
    "  - `num_nodes`: *int*, 点数量\n",
    "\n",
    "  - `position`: *array([num_nodes, 3])*, 点的坐标(x, y, z)\n",
    "\n",
    "  - `orientation`: *array([num_nodes])*, 各点对应向量的方向角（以弧度表示）\n",
    "\n",
    "  - `magnitude`: *array([num_nodes])*, 各点对应向量的大小（即距离）\n",
    "\n",
    "  - `height`: *array([num_nodes])*, 各点与下一点之间的高度差 *(dim=3时才存在)*\n",
    "\n",
    "  - `type`: *array([num_nodes])*, 各点所属类型\n",
    "\n",
    "    > [ 'DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "    > 'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "    > 'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "    > 'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "\n",
    "+ `'map_point', 'to', 'map_polygon'`: *dict*, 点与多段线之间的索引映射关系\n",
    "\n",
    "  - `edge_index`: *array([2, num_points])*, [point_idx, polygon_idx]\n",
    "\n",
    "+ `'map_polygon', 'to', 'map_polygon'`: *dict*, 车道与车道之间的拓扑关系\n",
    "\n",
    "  - `edge_index`: *array([2, num_edges])*, [polygon1_idx, polygon2_idx]\n",
    "\n",
    "  - `type`: *array([num_edges])*, 拓扑关系类型-polygon1是polygon2的前驱/后继/左邻居/右邻居\n",
    "\n",
    "    > ['NONE', 'PRED', 'SUCC', 'LEFT', 'RIGHT']\n",
    "\n",
    "+ `'pt_token', 'to', 'map_polygon'`: *dict*, pt_token['token_idx']与原多段线之间的索引映射关系\n",
    "\n",
    "  - `edge_index`: *array([2, n_polyline])*, [token_idx, polygon_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 加载轨迹token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**agent_token_data**\n",
    "\n",
    "聚类得到的token信息，即以[0,0]为第一帧中心坐标，五帧为时间间隔到达的终点位置\n",
    "\n",
    "+ `token`: *dict*, 每个token对应的终点位置矩形的四个角点坐标(x, y)，**角点顺序为-左前、右前、右后、左后**\n",
    "    - `veh`: *array([2048, 4, 2])*\n",
    "    - `ped`: *array([2048, 4, 2])*\n",
    "    - `cyc`: *array([2048, 4, 2])*\n",
    "+ `traj`: *dict*, 每个token对应的6帧完整轨迹中心坐标 (x, y ,z)\n",
    "    - `veh`: *array([2048, 6, 3])*\n",
    "    - `ped`: *array([2048, 6, 3])*\n",
    "    - `cyc`: *array([2048, 6, 3])*\n",
    "+ `token_all`: *dict*, 每个token对应的6帧完整轨迹各处矩形四个角点坐标\n",
    "    - `veh`: *array([2048, 6, 4, 2])*\n",
    "    - `ped`: *array([2048, 6, 4, 2])*\n",
    "    - `cyc`: *array([2048, 6, 4, 2])*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_token_path = \"/home/yangyh408/codes/SMART/smart/tokens/cluster_frame_5_2048.pkl\"\n",
    "agent_token_data = pickle.load(open(agent_token_path, 'rb'))\n",
    "trajectory_token = agent_token_data['token']\n",
    "trajectory_token_traj = agent_token_data['traj']\n",
    "trajectory_token_all = agent_token_data['token_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 加载地图token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map_token_data**\n",
    "\n",
    "聚类得到的地图token信息，即以[0,0]为初始位置，连续11个点的坐标\n",
    "\n",
    "+ `traj_src`: *array([1024, 11, 2])*, 每个地图token对应的多段线信息，即11个点的xy坐标\n",
    "+ `sample_pt`: *array([1024, 3, 2])*, 对地图token的多段线信息进行采样，仅保留索引为[0, 5, 10]的三个点信息\n",
    "+ `traj_end_theta`: *array([1024])*, 根据traj_src计算各地图token在最后一个位置处的朝向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin_sample_len = 3\n",
    "\n",
    "map_token_traj_path = \"/home/yangyh408/codes/SMART/smart/tokens/map_traj_token5.pkl\"\n",
    "map_token_traj = pickle.load(open(map_token_traj_path, 'rb'))\n",
    "\n",
    "map_token = {'traj_src': map_token_traj['traj_src'], }\n",
    "traj_end_theta = np.arctan2(map_token['traj_src'][:, -1, 1]-map_token['traj_src'][:, -2, 1],\n",
    "                            map_token['traj_src'][:, -1, 0]-map_token['traj_src'][:, -2, 0])\n",
    "# 生成从 start 到 end 的 steps 个等间隔值。\n",
    "indices = torch.linspace(0, map_token['traj_src'].shape[1]-1, steps=argmin_sample_len).long()\n",
    "map_token['sample_pt'] = torch.from_numpy(map_token['traj_src'][:, indices]).to(torch.float)\n",
    "map_token['traj_end_theta'] = torch.from_numpy(traj_end_theta).to(torch.float)\n",
    "map_token['traj_src'] = torch.from_numpy(map_token['traj_src']).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 匹配地图token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_token_map(data):\n",
    "    traj_pos = data['map_save']['traj_pos'].to(torch.float)\n",
    "    traj_theta = data['map_save']['traj_theta'].to(torch.float)\n",
    "    pl_idx_list = data['map_save']['pl_idx_list']\n",
    "    token_sample_pt = map_token['sample_pt'].to(traj_pos.device)\n",
    "    token_src = map_token['traj_src'].to(traj_pos.device)\n",
    "    max_traj_len = map_token['traj_src'].shape[1]\n",
    "    pl_num = traj_pos.shape[0]\n",
    "\n",
    "    # 各地图多段线的起始点坐标xy\n",
    "    pt_token_pos = traj_pos[:, 0, :].clone()\n",
    "    # 各地图多段线的起始位置朝向\n",
    "    pt_token_orientation = traj_theta.clone()\n",
    "    # 将地图多段线由全局坐标系转换为局部坐标系\n",
    "    cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "    rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "    rot_mat[..., 0, 0] = cos\n",
    "    rot_mat[..., 0, 1] = -sin\n",
    "    rot_mat[..., 1, 0] = sin\n",
    "    rot_mat[..., 1, 1] = cos\n",
    "    traj_pos_local = torch.bmm((traj_pos - traj_pos[:, 0:1]), rot_mat.view(-1, 2, 2))\n",
    "    # 将坐标转换后的多段线与地图map_token进行匹配\n",
    "    distance = torch.sum((token_sample_pt[None] - traj_pos_local.unsqueeze(1))**2, dim=(-2, -1))\n",
    "    pt_token_id = torch.argmin(distance, dim=1)\n",
    "\n",
    "    if noise:\n",
    "        topk_indices = torch.argsort(torch.sum((token_sample_pt[None] - traj_pos_local.unsqueeze(1))**2, dim=(-2, -1)), dim=1)[:, :8]\n",
    "        sample_topk = torch.randint(0, topk_indices.shape[-1], size=(topk_indices.shape[0], 1), device=topk_indices.device)\n",
    "        pt_token_id = torch.gather(topk_indices, 1, sample_topk).squeeze(-1)\n",
    "\n",
    "    cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "    rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "    rot_mat[..., 0, 0] = cos\n",
    "    rot_mat[..., 0, 1] = sin\n",
    "    rot_mat[..., 1, 0] = -sin\n",
    "    rot_mat[..., 1, 1] = cos\n",
    "    token_src_world = torch.bmm(token_src[None, ...].repeat(pl_num, 1, 1, 1).reshape(pl_num, -1, 2),\n",
    "                                rot_mat.view(-1, 2, 2)).reshape(pl_num, token_src.shape[0], max_traj_len, 2) + traj_pos[:, None, [0], :]\n",
    "    token_src_world_select = token_src_world.view(-1, 1024, 11, 2)[torch.arange(pt_token_id.view(-1).shape[0]), pt_token_id.view(-1)].view(pl_num, max_traj_len, 2)\n",
    "\n",
    "    pl_idx_full = pl_idx_list.clone()\n",
    "    token2pl = torch.stack([torch.arange(len(pl_idx_list), device=traj_pos.device), pl_idx_full.long()])\n",
    "    count_nums = []\n",
    "    for pl in pl_idx_full.unique():\n",
    "        pt = token2pl[0, token2pl[1, :] == pl]\n",
    "        left_side = (data['pt_token']['side'][pt] == 0).sum()\n",
    "        right_side = (data['pt_token']['side'][pt] == 1).sum()\n",
    "        center_side = (data['pt_token']['side'][pt] == 2).sum()\n",
    "        count_nums.append(torch.Tensor([left_side, right_side, center_side]))\n",
    "    # count_nums: [N_polyline, 3]分别记录每个原始多段线对应的左侧、右侧、中心token有多少\n",
    "    count_nums = torch.stack(count_nums, dim=0)\n",
    "    # 获取每个原始多段线对应的最多token数量\n",
    "    max_token_num = int(count_nums.max().item())\n",
    "    # 构建多段线的轨迹掩码 [N_polyline, 3, max_token_num]\n",
    "    traj_mask = torch.zeros((int(len(pl_idx_full.unique())), 3, max_token_num), dtype=bool)\n",
    "    idx_matrix = torch.arange(traj_mask.size(2)).unsqueeze(0).unsqueeze(0)\n",
    "    idx_matrix = idx_matrix.expand(traj_mask.size(0), traj_mask.size(1), -1)    #[N_polyline, 3, max_token_num]\n",
    "    counts_num_expanded = count_nums.unsqueeze(-1)                              #[N_polyline, 3, 1]\n",
    "    traj_mask[idx_matrix < counts_num_expanded] = True\n",
    "\n",
    "    data['pt_token']['traj_mask'] = traj_mask\n",
    "    data['pt_token']['position'] = torch.cat([pt_token_pos, torch.zeros((data['pt_token']['num_nodes'], 1),\n",
    "                                                                        device=traj_pos.device, dtype=torch.float)], dim=-1)\n",
    "    data['pt_token']['orientation'] = pt_token_orientation\n",
    "    data['pt_token']['height'] = data['pt_token']['position'][:, -1]\n",
    "    data[('pt_token', 'to', 'map_polygon')] = {}\n",
    "    data[('pt_token', 'to', 'map_polygon')]['edge_index'] = token2pl\n",
    "    data['pt_token']['token_idx'] = pt_token_id\n",
    "    return data\n",
    "\n",
    "batch = match_token_map(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 随机生成地图token预测掩码信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pt_pred(data):\n",
    "    # traj_mask: [n_map_poly, 3, max_token_num]\n",
    "    traj_mask = data['pt_token']['traj_mask']\n",
    "    # 从每个原始多段线中随机选取1/3的traj值被掩码掉\n",
    "    raw_pt_index = torch.arange(1, traj_mask.shape[2]).repeat(traj_mask.shape[0], traj_mask.shape[1], 1)\n",
    "    masked_pt_index = raw_pt_index.view(-1)[torch.randperm(raw_pt_index.numel())[:traj_mask.shape[0]*traj_mask.shape[1]*((traj_mask.shape[2]-1)//3)].reshape(traj_mask.shape[0], traj_mask.shape[1], (traj_mask.shape[2]-1)//3)]\n",
    "    masked_pt_index = torch.sort(masked_pt_index, -1)[0]\n",
    "    # 有效掩码\n",
    "    pt_valid_mask = traj_mask.clone()\n",
    "    pt_valid_mask.scatter_(2, masked_pt_index, False)\n",
    "    # 预测掩码\n",
    "    pt_pred_mask = traj_mask.clone()\n",
    "    pt_pred_mask.scatter_(2, masked_pt_index, False)\n",
    "    tmp_mask = pt_pred_mask.clone()\n",
    "    tmp_mask[:, :, :] = True\n",
    "    tmp_mask.scatter_(2, masked_pt_index-1, False)\n",
    "    pt_pred_mask.masked_fill_(tmp_mask, False)\n",
    "    pt_pred_mask = pt_pred_mask * torch.roll(traj_mask, shifts=-1, dims=2)\n",
    "    # 目标掩码\n",
    "    pt_target_mask = torch.roll(pt_pred_mask, shifts=1, dims=2)\n",
    "    # 通过traj_mask将生成的掩码向量从[n_map_poly, 3, max_token_num]转换为[n_polyline]的形式，使其与token信息对应\n",
    "    data['pt_token']['pt_valid_mask'] = pt_valid_mask[traj_mask]\n",
    "    data['pt_token']['pt_pred_mask'] = pt_pred_mask[traj_mask]\n",
    "    data['pt_token']['pt_target_mask'] = pt_target_mask[traj_mask]\n",
    "\n",
    "    return data\n",
    "\n",
    "batch = sample_pt_pred(batch)\n",
    "batch['agent']['av_index'] += batch['agent']['ptr'][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 使用batch数据进行模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 23:44:08,730-INFO-smart.py-Line:222-Message:==> Loading parameters from checkpoint ../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt to GPU\n",
      "2024-11-17 23:44:09,189-INFO-smart.py-Line:231-Message:The number of disk ckpt keys: 818\n",
      "2024-11-17 23:44:09,296-INFO-smart.py-Line:247-Message:Missing keys: []\n",
      "2024-11-17 23:44:09,297-INFO-smart.py-Line:248-Message:The number of missing keys: 0\n",
      "2024-11-17 23:44:09,298-INFO-smart.py-Line:249-Message:The number of unexpected keys: 0\n",
      "2024-11-17 23:44:09,298-INFO-smart.py-Line:250-Message:==> Done (total keys 818)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x_pt': tensor([[-2.8628,  0.7293, -7.0975,  ...,  1.2902,  2.5426,  1.9984],\n",
       "         [-2.6509,  0.5438, -7.2383,  ...,  1.6891,  2.8929,  1.8436],\n",
       "         [-2.1915,  0.7175, -8.1312,  ...,  2.0025,  2.2056,  1.7226],\n",
       "         ...,\n",
       "         [ 4.0198, -2.7484, -5.1329,  ...,  4.4264,  3.8843,  2.2978],\n",
       "         [ 3.1914, -2.2112, -6.0598,  ...,  4.0475,  4.3945,  3.8649],\n",
       "         [ 5.0166, -2.0447, -5.4248,  ...,  3.6456,  4.0969,  3.7391]]),\n",
       " 'map_next_token_idx': tensor([[218, 166, 444,  ..., 908, 630, 487],\n",
       "         [218, 166, 444,  ..., 128, 362,  52],\n",
       "         [933, 218, 603,  ..., 630, 555,  35],\n",
       "         ...,\n",
       "         [613, 871, 873,  ..., 311, 659,  25],\n",
       "         [873, 954, 533,  ..., 659, 603, 123],\n",
       "         [267, 633, 494,  ..., 867, 873, 365]]),\n",
       " 'map_next_token_prob': tensor([[-8.8503e-02,  2.6148e-02,  2.8189e-01,  ...,  1.3059e-01,\n",
       "          -7.5653e-02, -2.6913e-01],\n",
       "         [-3.1502e-02,  3.2731e-02,  3.2199e-01,  ...,  7.6186e-02,\n",
       "          -1.1064e-01, -2.7430e-01],\n",
       "         [-7.5053e-02, -1.0026e-01,  3.7497e-01,  ...,  4.6723e-01,\n",
       "          -1.4110e-01, -3.7315e-01],\n",
       "         ...,\n",
       "         [-1.2690e-01,  5.8139e-02, -7.3275e-02,  ..., -1.3868e-01,\n",
       "          -9.8813e-02,  2.1049e-01],\n",
       "         [-1.2039e-02,  2.7022e-01,  1.7296e-01,  ..., -2.2214e-01,\n",
       "          -8.2641e-02,  7.8307e-02],\n",
       "         [ 1.4311e-04,  2.5294e-01, -5.1187e-04,  ..., -2.2156e-01,\n",
       "           1.3887e-02,  2.9255e-01]]),\n",
       " 'map_next_token_idx_gt': tensor([   2,  473,  626,  886,  116,  642,  630,  362,  283,   38,  561,  191,\n",
       "          109,  904,   14,  644,   96,   30,  230,  432,  687,  259,  367,   58,\n",
       "          230,  626,   52,  473,   52,  230,    2,  583,  230,   52,    2,   30,\n",
       "           26,  184,  726,  935,  548,  531,   33,   89,   30,   33,   52,  626,\n",
       "          626,   14,  626,  230,  345,   80,    4,   61,  473,  687,   33,  367,\n",
       "          626,  751,  223,  361,   33,  385,  408,  198,  747,  108,  305,  953,\n",
       "          514,  473,   14,  626,  386,  680,  268,  216,  326,   52,  189,  230,\n",
       "          187,  389,  903,  544,  230,  971,   52,   26,  230,  955,   30,   30,\n",
       "          473,   58,  473,   52,  473,  223,  739,   52,  189,  504,   66,  230,\n",
       "          944,    2,  687,   77,    3,  245,   77,  213,  358,  379,  709,  902,\n",
       "           35, 1005,   94,  731,   47,  280,  326,  541,  251,  717,  493,  905,\n",
       "          547,   52,  687,  469,  387,  355,  213,   33,  992,  473,   30,  687,\n",
       "            0,    2,  230,   52,  421,    2,  230,  687,  687,  230,   14,   12,\n",
       "          213,  687,   14,   14,  280,  311,  109,   58,  583,  923,  155,  331,\n",
       "          992,  230,   30,   12,  646,   52,   12,   33,  473,  196,  300,  601,\n",
       "          134,  321,  561,  458,  473,  473,  367,   33,  230,  908,  687,  473,\n",
       "          758,    4,   12,  230,  626,  213,  473,   52,  542,  230,  230,  336,\n",
       "          687,  287,  473,   30,  473,    2,  213,   58,  230,   30,    2,   58,\n",
       "          696,  777,  172,  561,  764,  601,   86,   30,  367,   33,  189,   57,\n",
       "          421,  450,  973,   33,  275,   30,   30,  473,  213,  473,  230,  444,\n",
       "          634,  230,  156,  680,  424,    2,  626,  912,  230,  230,  287,  473,\n",
       "          287,  230,  213,   33,  542,  230,   33,  781,  251,  948,  542,  213,\n",
       "           89,  473,  213,    2,  421,  667,  203,  955,  709,   30,  386,   52,\n",
       "          881,  191,  295,  632,  857,  944,  810,  561,  230,    2,  944,  368,\n",
       "          775,  494,   50,   61,  904,    2,   52,  473,  678,  469,   52,  469,\n",
       "          997,  626,  240,  359,  213,  626,  485,  893,   30,   30,  667,  626,\n",
       "           27,    2,    2,  785,  745,  469,  473,    4,   15,  964,  778,  512,\n",
       "           87,   87,  642,  613,  944,  213,  213,    2,   52,  485,  223,   66,\n",
       "          207,  123,   52,  973,  223,  213,  223,  367,  481,   61,  983,  287,\n",
       "          155,  213, 1020,  473,  473,  473,  626,  104,  213,  444,   52,   33,\n",
       "          687,  213,  444,  230,  230,   52,  407,  223,   52,    2,    2,  473,\n",
       "            2,  473,  248,  473,  626,   30,  367,  230,   52,  680,  788,  944,\n",
       "            2,   33,  473,  538,   30,  687,   52,   33,  837,  658,  905,  136,\n",
       "          696,  329,  610,  126,  204,  906,  687,   30,  687,  558,  544,  687,\n",
       "          381,  473,  230,  473,   14,  687,  473,  687,   33,  955,  230,  238,\n",
       "           33,  473,    2,  687,  819,  114,  667,  490,  967,  472,  880,  826,\n",
       "          566,  248,  973,  280,  239,  687,  644,  295,  404,  849,  230,  423,\n",
       "          230,   33,  687,   52,    2,  336,  230,  997,  307,  312,  933,  102,\n",
       "          319,  636,  455,  687,  141,  189,  657,  573,  178,  702,  904,  759,\n",
       "          223,  141, 1002,  156,  561,  373,  230,  453, 1002,   71,  944,  123,\n",
       "          409,  874,   27,    2,    2,   36,   33,   58,  423,  248,  817,   23,\n",
       "          243,  879,  693,  554,  544,  992,  591,  944,  982,  602,  238, 1001,\n",
       "           53,  230,   33,   52,   71,    2,  223,  960,   82,  582,  240,  557,\n",
       "          216,  200,  471,  997,  687,  119,  270,  325,  526,  573,  230,  230,\n",
       "          249,  904,  626,  933,  801,   47,   71,  179,  626,  213,   33,   33,\n",
       "           14,  434,  539,  887,  213,  123,  656,  680,  612,  119,  230,    2,\n",
       "           97,  720,  532,  838,  208,  732,  651,  196,   58,  997,  686,  310,\n",
       "          808,  207,  626,  473,    2,  626,  752,   66,   33,  213,  626,   58,\n",
       "          189,  341,  687,    2,  281,   80,  530,  162, 1002,  322,  840,   66,\n",
       "          373,  355,  277,  667,  281,  626,  248,  923,  473,  473,  626,  838,\n",
       "          213,  290,  409,   12,   30,  663,  970,   35,  923,  762,  385,  514,\n",
       "          544,  997,  481,  423,   52,  687,  473,  532,  959,  946,  213,    9,\n",
       "          217,  626,   20,  434,  230,  379,  233,  155,   75,  702,   71,   14,\n",
       "          207,  295,  838,  644,  230,  155,  273,   58,  717,    2,  104,  687,\n",
       "           58,   14,  667,  759,  473,  277,  687,    2,  230,  425,  287,   52,\n",
       "           93,    2,  189,  473, 1002,  230,  626,  295,  373,   14,  473,  421,\n",
       "          626,  687,  347,  680,  863,  563,  838,   52,  717, 1002,   33,  213,\n",
       "          702,  248,  845,  373,  893,  157,  399,  230,  997,   75,    2,   52,\n",
       "          750, 1020,  836,  579,   30,  973,  473,   14,    2,   33,  973,  230,\n",
       "          473,  473,  189,  473,  687,  207,  687,    2,  687,  213,    2,   61,\n",
       "          248,   30,   14,   58,  295,   30,    2,  230,   17,  687,  473,  432,\n",
       "          473,  167,   52,  230,   58,   52,  626,  473,  230,  207,   52,    2,\n",
       "          213,   58,  230,   28,  702,  213,  324,  473,  662,  230,   33,   52,\n",
       "            2,    2,    2,  230,    2,   30,  213,    2,  687,  230,  687,  473,\n",
       "          687,  473,  473,    2,   52,  213,   52,  213,  230,  230,  213,  702,\n",
       "          213,  657,  230,  230,  213,   52,  275,  303,   52,  230,  230,   32,\n",
       "          189,  777,   52,  473,   58,  626,   52,   58,   33,  687,  230,   30,\n",
       "          687,    2,  473,  261,   30,  473,   30,  345,   33,  230,    2,    2,\n",
       "          367,  687,  230,  687,   58,  248,  702,    2,  626,  473,  473,  626,\n",
       "          646,  223,   30,   12,  473,  626,  626,  123,  230,   33,  626,  230,\n",
       "           66,   73,   12,  712,    2,   14,  213,    2,   52,   52,    4,   52,\n",
       "           52,   58,  403,   52,  223,    2,  230,    2,   58,   58,  230,   12,\n",
       "           52,   33,   52,  626,  230,  213,   58,   12,  213,   52,   10,  303,\n",
       "          213,   53,  213,   33,   33,  230,   30,  687,  973,  626,   33,  473,\n",
       "          644,  469]),\n",
       " 'map_next_token_eval_mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True]),\n",
       " 'pos_a': tensor([[[3307.0730, 1544.0892],\n",
       "          [3310.4839, 1544.1665],\n",
       "          [3313.5837, 1544.1941],\n",
       "          ...,\n",
       "          [3326.9619, 1544.2662],\n",
       "          [3326.9749, 1544.2548],\n",
       "          [3326.9871, 1544.2889]],\n",
       " \n",
       "         [[3308.1113, 1601.2019],\n",
       "          [3308.0762, 1601.2113],\n",
       "          [3308.0864, 1601.2252],\n",
       "          ...,\n",
       "          [3308.0627, 1601.1914],\n",
       "          [3308.0730, 1601.2053],\n",
       "          [3308.0835, 1601.2192]],\n",
       " \n",
       "         [[3398.1506, 1541.0852],\n",
       "          [3404.2886, 1541.1219],\n",
       "          [3410.6790, 1541.1744],\n",
       "          ...,\n",
       "          [3497.4365, 1540.8700],\n",
       "          [3506.3198, 1540.6407],\n",
       "          [3515.3081, 1540.3412]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3360.7339, 1524.0161],\n",
       "          [3360.7456, 1524.0291],\n",
       "          [3360.7117, 1524.0420],\n",
       "          ...,\n",
       "          [3360.6025, 1526.6732],\n",
       "          [3360.5820, 1528.9242],\n",
       "          [3360.5435, 1531.9122]],\n",
       " \n",
       "         [[3348.7053, 1606.7520],\n",
       "          [3348.6970, 1605.3403],\n",
       "          [3348.7102, 1604.2474],\n",
       "          ...,\n",
       "          [3348.6184, 1586.3444],\n",
       "          [3348.6670, 1582.1313],\n",
       "          [3348.7100, 1577.4513]],\n",
       " \n",
       "         [[3344.8635, 1577.4205],\n",
       "          [3344.8826, 1576.2123],\n",
       "          [3344.9065, 1574.5283],\n",
       "          ...,\n",
       "          [3344.9363, 1518.8314],\n",
       "          [3344.9355, 1510.9137],\n",
       "          [3344.9636, 1502.6626]]]),\n",
       " 'head_a': tensor([[ 2.4264e-02,  2.2662e-02,  1.6328e-02,  4.3235e-03,  5.1625e-03,\n",
       "           1.1953e-02,  1.4140e-02,  2.1161e-02,  9.1808e-03,  8.7739e-03,\n",
       "           9.4351e-03,  6.1291e-03,  5.2136e-03,  4.3233e-03,  4.3741e-03,\n",
       "           1.7014e-02],\n",
       "         [ 1.6555e+00,  1.6682e+00,  1.6683e+00,  1.6661e+00,  1.6661e+00,\n",
       "           1.6661e+00,  1.6661e+00,  1.6640e+00,  1.6505e+00,  1.6483e+00,\n",
       "           1.6483e+00,  1.6484e+00,  1.6610e+00,  1.6588e+00,  1.6589e+00,\n",
       "           1.6589e+00],\n",
       "         [-5.9765e-03,  8.4688e-03,  4.5521e-03,  6.7903e-03,  6.6886e-03,\n",
       "          -5.4933e-03,  1.4547e-02,  7.6041e-03, -6.2817e-03,  2.1108e-03,\n",
       "          -1.0732e-02, -1.1063e-02, -1.6557e-02, -2.3221e-02, -2.6783e-02,\n",
       "          -3.4924e-02],\n",
       "         [ 3.2760e-02,  3.0573e-02,  7.9093e-03,  5.7222e-03,  1.8363e-02,\n",
       "           1.8388e-02,  1.8414e-02,  1.8439e-02,  1.6277e-02,  1.6302e-02,\n",
       "           1.6353e-02,  1.6404e-02,  1.4243e-02,  1.4267e-02,  1.4318e-02,\n",
       "           1.4370e-02],\n",
       "         [-3.1110e+00, -3.1245e+00, -3.1245e+00, -3.1266e+00, -3.1266e+00,\n",
       "          -3.1266e+00, -3.1265e+00, -3.1267e+00, -3.1289e+00, -3.1288e+00,\n",
       "          -3.1287e+00, -3.1287e+00, -3.1286e+00, -3.1286e+00, -3.1160e+00,\n",
       "          -3.1159e+00],\n",
       "         [-3.1350e+00, -3.1375e+00, -3.1382e+00, -3.1370e+00, -3.1374e+00,\n",
       "          -3.1367e+00,  3.1372e+00, -3.1382e+00, -3.1345e+00,  3.1409e+00,\n",
       "           3.1409e+00,  3.1410e+00,  3.1410e+00,  3.1411e+00,  3.1389e+00,\n",
       "           3.1367e+00],\n",
       "         [ 1.4833e+00,  1.4522e+00,  1.3681e+00,  1.2173e+00,  1.0082e+00,\n",
       "           7.0987e-01,  4.6162e-01,  2.0532e-01,  4.9636e-02,  1.3123e-02,\n",
       "          -2.5685e-03, -1.2537e-02, -1.3352e-02, -1.7981e-02, -9.5623e-03,\n",
       "          -1.1571e-02],\n",
       "         [ 1.0681e-02, -2.7974e-03, -2.7720e-03, -2.7211e-03,  1.8515e-02,\n",
       "          -4.1452e-03,  1.7091e-02,  1.6913e-02,  1.4751e-02, -7.9347e-03,\n",
       "          -7.9093e-03, -1.0071e-02, -1.0045e-02, -1.0020e-02, -9.9951e-03,\n",
       "           1.1241e-02],\n",
       "         [-3.1168e+00, -3.1042e+00, -3.1041e+00, -3.1063e+00, -3.1063e+00,\n",
       "          -3.1062e+00, -3.1062e+00, -3.1083e+00, -3.1218e+00, -3.1240e+00,\n",
       "          -3.1239e+00, -3.1239e+00, -3.1113e+00, -3.1134e+00, -3.1134e+00,\n",
       "          -3.1133e+00],\n",
       "         [-3.0858e+00, -3.1084e+00, -3.0958e+00, -3.0980e+00, -3.0979e+00,\n",
       "          -3.0979e+00, -3.0978e+00, -3.1000e+00, -3.1000e+00, -3.0873e+00,\n",
       "          -3.1100e+00, -3.1122e+00, -3.1122e+00, -3.0995e+00, -3.0995e+00,\n",
       "          -3.1016e+00],\n",
       "         [ 1.5593e+00,  1.5571e+00,  1.5572e+00,  1.5784e+00,  1.5783e+00,\n",
       "           1.5761e+00,  1.5761e+00,  1.5888e+00,  1.5888e+00,  1.5888e+00,\n",
       "           1.5753e+00,  1.5752e+00,  1.5743e+00,  1.5813e+00,  1.5819e+00,\n",
       "           1.5812e+00],\n",
       "         [ 3.7801e-02,  5.0451e-02,  5.0477e-02,  4.8287e-02,  4.8315e-02,\n",
       "           4.8363e-02,  4.8414e-02,  4.6225e-02,  3.2762e-02,  3.0573e-02,\n",
       "           3.0623e-02,  3.0674e-02,  4.3324e-02,  4.1160e-02,  4.1211e-02,\n",
       "           4.1261e-02],\n",
       "         [ 1.6183e+00,  1.6183e+00,  1.6162e+00,  1.6027e+00,  1.6027e+00,\n",
       "           1.6027e+00,  1.6239e+00,  1.6218e+00,  1.6216e+00,  1.6217e+00,\n",
       "           1.6195e+00,  1.6196e+00,  1.5969e+00,  1.6181e+00,  1.5955e+00,\n",
       "           1.6081e+00],\n",
       "         [-8.0679e-02, -8.2850e-02, -8.5021e-02, -8.4966e-02, -8.7137e-02,\n",
       "          -8.7112e-02, -8.7086e-02, -7.4457e-02, -7.4406e-02, -7.6569e-02,\n",
       "          -7.6522e-02, -7.6472e-02, -7.6417e-02, -7.6366e-02, -7.8537e-02,\n",
       "          -9.1991e-02],\n",
       "         [-3.1392e+00, -3.1399e+00, -3.1387e+00, -3.1407e+00, -3.1411e+00,\n",
       "           3.1402e+00,  3.1395e+00,  3.1405e+00, -3.1399e+00,  3.1410e+00,\n",
       "           3.1308e+00,  3.1379e+00, -3.1375e+00, -3.1377e+00, -3.1399e+00,\n",
       "           3.1411e+00],\n",
       "         [-1.2462e-02, -1.2436e-02,  2.0345e-04,  2.2888e-04,  2.5432e-04,\n",
       "          -1.9328e-03, -1.5412e-02, -1.5336e-02,  5.9002e-03,  5.9511e-03,\n",
       "          -7.5020e-03, -7.4261e-03, -7.4007e-03, -9.5882e-03, -2.3069e-02,\n",
       "          -2.5230e-02],\n",
       "         [-9.2432e-01, -2.7553e-01, -3.5723e-01, -4.1384e-01, -4.9564e-01,\n",
       "          -4.0991e-01, -3.2422e-01, -2.3858e-01, -1.5291e-01, -6.7202e-02,\n",
       "           1.8435e-02,  1.0419e-01, -1.2341e+00, -1.1484e+00, -1.2302e+00,\n",
       "          -1.1444e+00],\n",
       "         [-3.1117e+00, -3.1083e+00, -3.1074e+00, -3.1075e+00, -3.1088e+00,\n",
       "          -3.0984e+00, -3.0993e+00, -3.1018e+00, -3.0991e+00, -3.0958e+00,\n",
       "          -3.0961e+00, -3.0910e+00, -3.1098e+00, -3.1061e+00, -3.1087e+00,\n",
       "          -3.1091e+00],\n",
       "         [-1.5634e+00, -1.5635e+00, -1.5714e+00, -1.5713e+00, -1.5706e+00,\n",
       "          -1.5678e+00, -1.5712e+00, -1.5756e+00, -1.5725e+00, -1.5647e+00,\n",
       "          -1.5751e+00, -1.5707e+00, -1.5723e+00, -1.5739e+00, -1.5741e+00,\n",
       "          -1.5879e+00],\n",
       "         [-2.2075e-01, -1.4465e-01, -8.2364e-02, -4.2994e-02, -1.9125e-02,\n",
       "          -1.9355e-02, -2.2534e-02, -1.4115e-02,  8.1379e-04,  2.1871e-03,\n",
       "           4.4252e-03,  1.3530e-02,  1.3428e-02,  2.9810e-02,  2.8538e-02,\n",
       "           3.4619e-02],\n",
       "         [-1.9847e+00, -2.2011e+00, -2.4422e+00, -2.6856e+00, -2.8891e+00,\n",
       "          -3.0499e+00, -3.1407e+00,  3.1409e+00,  3.1242e+00,  3.1241e+00,\n",
       "           3.1352e+00,  3.1368e+00, -3.1204e+00, -3.1171e+00, -3.1149e+00,\n",
       "          -3.1083e+00],\n",
       "         [ 3.6808e-02,  5.8041e-02,  5.8066e-02,  3.5409e-02,  4.8058e-02,\n",
       "           2.5384e-02,  3.8028e-02,  3.5866e-02,  3.5688e-02,  3.5737e-02,\n",
       "           3.5764e-02,  3.3601e-02,  3.3651e-02,  3.1464e-02,  2.9300e-02,\n",
       "           2.9327e-02],\n",
       "         [-1.5629e+00, -1.5707e+00, -1.5706e+00, -1.5710e+00, -1.5591e+00,\n",
       "          -1.5686e+00, -1.5772e+00, -1.5776e+00, -1.5755e+00, -1.5712e+00,\n",
       "          -1.5744e+00, -1.5729e+00, -1.5734e+00, -1.5734e+00, -1.5758e+00,\n",
       "          -1.5745e+00],\n",
       "         [-1.5951e+00, -1.5935e+00, -1.5916e+00, -1.5829e+00, -1.5834e+00,\n",
       "          -1.5722e+00, -1.5638e+00, -1.5496e+00, -1.5506e+00, -1.5543e+00,\n",
       "          -1.5538e+00, -1.5605e+00, -1.5617e+00, -1.5635e+00, -1.5604e+00,\n",
       "          -1.5549e+00],\n",
       "         [-3.4509e-01, -2.0751e-01, -1.0362e-01,  4.1454e-03,  1.8592e-02,\n",
       "           1.6582e-02,  3.8148e-03,  1.6811e-02,  5.6968e-03,  1.9073e-03,\n",
       "           5.2896e-03, -3.3316e-03, -1.5361e-02, -2.5587e-02, -3.9047e-02,\n",
       "          -6.0715e-02],\n",
       "         [-1.5757e+00, -1.5748e+00, -1.5739e+00, -1.5730e+00, -1.5760e+00,\n",
       "          -1.5722e+00, -1.5678e+00, -1.5658e+00, -1.5614e+00, -1.5718e+00,\n",
       "          -1.5698e+00, -1.5674e+00, -1.5665e+00, -1.5668e+00, -1.5670e+00,\n",
       "          -1.5825e+00],\n",
       "         [ 3.1275e+00,  3.1401e+00,  3.1174e+00,  3.1387e+00,  3.1387e+00,\n",
       "           3.1388e+00,  3.1161e+00,  3.1373e+00,  3.1374e+00,  3.1374e+00,\n",
       "           3.1375e+00,  3.1240e+00,  3.1240e+00,  3.1218e+00,  3.1219e+00,\n",
       "           3.1197e+00],\n",
       "         [-3.1226e+00, -3.1100e+00, -3.1100e+00, -3.1121e+00, -3.1121e+00,\n",
       "          -3.1121e+00, -3.1120e+00, -3.1142e+00, -3.1277e+00, -3.1298e+00,\n",
       "          -3.1298e+00, -3.1298e+00, -3.1171e+00, -3.1193e+00, -3.1193e+00,\n",
       "          -3.1192e+00],\n",
       "         [-3.0997e+00, -3.1022e+00, -3.0988e+00, -3.1030e+00, -3.0993e+00,\n",
       "          -3.0997e+00, -3.0949e+00, -3.1016e+00, -3.0962e+00, -3.0968e+00,\n",
       "          -3.1035e+00, -3.0905e+00, -3.0972e+00, -3.0978e+00, -3.1197e+00,\n",
       "          -3.1143e+00],\n",
       "         [-1.5379e+00, -1.5573e+00, -1.5558e+00, -1.5549e+00, -1.5602e+00,\n",
       "          -1.5597e+00, -1.5613e+00, -1.5630e+00, -1.5729e+00, -1.5728e+00,\n",
       "          -1.5789e+00, -1.5827e+00, -1.5685e+00, -1.5801e+00, -1.5651e+00,\n",
       "          -1.5624e+00],\n",
       "         [ 1.5693e+00,  1.5671e+00,  1.5671e+00,  1.5797e+00,  1.5775e+00,\n",
       "           1.5753e+00,  1.5527e+00,  1.5654e+00,  1.5690e+00,  1.5690e+00,\n",
       "           1.5697e+00,  1.5707e+00,  1.5729e+00,  1.5709e+00,  1.5702e+00,\n",
       "           1.5741e+00],\n",
       "         [ 1.5629e+00,  1.5630e+00,  1.5608e+00,  1.5608e+00,  1.5734e+00,\n",
       "           1.5733e+00,  1.5711e+00,  1.5576e+00,  1.5554e+00,  1.5552e+00,\n",
       "           1.5542e+00,  1.5759e+00,  1.5726e+00,  1.5706e+00,  1.5716e+00,\n",
       "           1.5714e+00],\n",
       "         [ 1.5557e+00,  1.5557e+00,  1.5684e+00,  1.5662e+00,  1.5662e+00,\n",
       "           1.5788e+00,  1.5766e+00,  1.5764e+00,  1.5743e+00,  1.5869e+00,\n",
       "           1.5791e+00,  1.5781e+00,  1.5882e+00,  1.5875e+00,  1.5855e+00,\n",
       "           1.5767e+00],\n",
       "         [-1.5804e+00, -1.5811e+00, -1.5761e+00, -1.5765e+00, -1.5758e+00,\n",
       "          -1.5751e+00, -1.5755e+00, -1.5749e+00, -1.5852e+00, -1.5859e+00,\n",
       "          -1.5843e+00, -1.5734e+00, -1.5736e+00, -1.5695e+00, -1.5649e+00,\n",
       "          -1.5628e+00],\n",
       "         [-1.5516e+00, -1.5619e+00, -1.5597e+00, -1.5621e+00, -1.5547e+00,\n",
       "          -1.5650e+00, -1.5645e+00, -1.5704e+00, -1.5680e+00, -1.5819e+00,\n",
       "          -1.5674e+00, -1.5738e+00, -1.5739e+00, -1.5750e+00, -1.5721e+00,\n",
       "          -1.5649e+00]]),\n",
       " 'gt': tensor([[[3304.1130, 1543.9924],\n",
       "          [3304.8247, 1544.0099],\n",
       "          [3305.5229, 1544.0145],\n",
       "          ...,\n",
       "          [3325.3792, 1544.2700],\n",
       "          [3325.3777, 1544.2699],\n",
       "          [3325.4189, 1544.2715]],\n",
       " \n",
       "         [[3308.0872, 1601.2106],\n",
       "          [3308.0872, 1601.2106],\n",
       "          [3308.0872, 1601.2106],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000],\n",
       "          [   0.0000,    0.0000],\n",
       "          [   0.0000,    0.0000]],\n",
       " \n",
       "         [[3393.5391, 1541.1510],\n",
       "          [3394.7483, 1541.1548],\n",
       "          [3395.9534, 1541.1466],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000],\n",
       "          [   0.0000,    0.0000],\n",
       "          [   0.0000,    0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3360.7029, 1523.9574],\n",
       "          [3360.7073, 1523.9462],\n",
       "          [3360.7102, 1523.9404],\n",
       "          ...,\n",
       "          [3360.6824, 1560.9564],\n",
       "          [3360.6689, 1562.1666],\n",
       "          [3360.6619, 1563.3285]],\n",
       " \n",
       "         [[3348.7507, 1608.1921],\n",
       "          [3348.7476, 1607.8367],\n",
       "          [3348.7463, 1607.4929],\n",
       "          ...,\n",
       "          [3348.9016, 1571.2126],\n",
       "          [3348.9316, 1570.2194],\n",
       "          [3348.9158, 1569.1511]],\n",
       " \n",
       "         [[3344.8738, 1578.0803],\n",
       "          [3344.8743, 1577.9375],\n",
       "          [3344.8748, 1577.7764],\n",
       "          ...,\n",
       "          [3345.2747, 1501.9772],\n",
       "          [3345.3035, 1500.2695],\n",
       "          [3345.3315, 1498.5460]]]),\n",
       " 'valid_mask': tensor([[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]]),\n",
       " 'pred_traj': tensor([[[3304.1758, 1544.0381],\n",
       "          [3304.9219, 1544.0493],\n",
       "          [3305.6689, 1544.0616],\n",
       "          ...,\n",
       "          [3326.9814, 1544.2761],\n",
       "          [3326.9829, 1544.2838],\n",
       "          [3326.9871, 1544.2889]],\n",
       " \n",
       "         [[3308.1025, 1601.1912],\n",
       "          [3308.1047, 1601.1938],\n",
       "          [3308.1074, 1601.1963],\n",
       "          ...,\n",
       "          [3308.0796, 1601.2135],\n",
       "          [3308.0820, 1601.2164],\n",
       "          [3308.0835, 1601.2192]],\n",
       " \n",
       "         [[3393.4983, 1541.0747],\n",
       "          [3394.6963, 1541.0798],\n",
       "          [3395.8955, 1541.0842],\n",
       "          ...,\n",
       "          [3511.8428, 1540.4613],\n",
       "          [3513.6562, 1540.3987],\n",
       "          [3515.3081, 1540.3412]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3360.7239, 1524.0063],\n",
       "          [3360.7268, 1524.0087],\n",
       "          [3360.7295, 1524.0111],\n",
       "          ...,\n",
       "          [3360.5564, 1530.7603],\n",
       "          [3360.5488, 1531.3630],\n",
       "          [3360.5435, 1531.9122]],\n",
       " \n",
       "         [[3348.7261, 1608.1555],\n",
       "          [3348.7207, 1607.7939],\n",
       "          [3348.7148, 1607.4324],\n",
       "          ...,\n",
       "          [3348.6929, 1579.2556],\n",
       "          [3348.7019, 1578.3116],\n",
       "          [3348.7100, 1577.4513]],\n",
       " \n",
       "         [[3344.8594, 1578.0112],\n",
       "          [3344.8604, 1577.8591],\n",
       "          [3344.8613, 1577.7069],\n",
       "          ...,\n",
       "          [3344.9487, 1505.8439],\n",
       "          [3344.9561, 1504.1792],\n",
       "          [3344.9636, 1502.6626]]]),\n",
       " 'pred_head': tensor([[ 1.0630e-02,  1.4038e-02,  1.7447e-02,  ...,  1.1979e-02,\n",
       "           1.4496e-02,  1.7014e-02],\n",
       "         [ 1.6555e+00,  1.6555e+00,  1.6555e+00,  ...,  1.6589e+00,\n",
       "           1.6589e+00,  1.6589e+00],\n",
       "         [ 3.4079e-03,  1.0681e-03, -1.2716e-03,  ..., -3.1642e-02,\n",
       "          -3.3297e-02, -3.4924e-02],\n",
       "         ...,\n",
       "         [ 1.5556e+00,  1.5556e+00,  1.5557e+00,  ...,  1.5803e+00,\n",
       "           1.5785e+00,  1.5767e+00],\n",
       "         [-1.5784e+00, -1.5789e+00, -1.5794e+00,  ..., -1.5636e+00,\n",
       "          -1.5632e+00, -1.5628e+00],\n",
       "         [-1.5513e+00, -1.5513e+00, -1.5514e+00,  ..., -1.5677e+00,\n",
       "          -1.5664e+00, -1.5649e+00]]),\n",
       " 'next_token_idx': tensor([[ 857,   64,   47,  547,  174,   44,  171, 1949,  728,  347,  186, 1590,\n",
       "            24,   24,   31, 1084],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [1244,  392,  287,   67,   70,  905, 1769,  400, 1062,  965,  483,  216,\n",
       "            55, 1216,  450,  330],\n",
       "         [  31,  443,  181,  443, 1084,   31,   31,   31,  443,   31,   31,   31,\n",
       "           443,   31,   31,   31],\n",
       "         [  31, 1503,   31,  443,   31,   31,   31,  131,  443,   31,   31,   31,\n",
       "            31,   31, 1084,   31],\n",
       "         [  11,   90,   48,  219,  347,  186,  381, 1270,   76,  154,   31,   31,\n",
       "            31,   31,  443,  443],\n",
       "         [ 294,  325,  587, 1999,  782, 1246,  669, 1312, 1639,  935, 1115,  261,\n",
       "           314,  304,  135,  422],\n",
       "         [ 801, 1503,   31,   31,  801,  181,  801,  131,  443,  181,   31,  443,\n",
       "            31,   31,   31,  801],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [ 443,  181, 1084,  443,   31,   31,   31,  443,   31, 1084,  181,  443,\n",
       "            31, 1084,   31,  443],\n",
       "         [1084,  443,   31,  801,  131,  443,   31, 1084,   31,   31, 1503,  131,\n",
       "            24,   74,  277,   48],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [ 131,   31,  443, 1503,   31,   31,  801,  443,  131,   31,  443,   31,\n",
       "           181,  801,  181, 1084],\n",
       "         [ 181,  443,  443,   31,  443,   31,   31, 1084,   31,  443,   31,   31,\n",
       "            31,   31,  443, 1503],\n",
       "         [ 326,  136,  777,   57,    3,  356,   48,   39,   73,  267,  294,   74,\n",
       "          1270,  131,  443,  443],\n",
       "         [  31,   31, 1084,   31,   31,  443, 1503, 1895,  801,   31, 1503, 1895,\n",
       "            31,  443, 1503,  443],\n",
       "         [ 892, 1949, 1458, 1135, 1458, 1126, 1126, 1126, 1126, 1126, 1126, 1126,\n",
       "          1301, 1126, 1458, 1126],\n",
       "         [ 135,  158,  672,   70,  200, 1374,   10,  196, 1455,  220,  179, 1144,\n",
       "          1868, 1781,  433,  216],\n",
       "         [1084,  131,  154,  145,  186,   73,  161,  282,   68,  326,  488,  229,\n",
       "           126,   75,  530,  365],\n",
       "         [1978, 1825,  341,  902,  301,  355,  333,  135, 1537,  236,   67,  727,\n",
       "            70, 1227,  200,  647],\n",
       "         [ 457,  795, 1155, 1576, 1379, 1725,  827,  126, 1325,  530,   78,   59,\n",
       "          1836,  158,   67, 1955],\n",
       "         [1084,  801,   31,  181, 1084,  181, 1084,  443,  131,   31,   31,  443,\n",
       "            31,  443,  443,   31],\n",
       "         [ 131,  154,  145,  280, 1726,   33,  398,   34,  270,  229,  336,  297,\n",
       "           436,  128, 1103,  236],\n",
       "         [ 211,  134,  395,  561,  292,   78,  135, 1458,   45,  490,  397, 1216,\n",
       "           462,  665, 1082,  285],\n",
       "         [1694,  434, 1546,  908,  392,  422, 1008, 1508,  850,  490,  220,  776,\n",
       "           845,  202, 1974, 1768],\n",
       "         [1613,  139,  139,  139,  278,  258,  165,  395,  229,   60,   19,  256,\n",
       "           132,  355,  879,  753],\n",
       "         [ 181, 1084,  181,  801,   31,   31,  181,  801,   31,   31,   31, 1503,\n",
       "            31,  443,   31,  443],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [ 400,  196,  220,  482, 1781,  216, 1502, 1216,  551,  238, 1216,  633,\n",
       "          1216,  238, 1788,  551],\n",
       "         [ 267, 1250,   43,  139,  459,  129,  126,   75,  261,   30,  553,  315,\n",
       "          1458, 1880,  176, 1462],\n",
       "         [1084,  443,   31, 1084,  443,  443,  181, 1084,   76,  145,  186,   39,\n",
       "           171,   57,  136,  258],\n",
       "         [1503,   31,  443,   31, 1084,  131,  443, 1503,  443,  131,  101,  410,\n",
       "           161,   57,  139,    2],\n",
       "         [  31,   31, 1084,  443,   31, 1084,  443,  131,  443, 1084,  154,  101,\n",
       "          1134,   48,   57, 1481],\n",
       "         [  90,   48,  371,  347,  186,  186,  280,  277,  577,   37,  303,  439,\n",
       "             2,  290,  627,   12],\n",
       "         [ 347,  577,  171,  211,  451,  488,  129, 1872,  256,  365,  392,  193,\n",
       "            70,  144,  334,  552]]),\n",
       " 'next_token_idx_gt': tensor([[1933,   22,  521, 1618,  439,   57, 1587,  356,  424,  371, 1866, 1590,\n",
       "           122,  145,  154, 1931, 1033,  826],\n",
       "         [ 443,  443, 1581, 1084, 1147,  801, 1931, 1084,   31,   31,  443, 1084,\n",
       "          1464, 1190,  443,  443,  801,   31],\n",
       "         [1899,  177,  743,  245, 1816, 1084,  801,   31,  801,  181,  181,   31,\n",
       "           801,  801,  443,  801,   31, 1812],\n",
       "         [1084,  443, 1895, 1581,  443, 1084,  181,  801,   31,  181, 1895,  131,\n",
       "          1084,  443, 1084, 1895,  510,   31],\n",
       "         [ 801,  613,  443,  443,  131,  801,  443,  443,  181,  131,  801,   31,\n",
       "          1084,  443,   31, 1895,  181,   31],\n",
       "         [ 823, 1636,  550,  424,  918,  277, 1590,  804, 1580,  801,  181,  801,\n",
       "          1503,  131, 1241, 1058, 1401, 1796],\n",
       "         [ 771,  122,  267,  325,  321, 1842,  782, 1359, 1316, 1092, 1281, 1108,\n",
       "           888, 1919, 1394, 2041,  510,  101],\n",
       "         [ 181,  801,   31,   31,  801,   31,   31,  181,  443,  443,  979,  181,\n",
       "          1241, 1058, 1503, 1931, 1129,   31],\n",
       "         [ 443,  443, 1503,  979,   31,  443,  443, 1931, 1245, 1084,  801,  181,\n",
       "           443,   31,  801, 1580, 1895,   31],\n",
       "         [ 801,  613,  880,  686,  181,  181,  801,  181,  801,  801, 1084,  801,\n",
       "            31,  443,  801, 1084,  443,   31],\n",
       "         [ 181,  801,   31, 1084, 1895, 1581,  381,  186,   53,   90,  779, 1278,\n",
       "           393, 1831,  189,  645, 1872,  443],\n",
       "         [ 443,  443, 1084,  131, 1245,  510, 2029, 1084, 1084,  443, 1084,  801,\n",
       "           801,  181,  181, 1084,  801,   31],\n",
       "         [  31, 1129,  131,  443, 1084, 1931, 1129,  181,   31, 2029,  245,   31,\n",
       "           443, 1084,  443, 1084,   31,   31],\n",
       "         [1084, 1895,  510, 2029,   31,   31,  443,  181,  443,   31,   31,  801,\n",
       "           443, 1084,  801,   31, 1084,   31],\n",
       "         [ 488, 1400,  581, 1893, 1816,   44,   90, 1242,  918,  267,   95, 1327,\n",
       "          1038,   76,  443, 1058, 1580, 1401],\n",
       "         [  31,  801,   31,   31, 1241, 1503, 1895, 2029,  245,  443,  801,   31,\n",
       "            31,   31,  181, 1084,   31,   31],\n",
       "         [ 161,  957, 1616,  498,  810,  816, 1618, 1090, 1126, 1135,  545, 1506,\n",
       "           545, 1506,  217, 1506,  545, 1854],\n",
       "         [1244,  269,  135, 1829, 1516,  200, 1190, 1401, 1084,  443,  801,   31,\n",
       "           181,  181,  801,  181,  181,  678],\n",
       "         [1895,  131,   76,   74,   29,  347,  424,    3,  174,  451,   64,  129,\n",
       "           645, 1018, 2007,  888,  308,  443],\n",
       "         [1143, 1367, 1578, 1635, 1791,  308, 1584,  157, 1816,  510,  801, 1084,\n",
       "           443,  801, 1084,  181, 1084,  412],\n",
       "         [1952,  291,  512, 1145,  694, 1150, 1971, 1660,  374,  966,  193, 1023,\n",
       "          1234,  686,  686,  443,   31,  994],\n",
       "         [ 181, 1084,   31, 1129, 1931, 1129,   31,   31,   31,  443,  131,   31,\n",
       "          1129,   31,  131,   31, 1129,   31],\n",
       "         [ 443,   76, 1218, 1590,  371,  788, 1197, 1543,  362,  419,  717,  143,\n",
       "           261,  314,  159,  553,  571,  443],\n",
       "         [ 691, 1970,  921,  711,  210,   36,  544, 1972,  984, 1921, 1048, 1537,\n",
       "           236,  240,  202, 1462,  196,  384],\n",
       "         [1531, 1138, 1939, 1233, 1286,  245,  245,  443,   31,   31,  181, 1084,\n",
       "          1084,  181,  443,   31,  181,  617],\n",
       "         [ 521,  547,   68,   68, 1259,  652,  439, 1828,  488,  118,  627, 1668,\n",
       "          1614, 1905,  185, 2007,  263,  320],\n",
       "         [ 801, 1503,  181,   31,   31,  443,  801, 1084, 1895,  181,  443,  131,\n",
       "           443,  979, 1241, 1084, 1931,   31],\n",
       "         [ 443, 1503,  801,  443,   31,   31,   31, 1084,  181, 1895,  979, 1147,\n",
       "            31,   31, 1084, 1503,   31,   31],\n",
       "         [ 176,  739, 1893, 1401, 1084,   31,  443,  443,   31,  801, 1084,   31,\n",
       "            31,   31, 1084,  443,   31,   70],\n",
       "         [1730,  280,  312,  584,   43,  656,  681,  393,  395,  657, 1915,  105,\n",
       "           987,  855,  830,  287, 1098,  154],\n",
       "         [1895,   31, 1580, 1147,  979,  689, 1866,  918, 1219,  676,  914, 1796,\n",
       "           342,  258,  666,  419,  307,   31],\n",
       "         [ 801,   31, 1245,  979, 1503,  804,  410, 1250,   43,  136,   22,  849,\n",
       "             6,  833,   59,  301, 1480,   31],\n",
       "         [ 131,  801,  443,  443, 1503,   24,  267,   27, 1519, 1930,   47, 1208,\n",
       "           208, 1853,  308,  988,  858, 1895],\n",
       "         [ 102,   37,  677,  577,  325,   53,  623,  677, 1987,   43, 1123,  172,\n",
       "           165,  208,  871, 1872,   35,  777],\n",
       "         [1327, 1667,   27,  737,   68, 1217, 1818,  692,  143,  987, 1811, 1852,\n",
       "          1305,  240,  637, 1421,  397,  154]]),\n",
       " 'next_token_eval_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [False,  True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True]]),\n",
       " 'pred_prob': tensor([[0.0971, 0.1402, 0.1381, 0.0474, 0.1330, 0.1214, 0.1384, 0.0878, 0.0827,\n",
       "          0.0663, 0.1204, 0.0675, 0.1163, 0.0930, 0.1753, 0.0435],\n",
       "         [0.8971, 0.9032, 0.8981, 0.8998, 0.9010, 0.9010, 0.7724, 0.9018, 0.8949,\n",
       "          0.8977, 0.9020, 0.9018, 0.7646, 0.9004, 0.9007, 0.8998],\n",
       "         [0.0510, 0.1372, 0.0757, 0.1080, 0.1006, 0.0840, 0.1131, 0.1226, 0.0440,\n",
       "          0.0650, 0.0964, 0.0799, 0.0594, 0.0726, 0.0570, 0.0910],\n",
       "         [0.3600, 0.3952, 0.0948, 0.0446, 0.2646, 0.6391, 0.5764, 0.4868, 0.3079,\n",
       "          0.2974, 0.2548, 0.3356, 0.3153, 0.3922, 0.2971, 0.2837],\n",
       "         [0.2186, 0.0637, 0.2711, 0.2589, 0.3671, 0.3374, 0.2853, 0.0742, 0.1706,\n",
       "          0.2641, 0.2419, 0.2441, 0.2734, 0.3153, 0.0749, 0.2342],\n",
       "         [0.0906, 0.0877, 0.1482, 0.0992, 0.1488, 0.1373, 0.1200, 0.0678, 0.1743,\n",
       "          0.1073, 0.2201, 0.3007, 0.3098, 0.3179, 0.2114, 0.0783],\n",
       "         [0.0524, 0.0617, 0.1482, 0.0659, 0.0538, 0.0715, 0.1321, 0.0799, 0.0644,\n",
       "          0.0735, 0.1550, 0.1061, 0.1630, 0.0631, 0.1131, 0.0803],\n",
       "         [0.3297, 0.0839, 0.3231, 0.2613, 0.1830, 0.2393, 0.1931, 0.0618, 0.4445,\n",
       "          0.1207, 0.3791, 0.1859, 0.2828, 0.2755, 0.3065, 0.1136],\n",
       "         [0.8943, 0.9028, 0.8969, 0.9038, 0.8998, 0.9000, 0.7570, 0.9034, 0.8943,\n",
       "          0.9009, 0.8987, 0.9002, 0.8595, 0.9029, 0.9009, 0.9014],\n",
       "         [0.0844, 0.1433, 0.2117, 0.1709, 0.4598, 0.3880, 0.3575, 0.3441, 0.3202,\n",
       "          0.3030, 0.2345, 0.1520, 0.4519, 0.3276, 0.5880, 0.4074],\n",
       "         [0.1847, 0.1171, 0.4825, 0.0709, 0.1127, 0.3468, 0.2936, 0.0636, 0.2066,\n",
       "          0.1763, 0.1314, 0.1749, 0.1786, 0.0986, 0.1024, 0.1447],\n",
       "         [0.8585, 0.8701, 0.8964, 0.9013, 0.9001, 0.9002, 0.7164, 0.9028, 0.8900,\n",
       "          0.8975, 0.8991, 0.9027, 0.8483, 0.9015, 0.8993, 0.9017],\n",
       "         [0.0553, 0.1623, 0.1989, 0.0668, 0.2523, 0.2758, 0.1065, 0.1326, 0.1216,\n",
       "          0.2248, 0.3005, 0.4616, 0.0648, 0.2534, 0.1363, 0.3640],\n",
       "         [0.0749, 0.1618, 0.0929, 0.3896, 0.1371, 0.3856, 0.3391, 0.2948, 0.3474,\n",
       "          0.4156, 0.6091, 0.5186, 0.2788, 0.1673, 0.4826, 0.3254],\n",
       "         [0.0600, 0.1060, 0.1112, 0.0857, 0.0681, 0.1262, 0.0649, 0.1350, 0.1819,\n",
       "          0.1059, 0.0877, 0.1332, 0.0853, 0.1089, 0.0636, 0.1063],\n",
       "         [0.1513, 0.1587, 0.1789, 0.1680, 0.1824, 0.3485, 0.0978, 0.1647, 0.0533,\n",
       "          0.1730, 0.0845, 0.1239, 0.2064, 0.1795, 0.0560, 0.1071],\n",
       "         [0.0211, 0.0368, 0.0775, 0.0268, 0.0620, 0.2781, 0.4282, 0.4669, 0.5202,\n",
       "          0.5895, 0.5932, 0.5705, 0.0243, 0.2103, 0.0515, 0.5161],\n",
       "         [0.0685, 0.1043, 0.0976, 0.1512, 0.1426, 0.0849, 0.1032, 0.1169, 0.1080,\n",
       "          0.0830, 0.0600, 0.0499, 0.0461, 0.0554, 0.0536, 0.1128],\n",
       "         [0.3045, 0.1525, 0.2124, 0.1886, 0.1255, 0.1347, 0.1736, 0.1696, 0.1660,\n",
       "          0.0932, 0.1988, 0.0568, 0.1938, 0.1831, 0.1627, 0.0719],\n",
       "         [0.1027, 0.1971, 0.0537, 0.0761, 0.0976, 0.0528, 0.0439, 0.0890, 0.1161,\n",
       "          0.0931, 0.0651, 0.0615, 0.0779, 0.0862, 0.0729, 0.0743],\n",
       "         [0.0794, 0.0472, 0.0911, 0.0921, 0.1095, 0.0677, 0.0620, 0.0685, 0.0661,\n",
       "          0.0859, 0.1421, 0.0591, 0.2347, 0.0578, 0.0850, 0.0700],\n",
       "         [0.3672, 0.0620, 0.3739, 0.2588, 0.2089, 0.0910, 0.0868, 0.1906, 0.0573,\n",
       "          0.2022, 0.2510, 0.2756, 0.4141, 0.3023, 0.2118, 0.3287],\n",
       "         [0.3371, 0.1109, 0.0627, 0.1465, 0.0586, 0.1254, 0.1178, 0.1425, 0.2051,\n",
       "          0.1656, 0.1368, 0.1929, 0.0766, 0.1451, 0.1519, 0.1387],\n",
       "         [0.1225, 0.1040, 0.1366, 0.0890, 0.1082, 0.1797, 0.1168, 0.0776, 0.1003,\n",
       "          0.1068, 0.0936, 0.0627, 0.0775, 0.0777, 0.0771, 0.0655],\n",
       "         [0.0784, 0.2181, 0.1109, 0.2117, 0.0672, 0.0484, 0.1418, 0.0620, 0.1804,\n",
       "          0.1163, 0.0871, 0.0536, 0.0703, 0.0518, 0.0430, 0.1293],\n",
       "         [0.0903, 0.0676, 0.1520, 0.0871, 0.1082, 0.1900, 0.0924, 0.0671, 0.0907,\n",
       "          0.1953, 0.1880, 0.1129, 0.0754, 0.1183, 0.1705, 0.0985],\n",
       "         [0.3373, 0.4391, 0.0863, 0.3453, 0.5442, 0.5189, 0.0770, 0.2026, 0.4038,\n",
       "          0.3281, 0.3062, 0.0806, 0.2933, 0.1662, 0.4455, 0.1753],\n",
       "         [0.8950, 0.9045, 0.8963, 0.9025, 0.8999, 0.8999, 0.7475, 0.9037, 0.8921,\n",
       "          0.8988, 0.8986, 0.9002, 0.8809, 0.9038, 0.9000, 0.9006],\n",
       "         [0.1206, 0.0621, 0.0762, 0.1207, 0.0654, 0.0941, 0.0619, 0.0762, 0.0710,\n",
       "          0.0511, 0.0597, 0.0512, 0.0709, 0.0489, 0.0604, 0.0465],\n",
       "         [0.0603, 0.0751, 0.1590, 0.1158, 0.1378, 0.1520, 0.1551, 0.0940, 0.0717,\n",
       "          0.0887, 0.1576, 0.1334, 0.1130, 0.0680, 0.1780, 0.0886],\n",
       "         [0.2988, 0.1508, 0.3234, 0.1128, 0.2024, 0.1220, 0.0711, 0.3600, 0.0431,\n",
       "          0.0886, 0.0718, 0.0664, 0.0891, 0.1316, 0.1390, 0.1245],\n",
       "         [0.0333, 0.3184, 0.2267, 0.4740, 0.1914, 0.0408, 0.1425, 0.0621, 0.1423,\n",
       "          0.1296, 0.0600, 0.0624, 0.1296, 0.1184, 0.0702, 0.0722],\n",
       "         [0.1453, 0.1243, 0.2439, 0.3331, 0.4497, 0.1218, 0.2249, 0.0987, 0.2328,\n",
       "          0.0978, 0.0751, 0.1191, 0.0671, 0.1210, 0.0629, 0.0801],\n",
       "         [0.0884, 0.1641, 0.2236, 0.0972, 0.1782, 0.1663, 0.2044, 0.1083, 0.0617,\n",
       "          0.0622, 0.0931, 0.1652, 0.0772, 0.1298, 0.0762, 0.0753],\n",
       "         [0.0653, 0.2279, 0.0849, 0.1565, 0.0597, 0.1338, 0.0801, 0.0783, 0.1395,\n",
       "          0.1265, 0.1074, 0.2195, 0.1258, 0.0953, 0.0705, 0.1361]]),\n",
       " 'vel': tensor([[[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 7.7490e+00,  1.7139e-01],\n",
       "          [ 7.2847e+00,  1.1987e-01],\n",
       "          ...,\n",
       "          [ 4.2871e-01,  1.2451e-02],\n",
       "          [ 2.5879e-02, -2.2949e-02],\n",
       "          [ 2.4414e-02,  6.8359e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8359e-03, -7.3242e-02],\n",
       "          [ 2.0996e-02,  2.7832e-02],\n",
       "          ...,\n",
       "          [ 7.3242e-03, -7.2998e-02],\n",
       "          [ 2.0508e-02,  2.7832e-02],\n",
       "          [ 2.0996e-02,  2.7832e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 1.1082e+01,  1.9287e-02],\n",
       "          [ 1.1698e+01,  3.3447e-02],\n",
       "          ...,\n",
       "          [ 1.7550e+01, -3.8403e-01],\n",
       "          [ 1.7767e+01, -4.5850e-01],\n",
       "          [ 1.7977e+01, -5.9912e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.8828e-03,  1.3232e-01],\n",
       "          [ 2.3438e-02,  2.5391e-02],\n",
       "          ...,\n",
       "          [-5.9082e-02,  2.8225e+00],\n",
       "          [-4.1016e-02,  4.5020e+00],\n",
       "          [-7.7148e-02,  5.9761e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.8828e-02, -4.2964e+00],\n",
       "          [-4.9805e-02, -3.5291e+00],\n",
       "          ...,\n",
       "          [ 1.4160e-02, -7.4529e+00],\n",
       "          [ 9.7168e-02, -8.4260e+00],\n",
       "          [ 8.5938e-02, -9.3601e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-3.9062e-03, -8.8062e-01],\n",
       "          [ 1.1719e-02, -1.4854e+00],\n",
       "          ...,\n",
       "          [-5.3223e-02, -1.4875e+01],\n",
       "          [-1.4648e-03, -1.5835e+01],\n",
       "          [ 5.6152e-02, -1.6502e+01]]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "torch.manual_seed(12)\n",
    "\n",
    "from smart.model import SMART\n",
    "from smart.utils.config import load_config_act\n",
    "from smart.utils.log import Logging\n",
    "\n",
    "config = load_config_act(\"../configs/validation/validation_scalable.yaml\")\n",
    "pretrain_ckpt = \"../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt\"\n",
    "Predictor = SMART\n",
    "logger = Logging().log(level='DEBUG')\n",
    "model = Predictor(config.Model)\n",
    "model.load_params_from_file(filename=pretrain_ckpt, logger=logger)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model.inference(batch)\n",
    "    # pred = model(batch)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:11:59,903-DEBUG-scalable_dataset.py-Line:38-Message:Starting loading dataset with MultiDataset\n",
      "2024-11-17 21:12:18,186-DEBUG-scalable_dataset.py-Line:62-Message:The number of val dataset is 44911\n"
     ]
    }
   ],
   "source": [
    "from smart.datasets.scalable_dataset import MultiDataset\n",
    "from smart.model import SMART\n",
    "from smart.transforms import WaymoTargetBuilder\n",
    "from smart.utils.config import load_config_act\n",
    "from smart.utils.log import Logging\n",
    "from smart.metrics.real_metrics.custom_metrics import RealMetrics\n",
    "from smart.metrics.real_metrics.real_features import compute_real_metric_features\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from waymo_open_dataset.utils.sim_agents import visualizations\n",
    "from waymo_open_dataset.protos import scenario_pb2\n",
    "\n",
    "config = load_config_act(\"../configs/testing/testing_scalable.yaml\")\n",
    "\n",
    "data_config = config.Dataset\n",
    "test_dataset = {\n",
    "    \"scalable\": MultiDataset,\n",
    "}[data_config.dataset](root=data_config.root, split='val',\n",
    "                        raw_dir=data_config.val_raw_dir,\n",
    "                        processed_dir=data_config.val_processed_dir,\n",
    "                        transform=WaymoTargetBuilder(config.Model.num_historical_steps, config.Model.decoder.num_future_steps))\n",
    "dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=False, persistent_workers=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroDataBatch(\n",
       "  scenario_id=[1],\n",
       "  agent={\n",
       "    num_nodes=14,\n",
       "    av_index=[1],\n",
       "    valid_mask=[14, 91],\n",
       "    predict_mask=[14, 91],\n",
       "    id=[1],\n",
       "    type=[14],\n",
       "    category=[14],\n",
       "    position=[14, 91, 3],\n",
       "    heading=[14, 91],\n",
       "    velocity=[14, 91, 3],\n",
       "    shape=[14, 91, 3],\n",
       "    token_idx=[14, 18],\n",
       "    token_contour=[14, 18, 4, 2],\n",
       "    token_pos=[14, 18, 2],\n",
       "    token_heading=[14, 18],\n",
       "    agent_valid_mask=[14, 18],\n",
       "    token_velocity=[14, 18, 2],\n",
       "    batch=[14],\n",
       "    ptr=[2],\n",
       "  },\n",
       "  map_polygon={\n",
       "    num_nodes=121,\n",
       "    type=[121],\n",
       "    light_type=[121],\n",
       "    batch=[121],\n",
       "    ptr=[2],\n",
       "  },\n",
       "  map_point={\n",
       "    num_nodes=16751,\n",
       "    position=[16751, 3],\n",
       "    orientation=[16751],\n",
       "    magnitude=[16751],\n",
       "    height=[16751],\n",
       "    type=[16751],\n",
       "    batch=[16751],\n",
       "    ptr=[2],\n",
       "  },\n",
       "  map_save={\n",
       "    traj_pos=[1679, 3, 2],\n",
       "    traj_theta=[1679],\n",
       "    pl_idx_list=[1679],\n",
       "  },\n",
       "  pt_token={\n",
       "    type=[1679],\n",
       "    side=[1679],\n",
       "    pl_type=[1679],\n",
       "    num_nodes=1679,\n",
       "    batch=[1679],\n",
       "    ptr=[2],\n",
       "  },\n",
       "  (map_point, to, map_polygon)={ edge_index=[2, 16751] },\n",
       "  (map_polygon, to, map_polygon)={\n",
       "    edge_index=[2, 292],\n",
       "    type=[292],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(dataloader)\n",
    "batch = next(data_iter)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 180,  255, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  510,  510,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  245,  245,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  510, 1753,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  245,  245,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  510, 1833,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  510,  510,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  510, 1753,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [  31,  443,  510, 1753,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31],\n",
       "        [ 314,  314, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "           31,   31,   31,   31,   31,   31]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['agent']['token_idx']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 21:17:40,474-INFO-smart.py-Line:222-Message:==> Loading parameters from checkpoint ../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt to GPU\n",
      "2024-11-17 21:17:40,932-INFO-smart.py-Line:231-Message:The number of disk ckpt keys: 818\n",
      "2024-11-17 21:17:41,061-INFO-smart.py-Line:247-Message:Missing keys: []\n",
      "2024-11-17 21:17:41,062-INFO-smart.py-Line:248-Message:The number of missing keys: 0\n",
      "2024-11-17 21:17:41,062-INFO-smart.py-Line:249-Message:The number of unexpected keys: 0\n",
      "2024-11-17 21:17:41,063-INFO-smart.py-Line:250-Message:==> Done (total keys 818)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x_pt': tensor([[ 4.0965,  1.5222, -3.1555,  ..., -1.6200,  4.8519, -5.5597],\n",
       "         [ 1.8451, -1.2355, -2.8023,  ..., -4.7137,  5.5168, -4.8254],\n",
       "         [ 0.8611, -2.9032, -1.4840,  ..., -4.2531,  5.7611, -0.6347],\n",
       "         ...,\n",
       "         [ 1.7210, -6.5852, -3.3734,  ..., -1.1363,  2.4527,  0.9055],\n",
       "         [ 0.8461, -5.1582, -3.0413,  ..., -2.0396,  3.1396,  0.3555],\n",
       "         [ 0.2282, -8.2308, -3.9181,  ..., -2.7247,  3.4893, -2.0633]]),\n",
       " 'map_next_token_idx': tensor([[ 733,  648,  167,  ...,  885,  448,  166],\n",
       "         [ 476,  167,  448,  ..., 1009,  961,  722],\n",
       "         [ 476,  448,  933,  ...,  514,  166,  173],\n",
       "         ...,\n",
       "         [ 885,  613,   25,  ...,    6,  593,  883],\n",
       "         [ 885,  864,  287,  ...,  873,  122,   30],\n",
       "         [ 885,  613,  593,  ...,  196,  528,  194]]),\n",
       " 'map_next_token_prob': tensor([[-0.1768, -0.1692, -0.1485,  ..., -0.1117, -0.3023,  0.2430],\n",
       "         [-0.1941, -0.1418,  0.0420,  ..., -0.0900, -0.3504,  0.3512],\n",
       "         [-0.1816, -0.0418,  0.1498,  ..., -0.2764, -0.2642,  0.1723],\n",
       "         ...,\n",
       "         [-0.5251,  0.1084, -0.0418,  ..., -0.1564, -0.0968,  0.5680],\n",
       "         [-0.3619,  0.1986,  0.0100,  ..., -0.1505, -0.0821,  0.4215],\n",
       "         [-0.4363,  0.0489, -0.0148,  ..., -0.0577, -0.1558,  0.3436]]),\n",
       " 'map_next_token_idx_gt': tensor([   2,  626,  287,   52,  626,   52,  230,  230,   52,  230,   52,    2,\n",
       "          473,  687,  687,  213,   52,  626,    2,   52,   52,  230,  223,  626,\n",
       "          230,  367,  473,   58,  473,  626,  230,  213,   52,   30,   52,  473,\n",
       "          908,  687,  277,  213,  535,  291,  155,  230,  749,  223,   33,   52,\n",
       "           71,  434,  521,  562,  264,  213,  223,   33,  573,  703,  687,   33,\n",
       "          178,   33,  721,  875,  545, 1002,   30,    2,  213,  230,  576,  630,\n",
       "          466,  815,  473,   30,  213,  626,   52,  213,  213,  473, 1015,  687,\n",
       "            2,   30,  687,    2,    2,   18,    2,  656,  213,  473,   58,  626,\n",
       "          687,  582,    2,  473,   33,  687,   33,  687,   52,  473,   52,  626,\n",
       "          473,  687,  788,  741,   33,  343,  206,  155,    2,  473,   52,  687,\n",
       "           30,  626,   12,  539,  282,   52,   52,   52,    2,  687,    2,   30,\n",
       "           33,    2,   33,  507,  248,   12,   33,  213,  687,   52,  213,  558,\n",
       "           30,  473,   33,  213,  473,  626,   52,   30,  230,  687,  345,   33,\n",
       "           52,  230,  414,  473,   52,  213,    0,   33,  662,  851,  214,  230,\n",
       "          230,   52,  687,  213,  414,  473,   52,    2,   52,   34, 1017,  644,\n",
       "           52,    2,  230,  473,    2,   12,  473,   52,   52,  494,  981,  981,\n",
       "          329,  213,  181,  577,  626,  992,    2,  230,  473,  626,  213,   30,\n",
       "          305,  626,   30,  213,  626,  626,   30,    2,  334,   33,  213,  626,\n",
       "           30,  687,  473,   58,  230,  230,   58,  385,   30,   30,  924,  213,\n",
       "          473,  626,   82,    2,  213,  886,   52,  230,    2,   58,   30,   52,\n",
       "           52,  473,   58,  312,  223,  213,  473,  230,   52,   30,  473,   58,\n",
       "           14,  501,  473,    2,   52,    2,   52,    2,  687,  213,  230,   52,\n",
       "          230,  230,   30,   52,   52,   30,  687,  213,    2,  473,  213,  687,\n",
       "          230,  213,  228,  687,  230,    2,  687,   30,   33,  473,  626,    2,\n",
       "          213,   30,  213,  473,    2,  230,  687,   30,   52,   33,   52,   30,\n",
       "          473,  230,   58,   30,   12,  689, 1007,  782,  685,  926,   25,  554,\n",
       "           52,   52,   33,   33,  473,  473,   30,   33,   52,  687,    2,  687,\n",
       "          230,   30,  473,    2,  450,  626,    2,   30,  473,   52,  213,   33,\n",
       "          473,  973,  626,   33,  230,   33,   52,  973]),\n",
       " 'map_next_token_eval_mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]),\n",
       " 'pos_a': tensor([[[-1650.4908,  2750.2681],\n",
       "          [-1643.2311,  2744.5315],\n",
       "          [-1635.8319,  2738.7063],\n",
       "          [-1628.4108,  2732.8311],\n",
       "          [-1620.9421,  2726.9766],\n",
       "          [-1613.4285,  2721.1050],\n",
       "          [-1605.8872,  2715.1855],\n",
       "          [-1598.3564,  2709.2524],\n",
       "          [-1590.7798,  2703.2996],\n",
       "          [-1583.2417,  2697.2747],\n",
       "          [-1575.7354,  2691.2104],\n",
       "          [-1568.2758,  2685.1882],\n",
       "          [-1560.8270,  2679.1526],\n",
       "          [-1553.3893,  2673.1035],\n",
       "          [-1545.8979,  2667.0874],\n",
       "          [-1538.3865,  2661.0962]],\n",
       " \n",
       "         [[-1670.6926,  2756.5923],\n",
       "          [-1670.6626,  2756.6125],\n",
       "          [-1670.6587,  2756.5957],\n",
       "          [-1670.6888,  2756.6167],\n",
       "          [-1670.6851,  2756.5999],\n",
       "          [-1670.6813,  2756.5830],\n",
       "          [-1670.6774,  2756.5662],\n",
       "          [-1670.7075,  2756.5874],\n",
       "          [-1670.6465,  2756.6069],\n",
       "          [-1670.6763,  2756.6287],\n",
       "          [-1670.6726,  2756.6116],\n",
       "          [-1670.6691,  2756.5947],\n",
       "          [-1670.6655,  2756.5776],\n",
       "          [-1670.6906,  2756.5923],\n",
       "          [-1670.6823,  2756.5842],\n",
       "          [-1670.6519,  2756.6040]],\n",
       " \n",
       "         [[-1630.3777,  2724.9453],\n",
       "          [-1630.3472,  2724.9651],\n",
       "          [-1630.3438,  2724.9482],\n",
       "          [-1630.3735,  2724.9697],\n",
       "          [-1630.3700,  2724.9526],\n",
       "          [-1630.3666,  2724.9355],\n",
       "          [-1630.3632,  2724.9185],\n",
       "          [-1630.3929,  2724.9402],\n",
       "          [-1630.3315,  2724.9585],\n",
       "          [-1630.3608,  2724.9805],\n",
       "          [-1630.3575,  2724.9634],\n",
       "          [-1630.3542,  2724.9463],\n",
       "          [-1630.3236,  2724.9656],\n",
       "          [-1630.3531,  2724.9873],\n",
       "          [-1630.3499,  2724.9702],\n",
       "          [-1630.3464,  2724.9531]],\n",
       " \n",
       "         [[-1613.7091,  2741.9062],\n",
       "          [-1613.7285,  2741.9370],\n",
       "          [-1613.7115,  2741.9404],\n",
       "          [-1613.7334,  2741.9109],\n",
       "          [-1613.7164,  2741.9143],\n",
       "          [-1613.6995,  2741.9175],\n",
       "          [-1613.6824,  2741.9209],\n",
       "          [-1613.7043,  2741.8916],\n",
       "          [-1613.7222,  2741.9531],\n",
       "          [-1613.7446,  2741.9238],\n",
       "          [-1613.7277,  2741.9270],\n",
       "          [-1613.7107,  2741.9302],\n",
       "          [-1613.7299,  2741.9609],\n",
       "          [-1613.7518,  2741.9314],\n",
       "          [-1613.7349,  2741.9346],\n",
       "          [-1613.7179,  2741.9380]],\n",
       " \n",
       "         [[-1598.6697,  2730.6562],\n",
       "          [-1598.7017,  2730.6733],\n",
       "          [-1598.6885,  2730.6848],\n",
       "          [-1598.6930,  2730.6482],\n",
       "          [-1598.6799,  2730.6594],\n",
       "          [-1598.6669,  2730.6707],\n",
       "          [-1598.6538,  2730.6819],\n",
       "          [-1598.6582,  2730.6455],\n",
       "          [-1598.7041,  2730.6904],\n",
       "          [-1598.7091,  2730.6538],\n",
       "          [-1598.6958,  2730.6650],\n",
       "          [-1598.6824,  2730.6760],\n",
       "          [-1598.7142,  2730.6931],\n",
       "          [-1598.7189,  2730.6565],\n",
       "          [-1598.7057,  2730.6677],\n",
       "          [-1598.6925,  2730.6792]],\n",
       " \n",
       "         [[-1611.7301,  2740.2092],\n",
       "          [-1611.7477,  2740.2410],\n",
       "          [-1611.7305,  2740.2432],\n",
       "          [-1611.7542,  2740.2151],\n",
       "          [-1611.7369,  2740.2173],\n",
       "          [-1611.7198,  2740.2195],\n",
       "          [-1611.7026,  2740.2217],\n",
       "          [-1611.7263,  2740.1936],\n",
       "          [-1611.7402,  2740.2561],\n",
       "          [-1611.7644,  2740.2285],\n",
       "          [-1611.7471,  2740.2305],\n",
       "          [-1611.7299,  2740.2324],\n",
       "          [-1611.7471,  2740.2642],\n",
       "          [-1611.7710,  2740.2363],\n",
       "          [-1611.7539,  2740.2385],\n",
       "          [-1611.7368,  2740.2407]],\n",
       " \n",
       "         [[-1697.8291,  2762.7363],\n",
       "          [-1697.8604,  2762.7180],\n",
       "          [-1697.8632,  2762.7351],\n",
       "          [-1697.8342,  2762.7122],\n",
       "          [-1697.8370,  2762.7290],\n",
       "          [-1697.8397,  2762.7463],\n",
       "          [-1697.8425,  2762.7632],\n",
       "          [-1697.8137,  2762.7402],\n",
       "          [-1697.8759,  2762.7244],\n",
       "          [-1697.8474,  2762.7012],\n",
       "          [-1697.8499,  2762.7183],\n",
       "          [-1697.8524,  2762.7354],\n",
       "          [-1697.8838,  2762.7173],\n",
       "          [-1697.8551,  2762.6943],\n",
       "          [-1697.8577,  2762.7114],\n",
       "          [-1697.8604,  2762.7285]],\n",
       " \n",
       "         [[-1609.0643,  2739.0083],\n",
       "          [-1609.0812,  2739.0403],\n",
       "          [-1609.0640,  2739.0422],\n",
       "          [-1609.0881,  2739.0144],\n",
       "          [-1609.0710,  2739.0164],\n",
       "          [-1609.0538,  2739.0183],\n",
       "          [-1609.0365,  2739.0203],\n",
       "          [-1609.0607,  2738.9927],\n",
       "          [-1609.0735,  2739.0554],\n",
       "          [-1609.0981,  2739.0283],\n",
       "          [-1609.0808,  2739.0303],\n",
       "          [-1609.0636,  2739.0320],\n",
       "          [-1609.0803,  2739.0642],\n",
       "          [-1609.1047,  2739.0366],\n",
       "          [-1609.0874,  2739.0386],\n",
       "          [-1609.0701,  2739.0405]],\n",
       " \n",
       "         [[-1650.6691,  2779.5247],\n",
       "          [-1650.6471,  2779.4958],\n",
       "          [-1650.6637,  2779.4910],\n",
       "          [-1650.6445,  2779.5225],\n",
       "          [-1650.6611,  2779.5176],\n",
       "          [-1650.6777,  2779.5127],\n",
       "          [-1650.6943,  2779.5078],\n",
       "          [-1650.6750,  2779.5391],\n",
       "          [-1650.6519,  2779.4795],\n",
       "          [-1650.6321,  2779.5105],\n",
       "          [-1650.6489,  2779.5059],\n",
       "          [-1650.6656,  2779.5015],\n",
       "          [-1650.6440,  2779.4727],\n",
       "          [-1650.6248,  2779.5039],\n",
       "          [-1650.6415,  2779.4990],\n",
       "          [-1650.6582,  2779.4944]],\n",
       " \n",
       "         [[-1704.2008,  2782.9448],\n",
       "          [-1704.1693,  2782.9629],\n",
       "          [-1704.1666,  2782.9458],\n",
       "          [-1704.1953,  2782.9688],\n",
       "          [-1704.1926,  2782.9517],\n",
       "          [-1704.1899,  2782.9346],\n",
       "          [-1704.1874,  2782.9175],\n",
       "          [-1704.2159,  2782.9407],\n",
       "          [-1704.1538,  2782.9561],\n",
       "          [-1704.1821,  2782.9795],\n",
       "          [-1704.1798,  2782.9622],\n",
       "          [-1704.1775,  2782.9448],\n",
       "          [-1704.1460,  2782.9626],\n",
       "          [-1704.1744,  2782.9861],\n",
       "          [-1704.1720,  2782.9690],\n",
       "          [-1704.1694,  2782.9519]],\n",
       " \n",
       "         [[-1594.2018,  2726.9282],\n",
       "          [-1594.2209,  2726.9590],\n",
       "          [-1594.2039,  2726.9624],\n",
       "          [-1594.2260,  2726.9329],\n",
       "          [-1594.2089,  2726.9363],\n",
       "          [-1594.1918,  2726.9395],\n",
       "          [-1594.1747,  2726.9426],\n",
       "          [-1594.1969,  2726.9133],\n",
       "          [-1594.2144,  2726.9751],\n",
       "          [-1594.2369,  2726.9460],\n",
       "          [-1594.2200,  2726.9490],\n",
       "          [-1594.2029,  2726.9519],\n",
       "          [-1594.2218,  2726.9827],\n",
       "          [-1594.2440,  2726.9534],\n",
       "          [-1594.2269,  2726.9565],\n",
       "          [-1594.2098,  2726.9597]],\n",
       " \n",
       "         [[-1610.3914,  2746.3589],\n",
       "          [-1610.4100,  2746.3899],\n",
       "          [-1610.3929,  2746.3928],\n",
       "          [-1610.4154,  2746.3638],\n",
       "          [-1610.3984,  2746.3667],\n",
       "          [-1610.3813,  2746.3696],\n",
       "          [-1610.3643,  2746.3728],\n",
       "          [-1610.3868,  2746.3438],\n",
       "          [-1610.4033,  2746.4055],\n",
       "          [-1610.4264,  2746.3767],\n",
       "          [-1610.4093,  2746.3794],\n",
       "          [-1610.3921,  2746.3821],\n",
       "          [-1610.4105,  2746.4131],\n",
       "          [-1610.4332,  2746.3843],\n",
       "          [-1610.4161,  2746.3872],\n",
       "          [-1610.3990,  2746.3901]],\n",
       " \n",
       "         [[-1585.2031,  2720.6904],\n",
       "          [-1585.2212,  2720.7219],\n",
       "          [-1585.2040,  2720.7246],\n",
       "          [-1585.2271,  2720.6958],\n",
       "          [-1585.2100,  2720.6985],\n",
       "          [-1585.1929,  2720.7012],\n",
       "          [-1585.1758,  2720.7036],\n",
       "          [-1585.1989,  2720.6750],\n",
       "          [-1585.2141,  2720.7373],\n",
       "          [-1585.2377,  2720.7090],\n",
       "          [-1585.2205,  2720.7114],\n",
       "          [-1585.2032,  2720.7139],\n",
       "          [-1585.2212,  2720.7454],\n",
       "          [-1585.2445,  2720.7168],\n",
       "          [-1585.2273,  2720.7192],\n",
       "          [-1585.2102,  2720.7217]],\n",
       " \n",
       "         [[-1641.1617,  2738.9570],\n",
       "          [-1636.8229,  2735.5159],\n",
       "          [-1632.4857,  2732.0728],\n",
       "          [-1628.0975,  2728.6455],\n",
       "          [-1623.6680,  2725.1914],\n",
       "          [-1619.2412,  2721.7339],\n",
       "          [-1614.8173,  2718.2727],\n",
       "          [-1610.3960,  2714.8081],\n",
       "          [-1606.0321,  2711.3647],\n",
       "          [-1601.6641,  2707.8335],\n",
       "          [-1597.3030,  2704.3721],\n",
       "          [-1592.9548,  2700.9087],\n",
       "          [-1588.6030,  2697.3572],\n",
       "          [-1584.2578,  2693.8760],\n",
       "          [-1579.8760,  2690.4407],\n",
       "          [-1575.5071,  2687.0034]]]),\n",
       " 'head_a': tensor([[-0.6700, -0.6699, -0.6692, -0.6698, -0.6656, -0.6632, -0.6650, -0.6668,\n",
       "          -0.6664, -0.6717, -0.6769, -0.6787, -0.6805, -0.6823, -0.6790, -0.6756],\n",
       "         [-0.6343, -0.6217, -0.6216, -0.6238, -0.6237, -0.6237, -0.6237, -0.6258,\n",
       "          -0.6393, -0.6415, -0.6415, -0.6414, -0.6414, -0.6201, -0.6428, -0.6302],\n",
       "         [-0.6516, -0.6390, -0.6390, -0.6412, -0.6412, -0.6412, -0.6412, -0.6433,\n",
       "          -0.6568, -0.6589, -0.6589, -0.6588, -0.6462, -0.6484, -0.6483, -0.6483],\n",
       "         [ 0.9122,  0.9248,  0.9248,  0.9226,  0.9227,  0.9227,  0.9227,  0.9206,\n",
       "           0.9071,  0.9050,  0.9050,  0.9050,  0.9177,  0.9155,  0.9156,  0.9156],\n",
       "         [ 1.4268,  1.4394,  1.4395,  1.4373,  1.4374,  1.4374,  1.4374,  1.4353,\n",
       "           1.4218,  1.4196,  1.4196,  1.4197,  1.4323,  1.4301,  1.4302,  1.4302],\n",
       "         [ 0.8496,  0.8622,  0.8622,  0.8600,  0.8601,  0.8601,  0.8601,  0.8580,\n",
       "           0.8445,  0.8423,  0.8424,  0.8424,  0.8550,  0.8529,  0.8529,  0.8529],\n",
       "         [ 2.4481,  2.4608,  2.4608,  2.4586,  2.4587,  2.4587,  2.4587,  2.4565,\n",
       "           2.4431,  2.4409,  2.4409,  2.4409,  2.4536,  2.4514,  2.4514,  2.4515],\n",
       "         [ 0.8318,  0.8444,  0.8444,  0.8422,  0.8423,  0.8423,  0.8423,  0.8401,\n",
       "           0.8267,  0.8245,  0.8246,  0.8246,  0.8372,  0.8351,  0.8351,  0.8352],\n",
       "         [-2.1439, -2.1313, -2.1312, -2.1334, -2.1333, -2.1333, -2.1333, -2.1355,\n",
       "          -2.1489, -2.1511, -2.1510, -2.1510, -2.1383, -2.1405, -2.1405, -2.1405],\n",
       "         [-0.7022, -0.6896, -0.6895, -0.6917, -0.6917, -0.6917, -0.6917, -0.6939,\n",
       "          -0.7073, -0.7095, -0.7095, -0.7094, -0.6968, -0.6990, -0.6989, -0.6989],\n",
       "         [ 0.9038,  0.9165,  0.9165,  0.9143,  0.9143,  0.9143,  0.9143,  0.9122,\n",
       "           0.8987,  0.8966,  0.8966,  0.8967,  0.9093,  0.9071,  0.9071,  0.9072],\n",
       "         [ 0.8894,  0.9021,  0.9021,  0.8999,  0.9000,  0.9000,  0.9001,  0.8979,\n",
       "           0.8844,  0.8823,  0.8823,  0.8823,  0.8950,  0.8928,  0.8929,  0.8929],\n",
       "         [ 0.8692,  0.8819,  0.8819,  0.8798,  0.8798,  0.8798,  0.8799,  0.8777,\n",
       "           0.8642,  0.8621,  0.8621,  0.8622,  0.8748,  0.8726,  0.8727,  0.8727],\n",
       "         [-0.6705, -0.6710, -0.6714, -0.6609, -0.6617, -0.6625, -0.6633, -0.6641,\n",
       "          -0.6785, -0.6793, -0.6687, -0.6830, -0.6838, -0.6733, -0.6627, -0.6770]]),\n",
       " 'gt': tensor([[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]]),\n",
       " 'valid_mask': tensor([[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]]),\n",
       " 'pred_traj': tensor([[[-1656.1853,  2754.7231],\n",
       "          [-1654.7163,  2753.5786],\n",
       "          [-1653.2477,  2752.4321],\n",
       "          ...,\n",
       "          [-1541.2834,  2663.4053],\n",
       "          [-1539.7668,  2662.1978],\n",
       "          [-1538.3865,  2661.0962]],\n",
       " \n",
       "         [[-1670.6948,  2756.6060],\n",
       "          [-1670.6946,  2756.6023],\n",
       "          [-1670.6942,  2756.5986],\n",
       "          ...,\n",
       "          [-1670.6639,  2756.5972],\n",
       "          [-1670.6580,  2756.6023],\n",
       "          [-1670.6519,  2756.6040]],\n",
       " \n",
       "         [[-1630.3799,  2724.9590],\n",
       "          [-1630.3795,  2724.9556],\n",
       "          [-1630.3794,  2724.9521],\n",
       "          ...,\n",
       "          [-1630.3481,  2724.9597],\n",
       "          [-1630.3477,  2724.9561],\n",
       "          [-1630.3464,  2724.9531]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1610.4050,  2746.3572],\n",
       "          [-1610.4016,  2746.3574],\n",
       "          [-1610.3979,  2746.3574],\n",
       "          ...,\n",
       "          [-1610.4058,  2746.3887],\n",
       "          [-1610.4020,  2746.3889],\n",
       "          [-1610.3990,  2746.3901]],\n",
       " \n",
       "         [[-1585.2168,  2720.6887],\n",
       "          [-1585.2134,  2720.6890],\n",
       "          [-1585.2097,  2720.6890],\n",
       "          ...,\n",
       "          [-1585.2168,  2720.7205],\n",
       "          [-1585.2131,  2720.7207],\n",
       "          [-1585.2102,  2720.7217]],\n",
       " \n",
       "         [[-1644.6141,  2741.6926],\n",
       "          [-1643.7249,  2740.9880],\n",
       "          [-1642.8351,  2740.2832],\n",
       "          ...,\n",
       "          [-1577.1876,  2688.3335],\n",
       "          [-1576.3069,  2687.6394],\n",
       "          [-1575.5071,  2687.0034]]]),\n",
       " 'pred_head': tensor([[-0.6597, -0.6623, -0.6649,  ..., -0.6769, -0.6763, -0.6756],\n",
       "         [-0.6343, -0.6343, -0.6343,  ..., -0.6352, -0.6327, -0.6302],\n",
       "         [-0.6517, -0.6517, -0.6516,  ..., -0.6483, -0.6483, -0.6483],\n",
       "         ...,\n",
       "         [ 0.8894,  0.8894,  0.8894,  ...,  0.8929,  0.8929,  0.8929],\n",
       "         [ 0.8692,  0.8692,  0.8692,  ...,  0.8727,  0.8727,  0.8727],\n",
       "         [-0.6701, -0.6702, -0.6703,  ..., -0.6713, -0.6742, -0.6770]]),\n",
       " 'next_token_idx': tensor([[ 264,  881,    9,  386,  768,  540,  665,  665,  119, 1729, 1729,  665,\n",
       "           665,  665,  469,  469],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "            31,  801,  181, 1084],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [  31, 1084,   31,  443,   31,   31,   31,  443, 1503,  443,   31,   31,\n",
       "          1084,  443,   31,   31],\n",
       "         [ 436,  436,  436,  678,  314,  314,  314,  314,  988,  314,  678,  988,\n",
       "           314,  678,  678,  988]]),\n",
       " 'next_token_idx_gt': tensor([[ 255, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,  180],\n",
       "         [ 443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  510,  510,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  245,  245,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  510, 1753,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  245,  245,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  510, 1833,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  510,  510,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  510, 1753,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 443,  510, 1753,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,   31],\n",
       "         [ 314, 1401, 1401,   31,   31,   31,   31,   31,   31,   31,   31,   31,\n",
       "            31,   31,   31,   31,   31,  314]]),\n",
       " 'next_token_eval_mask': tensor([[ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False]]),\n",
       " 'pred_prob': tensor([[0.1933, 0.0652, 0.0734, 0.0708, 0.0613, 0.0864, 0.1252, 0.1679, 0.1137,\n",
       "          0.0830, 0.0951, 0.0956, 0.0789, 0.0610, 0.0762, 0.1363],\n",
       "         [0.9013, 0.9029, 0.8994, 0.9017, 0.9010, 0.9026, 0.8496, 0.9024, 0.9056,\n",
       "          0.8994, 0.9010, 0.9000, 0.1093, 0.9036, 0.8934, 0.8958],\n",
       "         [0.9002, 0.9055, 0.8986, 0.9003, 0.8995, 0.9022, 0.8036, 0.9023, 0.9030,\n",
       "          0.8994, 0.9001, 0.8999, 0.8943, 0.9032, 0.8998, 0.9008],\n",
       "         [0.9005, 0.9013, 0.9005, 0.9026, 0.9017, 0.9025, 0.8424, 0.9030, 0.9021,\n",
       "          0.9014, 0.9028, 0.9011, 0.8241, 0.9034, 0.9024, 0.9029],\n",
       "         [0.9019, 0.8986, 0.8986, 0.9036, 0.9013, 0.9023, 0.8582, 0.9037, 0.9016,\n",
       "          0.9012, 0.9010, 0.9010, 0.8502, 0.9041, 0.9022, 0.9006],\n",
       "         [0.9010, 0.9018, 0.9008, 0.9028, 0.9022, 0.9024, 0.8220, 0.9021, 0.9039,\n",
       "          0.9003, 0.9026, 0.9010, 0.8941, 0.9029, 0.9017, 0.9019],\n",
       "         [0.8997, 0.9024, 0.8995, 0.9043, 0.9026, 0.9032, 0.7940, 0.9015, 0.9072,\n",
       "          0.9015, 0.9020, 0.9010, 0.8655, 0.9015, 0.9030, 0.9037],\n",
       "         [0.9009, 0.9020, 0.9008, 0.9032, 0.9020, 0.9024, 0.7475, 0.9025, 0.9029,\n",
       "          0.9001, 0.9021, 0.9004, 0.8926, 0.9038, 0.9020, 0.9017],\n",
       "         [0.9003, 0.9004, 0.8988, 0.9027, 0.9007, 0.9014, 0.8447, 0.9027, 0.9046,\n",
       "          0.9004, 0.9010, 0.9001, 0.8556, 0.9016, 0.9016, 0.9016],\n",
       "         [0.8993, 0.9011, 0.9007, 0.9045, 0.9029, 0.9033, 0.8461, 0.9028, 0.9037,\n",
       "          0.9021, 0.9019, 0.9013, 0.8738, 0.9016, 0.9024, 0.9031],\n",
       "         [0.9012, 0.9002, 0.8997, 0.9043, 0.9019, 0.9028, 0.8113, 0.9037, 0.9042,\n",
       "          0.9005, 0.9015, 0.9009, 0.8715, 0.9029, 0.9022, 0.9018],\n",
       "         [0.9013, 0.9002, 0.9005, 0.9032, 0.9017, 0.9021, 0.7967, 0.9025, 0.9008,\n",
       "          0.9002, 0.9021, 0.9002, 0.8872, 0.9019, 0.9013, 0.9012],\n",
       "         [0.9020, 0.9017, 0.9001, 0.9043, 0.9022, 0.9032, 0.8535, 0.9023, 0.9036,\n",
       "          0.8996, 0.9019, 0.9015, 0.8406, 0.9028, 0.9034, 0.9022],\n",
       "         [0.2207, 0.2438, 0.2362, 0.2244, 0.2091, 0.2475, 0.3299, 0.3679, 0.1627,\n",
       "          0.0778, 0.4707, 0.1498, 0.0890, 0.4685, 0.1851, 0.2086]]),\n",
       " 'vel': tensor([[[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 1.4363e+01, -1.1093e+01],\n",
       "          [ 1.4327e+01, -1.1189e+01],\n",
       "          [ 1.4520e+01, -1.1473e+01],\n",
       "          [ 1.4798e+01, -1.1650e+01],\n",
       "          [ 1.4842e+01, -1.1750e+01],\n",
       "          [ 1.4937e+01, -1.1709e+01],\n",
       "          [ 1.5027e+01, -1.1743e+01],\n",
       "          [ 1.5083e+01, -1.1839e+01],\n",
       "          [ 1.5062e+01, -1.1866e+01],\n",
       "          [ 1.5153e+01, -1.1906e+01],\n",
       "          [ 1.5076e+01, -1.2050e+01],\n",
       "          [ 1.5013e+01, -1.2128e+01],\n",
       "          [ 1.4919e+01, -1.2044e+01],\n",
       "          [ 1.4897e+01, -1.2071e+01],\n",
       "          [ 1.4875e+01, -1.2098e+01],\n",
       "          [ 1.4983e+01, -1.2032e+01],\n",
       "          [ 1.5023e+01, -1.1982e+01]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-5.9814e-02,  4.2969e-02],\n",
       "          [ 7.0801e-03, -3.3691e-02],\n",
       "          [ 6.0059e-02,  4.0527e-02],\n",
       "          [ 7.8125e-03, -3.3691e-02],\n",
       "          [-6.0303e-02,  4.1992e-02],\n",
       "          [ 7.5684e-03, -3.3691e-02],\n",
       "          [ 7.5684e-03, -3.3691e-02],\n",
       "          [ 7.8125e-03, -3.3691e-02],\n",
       "          [-6.0303e-02,  4.2480e-02],\n",
       "          [ 1.2207e-01,  3.9062e-02],\n",
       "          [-5.9570e-02,  4.3457e-02],\n",
       "          [ 7.3242e-03, -3.4180e-02],\n",
       "          [ 7.0801e-03, -3.3691e-02],\n",
       "          [ 7.0801e-03, -3.4180e-02],\n",
       "          [-5.0049e-02,  2.9297e-02],\n",
       "          [ 1.6602e-02, -1.6113e-02],\n",
       "          [ 6.0791e-02,  3.9551e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-5.9082e-02,  4.3945e-02],\n",
       "          [ 6.8359e-03, -3.4180e-02],\n",
       "          [ 6.1035e-02,  3.9551e-02],\n",
       "          [ 6.8359e-03, -3.3691e-02],\n",
       "          [-5.9570e-02,  4.2969e-02],\n",
       "          [ 7.0801e-03, -3.4180e-02],\n",
       "          [ 6.8359e-03, -3.4180e-02],\n",
       "          [ 6.8359e-03, -3.4180e-02],\n",
       "          [-5.9570e-02,  4.3457e-02],\n",
       "          [ 1.2280e-01,  3.6621e-02],\n",
       "          [-5.8594e-02,  4.3945e-02],\n",
       "          [ 6.5918e-03, -3.4180e-02],\n",
       "          [ 6.5918e-03, -3.4180e-02],\n",
       "          [ 6.1279e-02,  3.8574e-02],\n",
       "          [-5.9082e-02,  4.3457e-02],\n",
       "          [ 6.5918e-03, -3.4180e-02],\n",
       "          [ 6.8359e-03, -3.4180e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.4434e-02, -5.8594e-02],\n",
       "          [ 3.4180e-02,  6.3477e-03],\n",
       "          [-3.8818e-02,  6.1523e-02],\n",
       "          [ 3.3936e-02,  6.8359e-03],\n",
       "          [-4.3701e-02, -5.9082e-02],\n",
       "          [ 3.3936e-02,  6.8359e-03],\n",
       "          [ 3.3936e-02,  6.3477e-03],\n",
       "          [ 3.4180e-02,  6.8359e-03],\n",
       "          [-4.3945e-02, -5.8594e-02],\n",
       "          [-3.5645e-02,  1.2305e-01],\n",
       "          [-4.4922e-02, -5.8594e-02],\n",
       "          [ 3.3936e-02,  6.3477e-03],\n",
       "          [ 3.3936e-02,  6.3477e-03],\n",
       "          [-3.8330e-02,  6.1523e-02],\n",
       "          [-4.3945e-02, -5.9082e-02],\n",
       "          [ 3.3936e-02,  6.3477e-03],\n",
       "          [ 3.3936e-02,  6.8359e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-9.7656e-03, -7.3242e-02],\n",
       "          [ 2.6367e-02,  2.2461e-02],\n",
       "          [-6.3965e-02,  3.4180e-02],\n",
       "          [ 2.6367e-02,  2.2949e-02],\n",
       "          [-9.0332e-03, -7.3242e-02],\n",
       "          [ 2.6123e-02,  2.2461e-02],\n",
       "          [ 2.6123e-02,  2.2461e-02],\n",
       "          [ 2.6123e-02,  2.2461e-02],\n",
       "          [-8.7891e-03, -7.2754e-02],\n",
       "          [-9.1797e-02,  8.9844e-02],\n",
       "          [-1.0010e-02, -7.3242e-02],\n",
       "          [ 2.6611e-02,  2.2461e-02],\n",
       "          [ 2.6855e-02,  2.1973e-02],\n",
       "          [-6.3721e-02,  3.4180e-02],\n",
       "          [-9.2773e-03, -7.3242e-02],\n",
       "          [ 2.6367e-02,  2.2461e-02],\n",
       "          [ 2.6367e-02,  2.2949e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.7852e-02, -5.5664e-02],\n",
       "          [ 3.4424e-02,  4.3945e-03],\n",
       "          [-3.5156e-02,  6.3477e-02],\n",
       "          [ 3.4424e-02,  4.3945e-03],\n",
       "          [-4.7363e-02, -5.6152e-02],\n",
       "          [ 3.4424e-02,  4.3945e-03],\n",
       "          [ 3.4180e-02,  4.3945e-03],\n",
       "          [ 3.4424e-02,  4.3945e-03],\n",
       "          [-4.7363e-02, -5.6152e-02],\n",
       "          [-2.7832e-02,  1.2500e-01],\n",
       "          [-4.8340e-02, -5.5176e-02],\n",
       "          [ 3.4668e-02,  3.9062e-03],\n",
       "          [ 3.4424e-02,  3.9062e-03],\n",
       "          [-3.4424e-02,  6.3477e-02],\n",
       "          [-4.7852e-02, -5.5664e-02],\n",
       "          [ 3.4180e-02,  4.3945e-03],\n",
       "          [ 3.4180e-02,  4.3945e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 5.7129e-02, -4.6387e-02],\n",
       "          [-5.1270e-03,  3.4668e-02],\n",
       "          [-6.2500e-02, -3.6621e-02],\n",
       "          [-5.6152e-03,  3.4180e-02],\n",
       "          [ 5.7861e-02, -4.5898e-02],\n",
       "          [-5.6152e-03,  3.3691e-02],\n",
       "          [-5.3711e-03,  3.4668e-02],\n",
       "          [-5.6152e-03,  3.3691e-02],\n",
       "          [ 5.7617e-02, -4.5898e-02],\n",
       "          [-1.2427e-01, -3.1738e-02],\n",
       "          [ 5.6885e-02, -4.6387e-02],\n",
       "          [-4.8828e-03,  3.4180e-02],\n",
       "          [-5.1270e-03,  3.4180e-02],\n",
       "          [-6.2744e-02, -3.6133e-02],\n",
       "          [ 5.7373e-02, -4.5898e-02],\n",
       "          [-5.1270e-03,  3.4180e-02],\n",
       "          [-5.3711e-03,  3.4180e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.8828e-02, -5.5176e-02],\n",
       "          [ 3.4424e-02,  3.4180e-03],\n",
       "          [-3.3691e-02,  6.3965e-02],\n",
       "          [ 3.4424e-02,  3.9062e-03],\n",
       "          [-4.8340e-02, -5.5664e-02],\n",
       "          [ 3.4180e-02,  3.9062e-03],\n",
       "          [ 3.4424e-02,  3.9062e-03],\n",
       "          [ 3.4668e-02,  3.9062e-03],\n",
       "          [-4.8340e-02, -5.5176e-02],\n",
       "          [-2.5635e-02,  1.2549e-01],\n",
       "          [-4.9316e-02, -5.4199e-02],\n",
       "          [ 3.4668e-02,  3.9062e-03],\n",
       "          [ 3.4424e-02,  3.4180e-03],\n",
       "          [-3.3447e-02,  6.4453e-02],\n",
       "          [-4.8828e-02, -5.5176e-02],\n",
       "          [ 3.4668e-02,  3.9062e-03],\n",
       "          [ 3.4668e-02,  3.9062e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 3.9062e-02,  6.2500e-02],\n",
       "          [-3.3447e-02, -9.2773e-03],\n",
       "          [ 4.3945e-02, -5.7617e-02],\n",
       "          [-3.3203e-02, -9.7656e-03],\n",
       "          [ 3.8330e-02,  6.2988e-02],\n",
       "          [-3.3203e-02, -9.7656e-03],\n",
       "          [-3.3203e-02, -9.7656e-03],\n",
       "          [-3.3203e-02, -9.7656e-03],\n",
       "          [ 3.8574e-02,  6.2500e-02],\n",
       "          [ 4.6387e-02, -1.1914e-01],\n",
       "          [ 3.9551e-02,  6.2012e-02],\n",
       "          [-3.3691e-02, -9.2773e-03],\n",
       "          [-3.3447e-02, -8.7891e-03],\n",
       "          [ 4.3213e-02, -5.7617e-02],\n",
       "          [ 3.8574e-02,  6.2500e-02],\n",
       "          [-3.3447e-02, -9.7656e-03],\n",
       "          [-3.3447e-02, -9.2773e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-5.6885e-02,  4.6875e-02],\n",
       "          [ 5.1270e-03, -3.4180e-02],\n",
       "          [ 6.2988e-02,  3.6133e-02],\n",
       "          [ 5.3711e-03, -3.4180e-02],\n",
       "          [-5.7373e-02,  4.5898e-02],\n",
       "          [ 5.3711e-03, -3.4180e-02],\n",
       "          [ 5.3711e-03, -3.4180e-02],\n",
       "          [ 5.1270e-03, -3.4180e-02],\n",
       "          [-5.7129e-02,  4.6387e-02],\n",
       "          [ 1.2427e-01,  3.0762e-02],\n",
       "          [-5.6641e-02,  4.6875e-02],\n",
       "          [ 4.6387e-03, -3.4668e-02],\n",
       "          [ 4.6387e-03, -3.4668e-02],\n",
       "          [ 6.2988e-02,  3.5645e-02],\n",
       "          [-5.6885e-02,  4.6875e-02],\n",
       "          [ 4.8828e-03, -3.4180e-02],\n",
       "          [ 5.1270e-03, -3.4180e-02]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.4922e-02, -5.8594e-02],\n",
       "          [ 3.3936e-02,  5.8594e-03],\n",
       "          [-3.8330e-02,  6.1523e-02],\n",
       "          [ 3.4180e-02,  6.8359e-03],\n",
       "          [-4.4189e-02, -5.9082e-02],\n",
       "          [ 3.4180e-02,  6.8359e-03],\n",
       "          [ 3.4180e-02,  6.3477e-03],\n",
       "          [ 3.4180e-02,  6.3477e-03],\n",
       "          [-4.4434e-02, -5.8594e-02],\n",
       "          [-3.4912e-02,  1.2354e-01],\n",
       "          [-4.5166e-02, -5.8105e-02],\n",
       "          [ 3.3936e-02,  5.8594e-03],\n",
       "          [ 3.4180e-02,  5.8594e-03],\n",
       "          [-3.7842e-02,  6.1523e-02],\n",
       "          [-4.4434e-02, -5.8594e-02],\n",
       "          [ 3.4180e-02,  6.3477e-03],\n",
       "          [ 3.4180e-02,  6.3477e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.5654e-02, -5.7617e-02],\n",
       "          [ 3.4180e-02,  5.8594e-03],\n",
       "          [-3.7354e-02,  6.2012e-02],\n",
       "          [ 3.4180e-02,  5.8594e-03],\n",
       "          [-4.4922e-02, -5.8105e-02],\n",
       "          [ 3.3936e-02,  5.8594e-03],\n",
       "          [ 3.4180e-02,  5.8594e-03],\n",
       "          [ 3.4180e-02,  6.3477e-03],\n",
       "          [-4.5166e-02, -5.8105e-02],\n",
       "          [-3.2959e-02,  1.2354e-01],\n",
       "          [-4.6143e-02, -5.7617e-02],\n",
       "          [ 3.4180e-02,  5.3711e-03],\n",
       "          [ 3.4424e-02,  5.3711e-03],\n",
       "          [-3.6865e-02,  6.2012e-02],\n",
       "          [-4.5410e-02, -5.7617e-02],\n",
       "          [ 3.4180e-02,  5.8594e-03],\n",
       "          [ 3.4180e-02,  5.8594e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-4.6875e-02, -5.7129e-02],\n",
       "          [ 3.4180e-02,  5.3711e-03],\n",
       "          [-3.6133e-02,  6.2988e-02],\n",
       "          [ 3.4424e-02,  5.3711e-03],\n",
       "          [-4.6143e-02, -5.7617e-02],\n",
       "          [ 3.4180e-02,  5.3711e-03],\n",
       "          [ 3.4180e-02,  5.3711e-03],\n",
       "          [ 3.4180e-02,  4.8828e-03],\n",
       "          [-4.6143e-02, -5.7129e-02],\n",
       "          [-3.0518e-02,  1.2451e-01],\n",
       "          [-4.7119e-02, -5.6641e-02],\n",
       "          [ 3.4424e-02,  4.8828e-03],\n",
       "          [ 3.4424e-02,  4.8828e-03],\n",
       "          [-3.5889e-02,  6.2988e-02],\n",
       "          [-4.6631e-02, -5.7129e-02],\n",
       "          [ 3.4424e-02,  4.8828e-03],\n",
       "          [ 3.4180e-02,  4.8828e-03]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [ 8.8010e+00, -6.9819e+00],\n",
       "          [ 8.6809e+00, -6.8779e+00],\n",
       "          [ 8.6777e+00, -6.8823e+00],\n",
       "          [ 8.6743e+00, -6.8862e+00],\n",
       "          [ 8.7764e+00, -6.8545e+00],\n",
       "          [ 8.8591e+00, -6.9082e+00],\n",
       "          [ 8.8535e+00, -6.9150e+00],\n",
       "          [ 8.8479e+00, -6.9224e+00],\n",
       "          [ 8.8425e+00, -6.9292e+00],\n",
       "          [ 8.7278e+00, -6.8867e+00],\n",
       "          [ 8.7361e+00, -7.0625e+00],\n",
       "          [ 8.7222e+00, -6.9229e+00],\n",
       "          [ 8.6963e+00, -6.9268e+00],\n",
       "          [ 8.7036e+00, -7.1030e+00],\n",
       "          [ 8.6904e+00, -6.9624e+00],\n",
       "          [ 8.7637e+00, -6.8706e+00],\n",
       "          [ 8.7378e+00, -6.8745e+00]]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "torch.manual_seed(12)\n",
    "\n",
    "from smart.model import SMART\n",
    "from smart.utils.config import load_config_act\n",
    "from smart.utils.log import Logging\n",
    "\n",
    "config = load_config_act(\"../configs/validation/validation_scalable.yaml\")\n",
    "pretrain_ckpt = \"../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt\"\n",
    "Predictor = SMART\n",
    "logger = Logging().log(level='DEBUG')\n",
    "model = Predictor(config.Model)\n",
    "model.load_params_from_file(filename=pretrain_ckpt, logger=logger)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = model.match_token_map(batch)\n",
    "    data = model.sample_pt_pred(data)\n",
    "    data['agent']['av_index'] += data['agent']['ptr'][:-1]\n",
    "    pred = model.inference(data)\n",
    "    # pred = model(batch)\n",
    "\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
