{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 文件预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# womd原始文件路径\n",
    "WOMD_DIR = \"/mnt/i/womd_scenario_v_1_2_0/training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 从proto中提取原始数据\n",
    "\n",
    "waymo地图信息定义可以参考[proto文件](https://github.com/waymo-research/waymo-open-dataset/blob/master/src/waymo_open_dataset/protos/map.proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save_infos**\n",
    "+ `scenario_id`: *str*, 场景编号\n",
    "+ `timestamps_seconds`: *list[91]*, 时间戳列表\n",
    "+ `current_time_index`: *int*, 当前时间戳\n",
    "+ `sdc_track_index`: *int*, 主车编号\n",
    "+ `objects_of_interest`: *list*, 感兴趣车辆列表（可能为空）\n",
    "+ `tracks_to_predict`: *dict*, 需要被预测的轨迹\n",
    "    - `track_index`: *list*, 代理轨迹编号\n",
    "    - `difficulty`: *list*, 预测难度 **（不确定划分依据）** \n",
    "    - `object_type`: *list*, 代理类型\n",
    "+ `track_infos`: *dict*, 代理轨迹信息\n",
    "    - `object_id`: *list*, 所有代理id\n",
    "    - `object_type`: *list[str]*, 代理类型\n",
    "        > 'TYPE_UNSET', 'TYPE_VEHICLE', 'TYPE_PEDESTRIAN', 'TYPE_CYCLIST', 'TYPE_OTHER'\n",
    "    - `trajs`: *array[NA, NT, 10]*, 代理状态信息\n",
    "        > center_x, center_y, center_z, length, width, height, heading, velocity_x, velocity_y, valid\n",
    "+ `map_infos`: *dict*, 静态地图信息\n",
    "    + `lane`: *list(dict)*, 车道线信息\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `speed_limit_mph`: *float*, 速度限制（单位mph）\n",
    "        - `type`: *int*, 地图元素类型\n",
    "            > 'TYPE_FREEWAY': 1, 'TYPE_SURFACE_STREET': 2, 'TYPE_BIKE_LANE': 3,\n",
    "        - `left_neighbors`: *list(int)*, 车道左侧车道\n",
    "        - `right_neighbors`: *list(int)*, 车道右侧车道\n",
    "        - `interpolating`: *bool*, 是否差值\n",
    "        - `entry_lanes`: *list(int)*, 上游车道\n",
    "        - `exit_lanes`: *list(int)*, 下游车道线\n",
    "        - `left_boundary_type`: *list(int)*, 左侧边界线类型\n",
    "        - `right_boundary_type`: *list(int)*, 右侧边界线类型\n",
    "        - `left_boundary`: *list(int)*, 左侧边界线id\n",
    "        - `right_boundary`: *list(int)*, 右侧边界线id\n",
    "        - `left_boundary_start_index`: *list(int)*\n",
    "        - `left_boundary_end_index`: *list(int)*\n",
    "        - `right_boundary_start_index`: *list(int)*\n",
    "        - `right_boundary_end_index`: *list(int)*\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `lane_dict`: *dict*, 根据地图元素id获取车道信息\n",
    "    + `road_line`: *list(dict)*, 车道分隔线信息\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `type`: *int*, 地图元素类型\n",
    "            > 'TYPE_BROKEN_SINGLE_WHITE': 6, 'TYPE_SOLID_SINGLE_WHITE': 7, 'TYPE_SOLID_DOUBLE_WHITE': 8, 'TYPE_BROKEN_SINGLE_YELLOW': 9, 'TYPE_BROKEN_DOUBLE_YELLOW': 10, 'TYPE_SOLID_SINGLE_YELLOW': 11, 'TYPE_SOLID_DOUBLE_YELLOW': 12, 'TYPE_PASSING_DOUBLE_YELLOW': 13\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `road_edge`: *list(dict)*, 车道边界线信息 \n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `type`: *int*, 地图元素类型\n",
    "            > 'TYPE_ROAD_EDGE_BOUNDARY': 15, 'TYPE_ROAD_EDGE_MEDIAN': 16\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `stop_sign`: *list(dict)*, 停车线信息\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `lane_ids`: *list*, 停车线控制的lane_id\n",
    "        - `position`: *array[3,]*, 停车线坐标\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `crosswalk`: *list(dict)*, 人行横道线\n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `speed_bump`: *list(dict)*, 减速带信息 \n",
    "        - `id`: *int*, 地图元素id\n",
    "        - `polyline_index`: 该多段线对应点在all_polylines中的起始和终止下标\n",
    "    + `all_polylines`: *array(n, 5)*, 所有多段线上点的信息（x, y, z, 所属道路元素类型, 所属道路元素id）\n",
    "    + `lane2other_dict`: *dict*, 获取车道与其他地图元素（左右边界线、停车线）的关联列表\n",
    "+ `dynamic_map_infos`: *dict*, 动态地图信息\n",
    "    - `lane_id`: *list(91)*, 每一帧所有信号灯控制的lane_id\n",
    "    - `state`: *list(91)*, 每一帧所有信号灯的状态\n",
    "        > 'LANE_STATE_UNKNOWN', 'LANE_STATE_ARROW_STOP', 'LANE_STATE_ARROW_CAUTION', 'LANE_STATE_ARROW_GO', 'LANE_STATE_STOP', 'LANE_STATE_CAUTION', 'LANE_STATE_GO', 'LANE_STATE_FLASHING_STOP', 'LANE_STATE_FLASHING_CAUTION'\n",
    "    - `stop_point`: *list(91)*, 每一帧所有信号灯的控制的停车点信息（x, y, z）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from waymo_open_dataset.protos import scenario_pb2\n",
    "\n",
    "for tfrecord in os.listdir(WOMD_DIR):\n",
    "    file_path = os.path.join(WOMD_DIR, tfrecord)\n",
    "    dataset = tf.data.TFRecordDataset(file_path, compression_type='', num_parallel_reads=3)\n",
    "    for cnt, data in enumerate(dataset):\n",
    "        scenario = scenario_pb2.Scenario()\n",
    "        scenario.ParseFromString(bytearray(data.numpy()))\n",
    "        print(f\"scene: {scenario.scenario_id}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def decode_tracks_from_proto(tracks):\n",
    "    object_type = {\n",
    "        0: 'TYPE_UNSET',\n",
    "        1: 'TYPE_VEHICLE',\n",
    "        2: 'TYPE_PEDESTRIAN',\n",
    "        3: 'TYPE_CYCLIST',\n",
    "        4: 'TYPE_OTHER'\n",
    "    }\n",
    "\n",
    "    track_infos = {\n",
    "        'object_id': [],  # {0: unset, 1: vehicle, 2: pedestrian, 3: cyclist, 4: others}\n",
    "        'object_type': [],\n",
    "        'trajs': []\n",
    "    }\n",
    "\n",
    "    for cur_data in tracks:  # number of objects\n",
    "        cur_traj = [np.array([x.center_x, x.center_y, x.center_z, x.length, x.width, x.height, x.heading,\n",
    "                              x.velocity_x, x.velocity_y, x.valid], dtype=np.float32) for x in cur_data.states]\n",
    "        cur_traj = np.stack(cur_traj, axis=0)  # (num_timestamp, 10)\n",
    "\n",
    "        track_infos['object_id'].append(cur_data.id)\n",
    "        track_infos['object_type'].append(object_type[cur_data.object_type])\n",
    "        track_infos['trajs'].append(cur_traj)\n",
    "\n",
    "    track_infos['trajs'] = np.stack(track_infos['trajs'], axis=0)  # (num_objects, num_timestamp, 9)\n",
    "    return track_infos\n",
    "\n",
    "def decode_map_features_from_proto(map_features):\n",
    "    polyline_type = {\n",
    "        # for lane\n",
    "        'TYPE_UNDEFINED': -1,\n",
    "        'TYPE_FREEWAY': 1,\n",
    "        'TYPE_SURFACE_STREET': 2,\n",
    "        'TYPE_BIKE_LANE': 3,\n",
    "\n",
    "        # for roadline\n",
    "        'TYPE_UNKNOWN': -1,\n",
    "        'TYPE_BROKEN_SINGLE_WHITE': 6,\n",
    "        'TYPE_SOLID_SINGLE_WHITE': 7,\n",
    "        'TYPE_SOLID_DOUBLE_WHITE': 8,\n",
    "        'TYPE_BROKEN_SINGLE_YELLOW': 9,\n",
    "        'TYPE_BROKEN_DOUBLE_YELLOW': 10,\n",
    "        'TYPE_SOLID_SINGLE_YELLOW': 11,\n",
    "        'TYPE_SOLID_DOUBLE_YELLOW': 12,\n",
    "        'TYPE_PASSING_DOUBLE_YELLOW': 13,\n",
    "\n",
    "        # for roadedge\n",
    "        'TYPE_ROAD_EDGE_BOUNDARY': 15,\n",
    "        'TYPE_ROAD_EDGE_MEDIAN': 16,\n",
    "\n",
    "        # for stopsign\n",
    "        'TYPE_STOP_SIGN': 17,\n",
    "\n",
    "        # for crosswalk\n",
    "        'TYPE_CROSSWALK': 18,\n",
    "\n",
    "        # for speed bump\n",
    "        'TYPE_SPEED_BUMP': 19\n",
    "    }\n",
    "\n",
    "    map_infos = {\n",
    "        'lane': [],\n",
    "        'road_line': [],\n",
    "        'road_edge': [],\n",
    "        'stop_sign': [],\n",
    "        'crosswalk': [],\n",
    "        'speed_bump': [],\n",
    "        'lane_dict': {},\n",
    "        'lane2other_dict': {}\n",
    "    }\n",
    "    polylines = []\n",
    "\n",
    "    point_cnt = 0\n",
    "    lane2other_dict = defaultdict(list)\n",
    "\n",
    "    for cur_data in map_features:\n",
    "        cur_info = {'id': cur_data.id}\n",
    "\n",
    "        if cur_data.lane.ByteSize() > 0:\n",
    "            cur_info['speed_limit_mph'] = cur_data.lane.speed_limit_mph\n",
    "            cur_info['type'] = cur_data.lane.type + 1  # 0: undefined, 1: freeway, 2: surface_street, 3: bike_lane\n",
    "            cur_info['left_neighbors'] = [lane.feature_id for lane in cur_data.lane.left_neighbors]\n",
    "\n",
    "            cur_info['right_neighbors'] = [lane.feature_id for lane in cur_data.lane.right_neighbors]\n",
    "\n",
    "            cur_info['interpolating'] = cur_data.lane.interpolating\n",
    "            cur_info['entry_lanes'] = list(cur_data.lane.entry_lanes)\n",
    "            cur_info['exit_lanes'] = list(cur_data.lane.exit_lanes)\n",
    "\n",
    "            cur_info['left_boundary_type'] = [x.boundary_type + 5 for x in cur_data.lane.left_boundaries]\n",
    "            cur_info['right_boundary_type'] = [x.boundary_type + 5 for x in cur_data.lane.right_boundaries]\n",
    "\n",
    "            cur_info['left_boundary'] = [x.boundary_feature_id for x in cur_data.lane.left_boundaries]\n",
    "            cur_info['right_boundary'] = [x.boundary_feature_id for x in cur_data.lane.right_boundaries]\n",
    "            cur_info['left_boundary_start_index'] = [lane.lane_start_index for lane in cur_data.lane.left_boundaries]\n",
    "            cur_info['left_boundary_end_index'] = [lane.lane_end_index for lane in cur_data.lane.left_boundaries]\n",
    "            cur_info['right_boundary_start_index'] = [lane.lane_start_index for lane in cur_data.lane.right_boundaries]\n",
    "            cur_info['right_boundary_end_index'] = [lane.lane_end_index for lane in cur_data.lane.right_boundaries]\n",
    "\n",
    "            lane2other_dict[cur_data.id].extend(cur_info['left_boundary'])\n",
    "            lane2other_dict[cur_data.id].extend(cur_info['right_boundary'])\n",
    "\n",
    "            global_type = cur_info['type']\n",
    "            cur_polyline = np.stack(\n",
    "                [np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in cur_data.lane.polyline],\n",
    "                axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['lane'].append(cur_info)\n",
    "            map_infos['lane_dict'][cur_data.id] = cur_info\n",
    "\n",
    "        elif cur_data.road_line.ByteSize() > 0:\n",
    "            cur_info['type'] = cur_data.road_line.type + 5\n",
    "\n",
    "            global_type = cur_info['type']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.road_line.polyline], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['road_line'].append(cur_info)\n",
    "\n",
    "        elif cur_data.road_edge.ByteSize() > 0:\n",
    "            cur_info['type'] = cur_data.road_edge.type + 14\n",
    "\n",
    "            global_type = cur_info['type']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.road_edge.polyline], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['road_edge'].append(cur_info)\n",
    "\n",
    "        elif cur_data.stop_sign.ByteSize() > 0:\n",
    "            cur_info['lane_ids'] = list(cur_data.stop_sign.lane)\n",
    "            for i in cur_info['lane_ids']:\n",
    "                lane2other_dict[i].append(cur_data.id)\n",
    "            point = cur_data.stop_sign.position\n",
    "            cur_info['position'] = np.array([point.x, point.y, point.z])\n",
    "\n",
    "            global_type = polyline_type['TYPE_STOP_SIGN']\n",
    "            cur_polyline = np.array([point.x, point.y, point.z, global_type, cur_data.id]).reshape(1, 5)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['stop_sign'].append(cur_info)\n",
    "        elif cur_data.crosswalk.ByteSize() > 0:\n",
    "            global_type = polyline_type['TYPE_CROSSWALK']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.crosswalk.polygon], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['crosswalk'].append(cur_info)\n",
    "\n",
    "        elif cur_data.speed_bump.ByteSize() > 0:\n",
    "            global_type = polyline_type['TYPE_SPEED_BUMP']\n",
    "            cur_polyline = np.stack([np.array([point.x, point.y, point.z, global_type, cur_data.id]) for point in\n",
    "                                     cur_data.speed_bump.polygon], axis=0)\n",
    "            cur_polyline = np.concatenate((cur_polyline[:, 0:3], cur_polyline[:, 3:]), axis=-1)\n",
    "            if cur_polyline.shape[0] <= 1:\n",
    "                continue\n",
    "            map_infos['speed_bump'].append(cur_info)\n",
    "\n",
    "        else:\n",
    "            # print(cur_data)\n",
    "            continue\n",
    "        polylines.append(cur_polyline)\n",
    "        cur_info['polyline_index'] = (point_cnt, point_cnt + len(cur_polyline))\n",
    "        point_cnt += len(cur_polyline)\n",
    "\n",
    "    # try:\n",
    "    polylines = np.concatenate(polylines, axis=0).astype(np.float32)\n",
    "    # except:\n",
    "    #     polylines = np.zeros((0, 8), dtype=np.float32)\n",
    "    #     print('Empty polylines: ')\n",
    "    map_infos['all_polylines'] = polylines\n",
    "    map_infos['lane2other_dict'] = lane2other_dict\n",
    "    return map_infos\n",
    "\n",
    "def decode_dynamic_map_states_from_proto(dynamic_map_states):\n",
    "    signal_state = {\n",
    "        0: 'LANE_STATE_UNKNOWN',\n",
    "\n",
    "        # // States for traffic signals with arrows.\n",
    "        1: 'LANE_STATE_ARROW_STOP',\n",
    "        2: 'LANE_STATE_ARROW_CAUTION',\n",
    "        3: 'LANE_STATE_ARROW_GO',\n",
    "\n",
    "        # // Standard round traffic signals.\n",
    "        4: 'LANE_STATE_STOP',\n",
    "        5: 'LANE_STATE_CAUTION',\n",
    "        6: 'LANE_STATE_GO',\n",
    "\n",
    "        # // Flashing light signals.\n",
    "        7: 'LANE_STATE_FLASHING_STOP',\n",
    "        8: 'LANE_STATE_FLASHING_CAUTION'\n",
    "    }\n",
    "\n",
    "    dynamic_map_infos = {\n",
    "        'lane_id': [],\n",
    "        'state': [],\n",
    "        'stop_point': []\n",
    "    }\n",
    "    for cur_data in dynamic_map_states:  # (num_timestamp)\n",
    "        lane_id, state, stop_point = [], [], []\n",
    "        for cur_signal in cur_data.lane_states:  # (num_observed_signals)\n",
    "            lane_id.append(cur_signal.lane)\n",
    "            state.append(signal_state[cur_signal.state])\n",
    "            stop_point.append([cur_signal.stop_point.x, cur_signal.stop_point.y, cur_signal.stop_point.z])\n",
    "\n",
    "        dynamic_map_infos['lane_id'].append(np.array([lane_id]))\n",
    "        dynamic_map_infos['state'].append(np.array([state]))\n",
    "        dynamic_map_infos['stop_point'].append(np.array([stop_point]))\n",
    "\n",
    "    return dynamic_map_infos\n",
    "\n",
    "def process_single_data(scenario):\n",
    "    info = {}\n",
    "    info['scenario_id'] = scenario.scenario_id\n",
    "    info['timestamps_seconds'] = list(scenario.timestamps_seconds)  # list of int of shape (91)\n",
    "    info['current_time_index'] = scenario.current_time_index  # int, 10\n",
    "    info['sdc_track_index'] = scenario.sdc_track_index  # int\n",
    "    info['objects_of_interest'] = list(scenario.objects_of_interest)  # list, could be empty list\n",
    "\n",
    "    info['tracks_to_predict'] = {\n",
    "        'track_index': [cur_pred.track_index for cur_pred in scenario.tracks_to_predict],\n",
    "        'difficulty': [cur_pred.difficulty for cur_pred in scenario.tracks_to_predict]\n",
    "    }  # for training: suggestion of objects to train on, for val/test: need to be predicted\n",
    "\n",
    "    track_infos = decode_tracks_from_proto(scenario.tracks)\n",
    "    info['tracks_to_predict']['object_type'] = [track_infos['object_type'][cur_idx] for cur_idx in\n",
    "                                                info['tracks_to_predict']['track_index']]\n",
    "\n",
    "    # decode map related data\n",
    "    map_infos = decode_map_features_from_proto(scenario.map_features)\n",
    "    dynamic_map_infos = decode_dynamic_map_states_from_proto(scenario.dynamic_map_states)\n",
    "\n",
    "    save_infos = {\n",
    "        'track_infos': track_infos,\n",
    "        'dynamic_map_infos': dynamic_map_infos,\n",
    "        'map_infos': map_infos\n",
    "    }\n",
    "    save_infos.update(info)\n",
    "    return save_infos\n",
    "\n",
    "save_infos = process_single_data(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 获取信控信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf_lights`: *array(n \\* 3)*, 每个信号灯每时刻的状态（lane_id, time_step, state）\n",
    "> LANE_STATE_STOP, LANE_STATE_GO, LANE_STATE_CAUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Any, Dict, List, Optional\n",
    "import easydict\n",
    "import pandas as pd\n",
    "\n",
    "def process_dynamic_map(dynamic_map_infos):\n",
    "    lane_ids = dynamic_map_infos[\"lane_id\"]\n",
    "    tf_lights = []\n",
    "    for t in range(len(lane_ids)):\n",
    "        lane_id = lane_ids[t]\n",
    "        time = np.ones_like(lane_id) * t\n",
    "        state = dynamic_map_infos[\"state\"][t]\n",
    "        tf_light = np.concatenate([lane_id, time, state], axis=0)\n",
    "        tf_lights.append(tf_light)\n",
    "    tf_lights = np.concatenate(tf_lights, axis=1).transpose(1, 0)\n",
    "    tf_lights = pd.DataFrame(data=tf_lights, columns=[\"lane_id\", \"time_step\", \"state\"])\n",
    "    tf_lights[\"time_step\"] = tf_lights[\"time_step\"].astype(\"str\")\n",
    "    tf_lights[\"lane_id\"] = tf_lights[\"lane_id\"].astype(\"str\")\n",
    "    tf_lights[\"state\"] = tf_lights[\"state\"].astype(\"str\")\n",
    "    tf_lights.loc[tf_lights[\"state\"].str.contains(\"STOP\"), [\"state\"] ] = 'LANE_STATE_STOP'\n",
    "    tf_lights.loc[tf_lights[\"state\"].str.contains(\"GO\"), [\"state\"] ] = 'LANE_STATE_GO'\n",
    "    tf_lights.loc[tf_lights[\"state\"].str.contains(\"CAUTION\"), [\"state\"] ] = 'LANE_STATE_CAUTION'\n",
    "    return tf_lights\n",
    "\n",
    "dynamic_map_infos = save_infos[\"dynamic_map_infos\"]\n",
    "tf_lights = process_dynamic_map(dynamic_map_infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 获取地图特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_list_index(ls: List[Any], elem: Any) -> Optional[int]:\n",
    "    try:\n",
    "        return ls.index(elem)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def get_map_features(map_infos, tf_current_light, dim=3):\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    _polygon_types = ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "    _polygon_light_type = ['LANE_STATE_STOP', 'LANE_STATE_GO', 'LANE_STATE_CAUTION', 'LANE_STATE_UNKNOWN']\n",
    "    _polygon_to_polygon_types = ['NONE', 'PRED', 'SUCC', 'LEFT', 'RIGHT']\n",
    "    \n",
    "    Lane_type_hash = {\n",
    "        4: \"BIKE\",\n",
    "        3: \"VEHICLE\",\n",
    "        2: \"VEHICLE\",\n",
    "        1: \"BUS\"\n",
    "    }\n",
    "    boundary_type_hash = {\n",
    "        5: \"UNKNOWN\",\n",
    "        6: \"DASHED_WHITE\",\n",
    "        7: \"SOLID_WHITE\",\n",
    "        8: \"DOUBLE_DASH_WHITE\",\n",
    "        9: \"DASHED_YELLOW\",\n",
    "        10: \"DOUBLE_DASH_YELLOW\",\n",
    "        11: \"SOLID_YELLOW\",\n",
    "        12: \"DOUBLE_SOLID_YELLOW\",\n",
    "        13: \"DASH_SOLID_YELLOW\",\n",
    "        14: \"UNKNOWN\",\n",
    "        15: \"EDGE\",\n",
    "        16: \"EDGE\"\n",
    "    }\n",
    "\n",
    "    lane_segments = map_infos['lane']\n",
    "    all_polylines = map_infos[\"all_polylines\"]\n",
    "    crosswalks = map_infos['crosswalk']\n",
    "    road_edges = map_infos['road_edge']\n",
    "    road_lines = map_infos['road_line']\n",
    "    lane_segment_ids = [info[\"id\"] for info in lane_segments]\n",
    "    cross_walk_ids = [info[\"id\"] for info in crosswalks]\n",
    "    road_edge_ids = [info[\"id\"] for info in road_edges]\n",
    "    road_line_ids = [info[\"id\"] for info in road_lines]\n",
    "    polygon_ids = lane_segment_ids + road_edge_ids + road_line_ids + cross_walk_ids\n",
    "    num_polygons = len(lane_segment_ids) + len(road_edge_ids) + len(road_line_ids) + len(cross_walk_ids)\n",
    "\n",
    "    # 多段线中各点所属多段线类型（对应关系见 _polygon_types）\n",
    "    polygon_type = torch.zeros(num_polygons, dtype=torch.uint8)\n",
    "    # 多段线中各点所属信控信号类型（默认为3未知，对应关系见 _polygon_light_type）\n",
    "    polygon_light_type = torch.ones(num_polygons, dtype=torch.uint8) * 3\n",
    "\n",
    "    # 多段线中点的坐标\n",
    "    point_position: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点对应向量的方向角（以弧度表示）\n",
    "    point_orientation: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点对应向量的大小（即距离）\n",
    "    point_magnitude: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点与下一点之间的高度差\n",
    "    point_height: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "    # 多段线中各点类型（对应关系见 _point_types）\n",
    "    point_type: List[Optional[torch.Tensor]] = [None] * num_polygons\n",
    "\n",
    "    for lane_segment in lane_segments:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        polyline_index = lane_segment.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(Lane_type_hash[lane_segment.type])\n",
    "\n",
    "        # 查找当前lane是否在当前帧的信控控制的序列中\n",
    "        res = tf_current_light[tf_current_light[\"lane_id\"] == str(lane_segment.id)]\n",
    "        if len(res) != 0:\n",
    "            polygon_light_type[lane_segment_idx] = _polygon_light_type.index(res[\"state\"].item())\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index('CENTERLINE')\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    for lane_segment in road_edges:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        polyline_index = lane_segment.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(\"VEHICLE\")\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index('EDGE')\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    for lane_segment in road_lines:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        polyline_index = lane_segment.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(\"VEHICLE\")\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index(boundary_type_hash[lane_segment.type])\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    for crosswalk in crosswalks:\n",
    "        crosswalk = easydict.EasyDict(crosswalk)\n",
    "        lane_segment_idx = polygon_ids.index(crosswalk.id)\n",
    "        polyline_index = crosswalk.polyline_index\n",
    "        centerline = all_polylines[polyline_index[0]:polyline_index[1], :]\n",
    "        centerline = torch.from_numpy(centerline).float()\n",
    "\n",
    "        polygon_type[lane_segment_idx] = _polygon_types.index(\"PEDESTRIAN\")\n",
    "\n",
    "        point_position[lane_segment_idx] = torch.cat([centerline[:-1, :dim]], dim=0)\n",
    "        center_vectors = centerline[1:] - centerline[:-1]\n",
    "        point_orientation[lane_segment_idx] = torch.cat([torch.atan2(center_vectors[:, 1], center_vectors[:, 0])], dim=0)\n",
    "        point_magnitude[lane_segment_idx] = torch.norm(torch.cat([center_vectors[:, :2]], dim=0), p=2, dim=-1)\n",
    "        point_height[lane_segment_idx] = torch.cat([center_vectors[:, 2]], dim=0)\n",
    "        center_type = _point_types.index(\"CROSSWALK\")\n",
    "        point_type[lane_segment_idx] = torch.cat(\n",
    "            [torch.full((len(center_vectors),), center_type, dtype=torch.uint8)], dim=0)\n",
    "\n",
    "    # 每条多段线对应的点数\n",
    "    num_points = torch.tensor([point.size(0) for point in point_position], dtype=torch.long)\n",
    "    # [2, N_points] 点索引与多段线索引之间的关系\n",
    "    point_to_polygon_edge_index = torch.stack(\n",
    "        [torch.arange(num_points.sum(), dtype=torch.long),\n",
    "            torch.arange(num_polygons, dtype=torch.long).repeat_interleave(num_points)], dim=0)\n",
    "    # array([2, N_edge])) 提取车道拓扑关系[车道索引1，车道索引2](不根据顺序区分上下游)\n",
    "    polygon_to_polygon_edge_index = []\n",
    "    # array([N_edge])) 拓扑关系类型，参考 _polygon_to_polygon_types\n",
    "    polygon_to_polygon_type = []\n",
    "    for lane_segment in lane_segments:\n",
    "        lane_segment = easydict.EasyDict(lane_segment)\n",
    "        lane_segment_idx = polygon_ids.index(lane_segment.id)\n",
    "        pred_inds = []\n",
    "        for pred in lane_segment.entry_lanes:\n",
    "            pred_idx = _safe_list_index(polygon_ids, pred)\n",
    "            if pred_idx is not None:\n",
    "                pred_inds.append(pred_idx)\n",
    "        if len(pred_inds) != 0:\n",
    "            polygon_to_polygon_edge_index.append(\n",
    "                torch.stack([torch.tensor(pred_inds, dtype=torch.long),\n",
    "                             torch.full((len(pred_inds),), lane_segment_idx, dtype=torch.long)], dim=0))\n",
    "            polygon_to_polygon_type.append(\n",
    "                torch.full((len(pred_inds),), _polygon_to_polygon_types.index('PRED'), dtype=torch.uint8))\n",
    "        succ_inds = []\n",
    "        for succ in lane_segment.exit_lanes:\n",
    "            succ_idx = _safe_list_index(polygon_ids, succ)\n",
    "            if succ_idx is not None:\n",
    "                succ_inds.append(succ_idx)\n",
    "        if len(succ_inds) != 0:\n",
    "            polygon_to_polygon_edge_index.append(\n",
    "                torch.stack([torch.tensor(succ_inds, dtype=torch.long),\n",
    "                             torch.full((len(succ_inds),), lane_segment_idx, dtype=torch.long)], dim=0))\n",
    "            polygon_to_polygon_type.append(\n",
    "                torch.full((len(succ_inds),), _polygon_to_polygon_types.index('SUCC'), dtype=torch.uint8))\n",
    "        if len(lane_segment.left_neighbors) != 0:\n",
    "            left_neighbor_ids = lane_segment.left_neighbors\n",
    "            for left_neighbor_id in left_neighbor_ids:\n",
    "                left_idx = _safe_list_index(polygon_ids, left_neighbor_id)\n",
    "                if left_idx is not None:\n",
    "                    polygon_to_polygon_edge_index.append(\n",
    "                        torch.tensor([[left_idx], [lane_segment_idx]], dtype=torch.long))\n",
    "                    polygon_to_polygon_type.append(\n",
    "                        torch.tensor([_polygon_to_polygon_types.index('LEFT')], dtype=torch.uint8))\n",
    "        if len(lane_segment.right_neighbors) != 0:\n",
    "            right_neighbor_ids = lane_segment.right_neighbors\n",
    "            for right_neighbor_id in right_neighbor_ids:\n",
    "                right_idx = _safe_list_index(polygon_ids, right_neighbor_id)\n",
    "                if right_idx is not None:\n",
    "                    polygon_to_polygon_edge_index.append(\n",
    "                        torch.tensor([[right_idx], [lane_segment_idx]], dtype=torch.long))\n",
    "                    polygon_to_polygon_type.append(\n",
    "                        torch.tensor([_polygon_to_polygon_types.index('RIGHT')], dtype=torch.uint8))\n",
    "    if len(polygon_to_polygon_edge_index) != 0:\n",
    "        polygon_to_polygon_edge_index = torch.cat(polygon_to_polygon_edge_index, dim=1)\n",
    "        polygon_to_polygon_type = torch.cat(polygon_to_polygon_type, dim=0)\n",
    "    else:\n",
    "        polygon_to_polygon_edge_index = torch.tensor([[], []], dtype=torch.long)\n",
    "        polygon_to_polygon_type = torch.tensor([], dtype=torch.uint8)\n",
    "\n",
    "    map_data = {\n",
    "        'map_polygon': {},\n",
    "        'map_point': {},\n",
    "        ('map_point', 'to', 'map_polygon'): {},\n",
    "        ('map_polygon', 'to', 'map_polygon'): {},\n",
    "    }\n",
    "    map_data['map_polygon']['num_nodes'] = num_polygons\n",
    "    map_data['map_polygon']['type'] = polygon_type\n",
    "    map_data['map_polygon']['light_type'] = polygon_light_type\n",
    "    if len(num_points) == 0:\n",
    "        map_data['map_point']['num_nodes'] = 0\n",
    "        map_data['map_point']['position'] = torch.tensor([], dtype=torch.float)\n",
    "        map_data['map_point']['orientation'] = torch.tensor([], dtype=torch.float)\n",
    "        map_data['map_point']['magnitude'] = torch.tensor([], dtype=torch.float)\n",
    "        if dim == 3:\n",
    "            map_data['map_point']['height'] = torch.tensor([], dtype=torch.float)\n",
    "        map_data['map_point']['type'] = torch.tensor([], dtype=torch.uint8)\n",
    "        map_data['map_point']['side'] = torch.tensor([], dtype=torch.uint8)\n",
    "    else:\n",
    "        map_data['map_point']['num_nodes'] = num_points.sum().item()\n",
    "        map_data['map_point']['position'] = torch.cat(point_position, dim=0)\n",
    "        map_data['map_point']['orientation'] = torch.cat(point_orientation, dim=0)\n",
    "        map_data['map_point']['magnitude'] = torch.cat(point_magnitude, dim=0)\n",
    "        if dim == 3:\n",
    "            map_data['map_point']['height'] = torch.cat(point_height, dim=0)\n",
    "        map_data['map_point']['type'] = torch.cat(point_type, dim=0)\n",
    "    map_data['map_point', 'to', 'map_polygon']['edge_index'] = point_to_polygon_edge_index\n",
    "    map_data['map_polygon', 'to', 'map_polygon']['edge_index'] = polygon_to_polygon_edge_index\n",
    "    map_data['map_polygon', 'to', 'map_polygon']['type'] = polygon_to_polygon_type\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # plt.axis('equal')\n",
    "    # plt.scatter(map_data['map_point']['position'][:, 0],\n",
    "    #             map_data['map_point']['position'][:, 1], s=0.2, c='black', edgecolors='none')\n",
    "    # plt.show(dpi=600)\n",
    "    return map_data\n",
    "\n",
    "map_info = save_infos[\"map_infos\"]\n",
    "tf_current_light = tf_lights.loc[tf_lights[\"time_step\"] == \"11\"]\n",
    "map_data = get_map_features(map_info, tf_current_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 获取代理特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**new_agents_array**: *array(num_track, 20)*, 详细记录轨迹相关信息\n",
    "+ `observed`\t    是否观测到该点\n",
    "+ `track_id`\t    物体的唯一轨迹ID\n",
    "+ `object_type`\t    物体类型（vehicle、pedestrian 等）\n",
    "+ `object_category`\t物体类别\n",
    "+ `timestep`\t    当前时间步\n",
    "+ `position_x`\t    x 方向位置坐标\n",
    "+ `position_y`\t    y 方向位置坐标\n",
    "+ `position_z`\t    z 方向位置坐标\n",
    "+ `length`\t        物体长度\n",
    "+ `width`\t        物体宽度\n",
    "+ `height`\t        物体高度\n",
    "+ `heading`\t        物体朝向\n",
    "+ `velocity_x`\t    x 方向速度\n",
    "+ `velocity_y`\t    y 方向速度\n",
    "+ `scenario_id`\t    场景ID\n",
    "+ `start_timestamp`\t起始时间戳\n",
    "+ `end_timestamp`\t结束时间戳\n",
    "+ `num_timestamps`\t时间步总数\n",
    "+ `focal_track_id`\t聚焦轨迹ID\n",
    "+ `city`\t        城市标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_agent(track_info, tracks_to_predict, sdc_track_index, scenario_id, start_timestamp, end_timestamp):\n",
    "    agents_array = track_info[\"trajs\"].transpose(1, 0, 2)   #[NT, NA, 10]\n",
    "    # 代理ID\n",
    "    object_id = np.array(track_info[\"object_id\"])\n",
    "    # 代理类型（str）\n",
    "    object_type = track_info[\"object_type\"]\n",
    "    # 映射关系 {代理ID：代理类型}\n",
    "    id_hash = {object_id[o_idx]: object_type[o_idx] for o_idx in range(len(object_id))}\n",
    "    def type_hash(x):\n",
    "        tp = id_hash[x]\n",
    "        type_re_hash = {\n",
    "            \"TYPE_VEHICLE\": \"vehicle\",\n",
    "            \"TYPE_PEDESTRIAN\": \"pedestrian\",\n",
    "            \"TYPE_CYCLIST\": \"cyclist\",\n",
    "            \"TYPE_OTHER\": \"background\",\n",
    "            \"TYPE_UNSET\": \"background\"\n",
    "        }\n",
    "        return type_re_hash[tp]\n",
    "\n",
    "    columns = ['observed', 'track_id', 'object_type', 'object_category', 'timestep',\n",
    "               'position_x', 'position_y', 'position_z', 'length', 'width', 'height', 'heading', 'velocity_x', 'velocity_y',\n",
    "               'scenario_id', 'start_timestamp', 'end_timestamp', 'num_timestamps',\n",
    "               'focal_track_id', 'city']\n",
    "    new_columns = np.ones((agents_array.shape[0], agents_array.shape[1], 11))\n",
    "    new_columns[:11, :, 0] = True\n",
    "    new_columns[11:, :, 0] = False\n",
    "    for index in range(new_columns.shape[0]):\n",
    "        new_columns[index, :, 4] = int(index)\n",
    "    new_columns[..., 1] = object_id\n",
    "    new_columns[..., 2] = object_id\n",
    "    new_columns[:, tracks_to_predict[\"track_index\"], 3] = 3\n",
    "    new_columns[..., 5] = 11\n",
    "    new_columns[..., 6] = int(start_timestamp)\n",
    "    new_columns[..., 7] = int(end_timestamp)\n",
    "    new_columns[..., 8] = int(91)\n",
    "    new_columns[..., 9] = object_id\n",
    "    new_columns[..., 10] = 10086\n",
    "    new_columns = new_columns\n",
    "    new_agents_array = np.concatenate([new_columns, agents_array], axis=-1)\n",
    "    new_agents_array = new_agents_array[new_agents_array[..., -1] == 1.0].reshape(-1, new_agents_array.shape[-1])\n",
    "    new_agents_array = new_agents_array[..., [0, 1, 2, 3, 4, 11, 12, 13, 14, 15, 16, 17, 18, 19, 5, 6, 7, 8, 9, 10]]\n",
    "    new_agents_array = pd.DataFrame(data=new_agents_array, columns=columns)\n",
    "    new_agents_array[\"object_type\"] = new_agents_array[\"object_type\"].apply(func=type_hash)\n",
    "    new_agents_array[\"start_timestamp\"] = new_agents_array[\"start_timestamp\"].astype(int)\n",
    "    new_agents_array[\"end_timestamp\"] = new_agents_array[\"end_timestamp\"].astype(int)\n",
    "    new_agents_array[\"num_timestamps\"] = new_agents_array[\"num_timestamps\"].astype(int)\n",
    "    new_agents_array[\"scenario_id\"] = scenario_id\n",
    "    return new_agents_array\n",
    "\n",
    "\n",
    "track_info = save_infos['track_infos']\n",
    "tracks_to_predict = save_infos['tracks_to_predict']\n",
    "assert len(tracks_to_predict[\"track_index\"]) >= 1 \n",
    "sdc_track_index = save_infos['sdc_track_index']\n",
    "scenario_id = save_infos['scenario_id']\n",
    "\n",
    "new_agents_array = process_agent(track_info, tracks_to_predict, sdc_track_index, scenario_id, 0, 91) # mtr2argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_unseen_agents = False\n",
    "vector_repr = True\n",
    "split = 'train'\n",
    "\n",
    "def get_agent_features(df: pd.DataFrame, av_id, num_historical_steps=10, dim=3, num_steps=91) -> Dict[str, Any]:\n",
    "    _agent_types = ['vehicle', 'pedestrian', 'cyclist', 'background']\n",
    "    \n",
    "    if not predict_unseen_agents:  # filter out agents that are unseen during the historical time steps\n",
    "        historical_df = df[df['timestep'] == num_historical_steps-1]\n",
    "        agent_ids = list(historical_df['track_id'].unique())\n",
    "        df = df[df['track_id'].isin(agent_ids)]\n",
    "    else:\n",
    "        agent_ids = list(df['track_id'].unique())\n",
    "\n",
    "    num_agents = len(agent_ids)\n",
    "\n",
    "    # 代理是否处在有效状态\n",
    "    valid_mask = torch.zeros(num_agents, num_steps, dtype=torch.bool)\n",
    "    # 代理在当前帧是否有效\n",
    "    current_valid_mask = torch.zeros(num_agents, dtype=torch.bool)\n",
    "    # 是否需要预测\n",
    "    predict_mask = torch.zeros(num_agents, num_steps, dtype=torch.bool)\n",
    "    # 代理ID\n",
    "    agent_id: List[Optional[str]] = [None] * num_agents\n",
    "    # 代理类型：0 'vehicle', 1 'pedestrian', 2 'cyclist', 3 'background'\n",
    "    agent_type = torch.zeros(num_agents, dtype=torch.uint8)\n",
    "    # 代理类别：1 其他代理, 3 应该被预测代理\n",
    "    agent_category = torch.zeros(num_agents, dtype=torch.uint8)\n",
    "    # 代理位置 [NA, NT, 3] (x, y, z)\n",
    "    position = torch.zeros(num_agents, num_steps, dim, dtype=torch.float)\n",
    "    # 代理航向 [NA, NT]\n",
    "    heading = torch.zeros(num_agents, num_steps, dtype=torch.float)\n",
    "    # 代理速度 [NA, NT, 3] (vx, vy, 0)\n",
    "    velocity = torch.zeros(num_agents, num_steps, dim, dtype=torch.float)\n",
    "    # 代理尺寸 [NA, NT, 3] (length, width, height)\n",
    "    shape = torch.zeros(num_agents, num_steps, dim, dtype=torch.float)\n",
    "\n",
    "    for track_id, track_df in df.groupby('track_id'):\n",
    "        agent_idx = agent_ids.index(track_id)\n",
    "        agent_steps = track_df['timestep'].values\n",
    "\n",
    "        # 与tracks中提供的valid一致\n",
    "        valid_mask[agent_idx, agent_steps] = True\n",
    "        # 当前帧是否可用\n",
    "        current_valid_mask[agent_idx] = valid_mask[agent_idx, num_historical_steps - 1]\n",
    "        # 与tracks中提供的valid一致\n",
    "        predict_mask[agent_idx, agent_steps] = True\n",
    "        # 当前时间步 t 的有效性依赖于 t 和 t-1 的有效性。\n",
    "        if vector_repr:  # a time step t is valid only when both t and t-1 are valid\n",
    "            valid_mask[agent_idx, 1: num_historical_steps] = (\n",
    "                valid_mask[agent_idx, :num_historical_steps - 1] &\n",
    "                valid_mask[agent_idx, 1: num_historical_steps])\n",
    "            valid_mask[agent_idx, 0] = False\n",
    "        # 设置历史时间步的预测掩码为无效\n",
    "        predict_mask[agent_idx, :num_historical_steps] = False\n",
    "        # 如果当前帧无效，设置后续时间步的预测掩码为无效\n",
    "        if not current_valid_mask[agent_idx]:\n",
    "            predict_mask[agent_idx, num_historical_steps:] = False\n",
    "\n",
    "        agent_id[agent_idx] = track_id\n",
    "        agent_type[agent_idx] = _agent_types.index(track_df['object_type'].values[0])\n",
    "        agent_category[agent_idx] = track_df['object_category'].values[0]\n",
    "        position[agent_idx, agent_steps, :3] = torch.from_numpy(np.stack([track_df['position_x'].values,\n",
    "                                                                          track_df['position_y'].values,\n",
    "                                                                          track_df['position_z'].values],\n",
    "                                                                         axis=-1)).float()\n",
    "        heading[agent_idx, agent_steps] = torch.from_numpy(track_df['heading'].values).float()\n",
    "        velocity[agent_idx, agent_steps, :2] = torch.from_numpy(np.stack([track_df['velocity_x'].values,\n",
    "                                                                          track_df['velocity_y'].values],\n",
    "                                                                         axis=-1)).float()\n",
    "        shape[agent_idx, agent_steps, :3] = torch.from_numpy(np.stack([track_df['length'].values,\n",
    "                                                                       track_df['width'].values,\n",
    "                                                                       track_df[\"height\"].values],\n",
    "                                                                      axis=-1)).float()\n",
    "    av_idx = agent_id.index(av_id)\n",
    "    if split == 'test':\n",
    "        predict_mask[current_valid_mask\n",
    "                     | (agent_category == 2)\n",
    "                     | (agent_category == 3), num_historical_steps:] = True\n",
    "\n",
    "    return {\n",
    "        'num_nodes': num_agents,\n",
    "        'av_index': av_idx,\n",
    "        'valid_mask': valid_mask,\n",
    "        'predict_mask': predict_mask,\n",
    "        'id': agent_id,\n",
    "        'type': agent_type,\n",
    "        'category': agent_category,\n",
    "        'position': position,\n",
    "        'heading': heading,\n",
    "        'velocity': velocity,\n",
    "        'shape': shape\n",
    "    }\n",
    "\n",
    "av_id = track_info[\"object_id\"][sdc_track_index]\n",
    "agent_features = get_agent_features(new_agents_array, av_id, num_historical_steps=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 组织预处理的data信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data**\n",
    "+ `scenario_id`: *str*, 场景id\n",
    "+ `city`: *float*, 场景所属城市编号（默认10086）\n",
    "+ `agent`: *dict*, 场景中的代理信息\n",
    "    - `num_nodes`: *int*, 代理数量\n",
    "    - `av_index`: *int*, AV对应的代理编号\n",
    "    - `valid_mask`: *array([NA, NT])*, 各代理各时间步是否有效\n",
    "    - `predict_mask`: *array([NA, NT])*, 各代理需要被预测的时间步\n",
    "    - `id`: *list([NA])*, 代理ID \n",
    "    - `type`: *array([NA])*, 代理类型\n",
    "        > 0 'vehicle', 1 'pedestrian', 2 'cyclist', 3 'background'\n",
    "    - `category`: *array([NA])*, 代理类别\n",
    "        > 1 其他代理, 2 感兴趣代理, 3 被预测代理\n",
    "    - `position`: *array([NA, NT, 3])*, 代理位置 (x, y, z)\n",
    "    - `heading`: *array([NA, NT])*, 代理航向\n",
    "    - `velocity`: *array([NA, NT, 3])*, 代理速度 (vx, vy, 0)\n",
    "    - `shape`: *array([NA, NT, 3])*, 代理尺寸 (length, width, height)\n",
    "+ `map_polygon`: *dict*, 地图中多段线信息\n",
    "    - `num_nodes`: *int*, 多段线数量\n",
    "    - `type`: *array([num_nodes])*, 每条多段线对应的类型\n",
    "        > ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "    - `light_type`: *array([num_nodes])*, 每条多段线对应的交通信号状态\n",
    "        > ['LANE_STATE_STOP', 'LANE_STATE_GO', 'LANE_STATE_CAUTION', 'LANE_STATE_UNKNOWN']\n",
    "+ `map_point`: *dict*, 地图中各点信息\n",
    "    - `num_nodes`: *int*, 点数量\n",
    "    - `position`: *array([num_nodes, 3])*, 点的坐标(x, y, z)\n",
    "    - `orientation`: *array([num_nodes])*, 各点对应向量的方向角（以弧度表示）\n",
    "    - `magnitude`: *array([num_nodes])*, 各点对应向量的大小（即距离）\n",
    "    - `height`: *array([num_nodes])*, 各点与下一点之间的高度差 *(dim=3时才存在)*\n",
    "    - `type`: *array([num_nodes])*, 各点所属类型\n",
    "        > [ 'DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "            'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "            'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "            'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "+ `'map_point', 'to', 'map_polygon'`: *dict*, 点与多段线之间的索引映射关系\n",
    "    - `edge_index`: *array([2, num_points])*, [point_idx, polygon_idx]\n",
    "+ `'map_polygon', 'to', 'map_polygon'`: *dict*, 车道与车道之间的拓扑关系\n",
    "    - `edge_index`: *array([2, num_edges])*, [polygon1_idx, polygon2_idx]\n",
    "    - `type`: *array([num_edges])*, 拓扑关系类型-polygon1是polygon2的前驱/后继/左邻居/右邻居\n",
    "        > ['NONE', 'PRED', 'SUCC', 'LEFT', 'RIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['scenario_id'] = new_agents_array['scenario_id'].values[0]\n",
    "data['city'] = new_agents_array['city'].values[0]\n",
    "data['agent'] = agent_features\n",
    "data.update(map_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 数据加载时token化预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**agent_token_data**\n",
    "\n",
    "聚类得到的token信息，即以[0,0]为第一帧中心坐标，五帧为时间间隔到达的终点位置\n",
    "\n",
    "+ `token`: *dict*, 每个token对应的终点位置矩形的四个角点坐标(x, y)，**角点顺序为-左前、右前、右后、左后**\n",
    "    - `veh`: *array([2048, 4, 2])*\n",
    "    - `ped`: *array([2048, 4, 2])*\n",
    "    - `cyc`: *array([2048, 4, 2])*\n",
    "+ `traj`: *dict*, 每个token对应的6帧完整轨迹中心坐标 (x, y ,z)\n",
    "    - `veh`: *array([2048, 6, 3])*\n",
    "    - `ped`: *array([2048, 6, 3])*\n",
    "    - `cyc`: *array([2048, 6, 3])*\n",
    "+ `token_all`: *dict*, 每个token对应的6帧完整轨迹各处矩形四个角点坐标\n",
    "    - `veh`: *array([2048, 6, 4, 2])*\n",
    "    - `ped`: *array([2048, 6, 4, 2])*\n",
    "    - `cyc`: *array([2048, 6, 4, 2])*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "current_step = 10\n",
    "shift = 5\n",
    "noise = True\n",
    "training = False\n",
    "\n",
    "agent_token_path = \"/home/yangyh408/codes/SMART/smart/tokens/cluster_frame_5_2048.pkl\"\n",
    "agent_token_data = pickle.load(open(agent_token_path, 'rb'))\n",
    "trajectory_token = agent_token_data['token']\n",
    "trajectory_token_all = agent_token_data['token_all']\n",
    "# 对所有token依据倒数第二帧的状态为基准状态对最后一帧进行归一化\n",
    "token_last_all = {}\n",
    "\n",
    "for k, v in trajectory_token_all.items():\n",
    "    # 计算每个 agent 的最终 token 朝向\n",
    "    token_last = torch.from_numpy(v[:, -2:]).to(torch.float)    # [2048, 2, 4, 2]\n",
    "    diff_xy = token_last[:, 0, 0] - token_last[:, 0, 3]         # 倒数第二帧 左前-左后\n",
    "    theta = torch.arctan2(diff_xy[:, 1], diff_xy[:, 0])         # 倒数第二帧的航向角\n",
    "    cos, sin = theta.cos(), theta.sin()\n",
    "    # 生成旋转矩阵\n",
    "    rot_mat = theta.new_zeros(token_last.shape[0], 2, 2)\n",
    "    rot_mat[:, 0, 0] = cos\n",
    "    rot_mat[:, 0, 1] = -sin\n",
    "    rot_mat[:, 1, 0] = sin\n",
    "    rot_mat[:, 1, 1] = cos\n",
    "    # 应用旋转矩阵并归一化 token 数据\n",
    "    agent_token = torch.bmm(token_last[:, 1], rot_mat)\n",
    "    agent_token -= token_last[:, 0].mean(1)[:, None, :]\n",
    "    token_last_all[k] = agent_token.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_heading(data):\n",
    "    \"\"\"\n",
    "        这个函数 clean_heading 的主要功能是对“heading” (朝向角度) 进行清理，以修复明显异常或突然变化的朝向角度\n",
    "        （例如，当相邻帧之间的朝向差异超过一定阈值时），从而平滑朝向数据。\n",
    "        具体而言，代码通过对相邻帧的朝向差异进行检测和修正，使得朝向变化更连贯。\n",
    "    \"\"\"\n",
    "    heading = data['agent']['heading']\n",
    "    valid = data['agent']['valid_mask']\n",
    "    pi = torch.tensor(torch.pi)\n",
    "    n_vehicles, n_frames = heading.shape\n",
    "\n",
    "    heading_diff_raw = heading[:, :-1] - heading[:, 1:]\n",
    "    heading_diff = torch.remainder(heading_diff_raw + pi, 2 * pi) - pi\n",
    "    heading_diff[heading_diff > pi] -= 2 * pi\n",
    "    heading_diff[heading_diff < -pi] += 2 * pi\n",
    "\n",
    "    valid_pairs = valid[:, :-1] & valid[:, 1:]\n",
    "\n",
    "    for i in range(n_frames - 1):\n",
    "        change_needed = (torch.abs(heading_diff[:, i:i + 1]) > 1.0) & valid_pairs[:, i:i + 1]\n",
    "\n",
    "        heading[:, i + 1][change_needed.squeeze()] = heading[:, i][change_needed.squeeze()]\n",
    "\n",
    "        if i < n_frames - 2:\n",
    "            heading_diff_raw = heading[:, i + 1] - heading[:, i + 2]\n",
    "            heading_diff[:, i + 1] = torch.remainder(heading_diff_raw + pi, 2 * pi) - pi\n",
    "            heading_diff[heading_diff[:, i + 1] > pi] -= 2 * pi\n",
    "            heading_diff[heading_diff[:, i + 1] < -pi] += 2 * pi\n",
    "\n",
    "def cal_polygon_contour(x, y, theta, width, length):\n",
    "    \"\"\"\n",
    "        函数功能：计算一个矩形多边形的四个顶点坐标（轮廓）\n",
    "        返回值：返回一个形状为 [n, 4, 2] 的数组 polygon_contour，表示每个矩形的四个顶点的坐标，方便后续用作绘制或碰撞检测等应用。\n",
    "    \"\"\"\n",
    "    left_front_x = x + 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_front_y = y + 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_front = np.column_stack((left_front_x, left_front_y))\n",
    "\n",
    "    right_front_x = x + 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_front_y = y + 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_front = np.column_stack((right_front_x, right_front_y))\n",
    "\n",
    "    right_back_x = x - 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_back_y = y - 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_back = np.column_stack((right_back_x, right_back_y))\n",
    "\n",
    "    left_back_x = x - 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_back_y = y - 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_back = np.column_stack((left_back_x, left_back_y))\n",
    "\n",
    "    polygon_contour = np.concatenate(\n",
    "        (left_front[:, None, :], right_front[:, None, :], right_back[:, None, :], left_back[:, None, :]), axis=1)\n",
    "\n",
    "    return polygon_contour\n",
    "\n",
    "def match_token(pos, valid_mask, heading, category, agent_category, extra_mask):\n",
    "    \"\"\"\n",
    "        将轨迹位置和朝向数据与预定义的 token 数据进行匹配，以便在场景中的每个时间步中都能追踪到正确的 token。\n",
    "    \"\"\"\n",
    "    agent_token_src = trajectory_token[category]\n",
    "    token_last = token_last_all[category]\n",
    "    if shift <= 2:\n",
    "        if category == 'veh':\n",
    "            width = 1.0\n",
    "            length = 2.4\n",
    "        elif category == 'cyc':\n",
    "            width = 0.5\n",
    "            length = 1.5\n",
    "        else:\n",
    "            width = 0.5\n",
    "            length = 0.5\n",
    "    else:\n",
    "        if category == 'veh':\n",
    "            width = 2.0\n",
    "            length = 4.8\n",
    "        elif category == 'cyc':\n",
    "            width = 1.0\n",
    "            length = 2.0\n",
    "        else:\n",
    "            width = 1.0\n",
    "            length = 1.0\n",
    "\n",
    "    prev_heading = heading[:, 0]\n",
    "    prev_pos = pos[:, 0]\n",
    "    agent_num, num_step, feat_dim = pos.shape   # [NA, 91, 2]\n",
    "    token_num, token_contour_dim, feat_dim = agent_token_src.shape  # [2048, 4, 2]\n",
    "    agent_token_src = agent_token_src.reshape(1, token_num * token_contour_dim, feat_dim).repeat(agent_num, 0)\n",
    "    token_last = token_last.reshape(1, token_num * token_contour_dim, feat_dim).repeat(extra_mask.sum(), 0)\n",
    "    token_index_list = []\n",
    "    token_contour_list = []\n",
    "    prev_token_idx = None\n",
    "\n",
    "    for i in range(shift, pos.shape[1], shift):\n",
    "        # 上一token所在位置航向角（5帧前）\n",
    "        theta = prev_heading\n",
    "        # 当前航向角和位置\n",
    "        cur_heading = heading[:, i]\n",
    "        cur_pos = pos[:, i]\n",
    "        # 将归一化的原始token信息以上一时刻位置和航向状态为基准调整到全局坐标系\n",
    "        cos, sin = theta.cos(), theta.sin()\n",
    "        rot_mat = theta.new_zeros(agent_num, 2, 2)\n",
    "        rot_mat[:, 0, 0] = cos\n",
    "        rot_mat[:, 0, 1] = sin\n",
    "        rot_mat[:, 1, 0] = -sin\n",
    "        rot_mat[:, 1, 1] = cos\n",
    "        agent_token_world = torch.bmm(torch.from_numpy(agent_token_src).to(torch.float), rot_mat).reshape(agent_num,\n",
    "                                                                                                            token_num,\n",
    "                                                                                                            token_contour_dim,\n",
    "                                                                                                            feat_dim)\n",
    "        agent_token_world += prev_pos[:, None, None, :]\n",
    "\n",
    "        # 获取当前所在位置的矩形四角信息\n",
    "        cur_contour = cal_polygon_contour(cur_pos[:, 0], cur_pos[:, 1], cur_heading, width, length)\n",
    "        # 找出与当前距离最近的token作为匹配对象，记录该tokenid\n",
    "        agent_token_index = torch.from_numpy(np.argmin(\n",
    "            np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)), axis=2),\n",
    "            axis=-1))\n",
    "        if prev_token_idx is not None and noise:\n",
    "            same_idx = prev_token_idx == agent_token_index\n",
    "            same_idx[:] = True\n",
    "            topk_indices = np.argsort(\n",
    "                np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)),\n",
    "                        axis=2), axis=-1)[:, :5]\n",
    "            sample_topk = np.random.choice(range(0, topk_indices.shape[1]), topk_indices.shape[0])\n",
    "            agent_token_index[same_idx] = \\\n",
    "                torch.from_numpy(topk_indices[np.arange(topk_indices.shape[0]), sample_topk])[same_idx]\n",
    "        # 将匹配的tokenid转换为矩形四角坐标\n",
    "        token_contour_select = agent_token_world[torch.arange(agent_num), agent_token_index]\n",
    "\n",
    "        # 将当前帧信息更新为上一帧信息\n",
    "        diff_xy = token_contour_select[:, 0, :] - token_contour_select[:, 3, :]\n",
    "        # 数据集中原航向角\n",
    "        prev_heading = heading[:, i].clone()\n",
    "        # 如果是这一帧被预测的对象，则用当前token所在状态更新航向和位置信息\n",
    "        prev_heading[valid_mask[:, i - shift]] = torch.arctan2(diff_xy[:, 1], diff_xy[:, 0])[\n",
    "            valid_mask[:, i - shift]]\n",
    "\n",
    "        prev_pos = pos[:, i].clone()\n",
    "        prev_pos[valid_mask[:, i - shift]] = token_contour_select.mean(dim=1)[valid_mask[:, i - shift]]\n",
    "        prev_token_idx = agent_token_index\n",
    "        token_index_list.append(agent_token_index[:, None])\n",
    "        token_contour_list.append(token_contour_select[:, None, ...])\n",
    "\n",
    "    token_index = torch.cat(token_index_list, dim=1)\n",
    "    token_contour = torch.cat(token_contour_list, dim=1)\n",
    "\n",
    "    # extra matching（如果在第十一帧存在但第六帧不存在的代理，则根据第十帧的状态来匹配token信息）\n",
    "    if not training:\n",
    "        theta = heading[extra_mask, current_step - 1]\n",
    "        prev_pos = pos[extra_mask, current_step - 1]\n",
    "        cur_pos = pos[extra_mask, current_step]\n",
    "        cur_heading = heading[extra_mask, current_step]\n",
    "        cos, sin = theta.cos(), theta.sin()\n",
    "        rot_mat = theta.new_zeros(extra_mask.sum(), 2, 2)\n",
    "        rot_mat[:, 0, 0] = cos\n",
    "        rot_mat[:, 0, 1] = sin\n",
    "        rot_mat[:, 1, 0] = -sin\n",
    "        rot_mat[:, 1, 1] = cos\n",
    "        agent_token_world = torch.bmm(torch.from_numpy(token_last).to(torch.float), rot_mat).reshape(\n",
    "            extra_mask.sum(), token_num, token_contour_dim, feat_dim)\n",
    "        agent_token_world += prev_pos[:, None, None, :]\n",
    "\n",
    "        cur_contour = cal_polygon_contour(cur_pos[:, 0], cur_pos[:, 1], cur_heading, width, length)\n",
    "        agent_token_index = torch.from_numpy(np.argmin(\n",
    "            np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)), axis=2),\n",
    "            axis=-1))\n",
    "        token_contour_select = agent_token_world[torch.arange(extra_mask.sum()), agent_token_index]\n",
    "\n",
    "        token_index[extra_mask, 1] = agent_token_index\n",
    "        token_contour[extra_mask, 1] = token_contour_select\n",
    "\n",
    "    return token_index, token_contour\n",
    "\n",
    "def tokenize_agent(data):\n",
    "    if data['agent'][\"velocity\"].shape[1] == 90:\n",
    "        print(data['scenario_id'], data['agent'][\"velocity\"].shape)\n",
    "    \n",
    "    # 创建插值掩码 interplote_mask，用于标记那些当前时间步为无效但坐标非零的位置，以确定需要插值的数据点\n",
    "    interplote_mask = (data['agent']['valid_mask'][:, current_step] == False) * (\n",
    "            data['agent']['position'][:, current_step, 0] != 0)\n",
    "    # 通过检查当前时间步中无效但位置非零的轨迹点，将其前一个时间步的位置、速度、航向等信息进行估算和填充，确保轨迹数据连续性\n",
    "    if data['agent'][\"velocity\"].shape[-1] == 2:\n",
    "        data['agent'][\"velocity\"] = torch.cat([data['agent'][\"velocity\"],\n",
    "                                                torch.zeros(data['agent'][\"velocity\"].shape[0],\n",
    "                                                            data['agent'][\"velocity\"].shape[1], 1)], dim=-1)\n",
    "    vel = data['agent'][\"velocity\"][interplote_mask, current_step]\n",
    "    # 插值前一个时间步的位置、航向、速度\n",
    "    data['agent']['position'][interplote_mask, current_step - 1, :3] = data['agent']['position'][\n",
    "                                                                            interplote_mask, current_step,\n",
    "                                                                            :3] - vel * 0.1\n",
    "    data['agent']['heading'][interplote_mask, current_step - 1] = data['agent']['heading'][\n",
    "        interplote_mask, current_step]\n",
    "    data['agent'][\"velocity\"][interplote_mask, current_step - 1] = data['agent'][\"velocity\"][\n",
    "        interplote_mask, current_step]\n",
    "    data['agent']['valid_mask'][interplote_mask, current_step - 1:current_step + 1] = True\n",
    "\n",
    "    data['agent']['type'] = data['agent']['type'].to(torch.uint8)\n",
    "\n",
    "    clean_heading(data)\n",
    "    matching_extra_mask = (data['agent']['valid_mask'][:, current_step] == True) * (\n",
    "            data['agent']['valid_mask'][:, current_step - 5] == False)\n",
    "\n",
    "    interplote_mask_first = (data['agent']['valid_mask'][:, 0] == False) * (data['agent']['position'][:, 0, 0] != 0)\n",
    "    data['agent']['valid_mask'][interplote_mask_first, 0] = True\n",
    "\n",
    "    agent_pos = data['agent']['position'][:, :, :2]\n",
    "    valid_mask = data['agent']['valid_mask']\n",
    "    # 以下标1为起点，长度为6，间隔为5创建滑动窗口\n",
    "    valid_mask_shift = valid_mask.unfold(1, shift + 1, shift)         # [NA, 18, 6]\n",
    "    # 每个滑动窗口的起止都为true时窗口才有效\n",
    "    token_valid_mask = valid_mask_shift[:, :, 0] * valid_mask_shift[:, :, -1]   # [NA, 18]\n",
    "    agent_type = data['agent']['type']\n",
    "    agent_category = data['agent']['category']\n",
    "    agent_heading = data['agent']['heading']\n",
    "    vehicle_mask = agent_type == 0\n",
    "    cyclist_mask = agent_type == 2\n",
    "    ped_mask = agent_type == 1\n",
    "\n",
    "    veh_pos = agent_pos[vehicle_mask, :, :]\n",
    "    veh_valid_mask = valid_mask[vehicle_mask, :]\n",
    "    cyc_pos = agent_pos[cyclist_mask, :, :]\n",
    "    cyc_valid_mask = valid_mask[cyclist_mask, :]\n",
    "    ped_pos = agent_pos[ped_mask, :, :]\n",
    "    ped_valid_mask = valid_mask[ped_mask, :]\n",
    "\n",
    "    veh_token_index, veh_token_contour = match_token(veh_pos, veh_valid_mask, agent_heading[vehicle_mask],\n",
    "                                                            'veh', agent_category[vehicle_mask],\n",
    "                                                            matching_extra_mask[vehicle_mask])\n",
    "    ped_token_index, ped_token_contour = match_token(ped_pos, ped_valid_mask, agent_heading[ped_mask], 'ped',\n",
    "                                                            agent_category[ped_mask], matching_extra_mask[ped_mask])\n",
    "    cyc_token_index, cyc_token_contour = match_token(cyc_pos, cyc_valid_mask, agent_heading[cyclist_mask],\n",
    "                                                            'cyc', agent_category[cyclist_mask],\n",
    "                                                            matching_extra_mask[cyclist_mask])\n",
    "\n",
    "    # token_index: [NA, 18(90/5)] 每个代理在90帧中匹配到的18个token索引\n",
    "    token_index = torch.zeros((agent_pos.shape[0], veh_token_index.shape[1])).to(torch.int64)\n",
    "    token_index[vehicle_mask] = veh_token_index\n",
    "    token_index[ped_mask] = ped_token_index\n",
    "    token_index[cyclist_mask] = cyc_token_index\n",
    "\n",
    "    # token_contour: [NA, 18, 4, 2] 每个代理在90帧中匹配到的18个token对应的矩形信息\n",
    "    token_contour = torch.zeros((agent_pos.shape[0], veh_token_contour.shape[1],\n",
    "                                    veh_token_contour.shape[2], veh_token_contour.shape[3]))\n",
    "    token_contour[vehicle_mask] = veh_token_contour\n",
    "    token_contour[ped_mask] = ped_token_contour\n",
    "    token_contour[cyclist_mask] = cyc_token_contour\n",
    "\n",
    "    # trajectory_token_veh = torch.from_numpy(trajectory_token['veh']).clone().to(torch.float)\n",
    "    # trajectory_token_ped = torch.from_numpy(trajectory_token['ped']).clone().to(torch.float)\n",
    "    # trajectory_token_cyc = torch.from_numpy(trajectory_token['cyc']).clone().to(torch.float)\n",
    "\n",
    "    # agent_token_traj = torch.zeros((agent_pos.shape[0], trajectory_token_veh.shape[0], 4, 2))\n",
    "    # agent_token_traj[vehicle_mask] = trajectory_token_veh\n",
    "    # agent_token_traj[ped_mask] = trajectory_token_ped\n",
    "    # agent_token_traj[cyclist_mask] = trajectory_token_cyc\n",
    "\n",
    "    if not training:\n",
    "        token_valid_mask[matching_extra_mask, 1] = True\n",
    "\n",
    "    data['agent']['token_idx'] = token_index            # [NA, 18]\n",
    "    data['agent']['token_contour'] = token_contour      # [NA, 18, 4, 2]\n",
    "    token_pos = token_contour.mean(dim=2)               \n",
    "    data['agent']['token_pos'] = token_pos              # [NA, 18, 2]\n",
    "    diff_xy = token_contour[:, :, 0, :] - token_contour[:, :, 3, :]\n",
    "    data['agent']['token_heading'] = torch.arctan2(diff_xy[:, :, 1], diff_xy[:, :, 0])  # [NA, 18]\n",
    "    data['agent']['agent_valid_mask'] = token_valid_mask                                # [NA, 18]\n",
    "\n",
    "    vel = torch.cat([token_pos.new_zeros(data['agent']['num_nodes'], 1, 2),\n",
    "                        ((token_pos[:, 1:] - token_pos[:, :-1]) / (0.1 * shift))], dim=1)\n",
    "    vel_valid_mask = torch.cat([torch.zeros(token_valid_mask.shape[0], 1, dtype=torch.bool),\n",
    "                                (token_valid_mask * token_valid_mask.roll(shifts=1, dims=1))[:, 1:]], dim=1)\n",
    "    vel[~vel_valid_mask] = 0\n",
    "    vel[data['agent']['valid_mask'][:, current_step], 1] = data['agent']['velocity'][\n",
    "                                                                data['agent']['valid_mask'][:, current_step],\n",
    "                                                                current_step, :2]\n",
    "\n",
    "    data['agent']['token_velocity'] = vel\n",
    "\n",
    "    return data\n",
    "\n",
    "token_data = tokenize_agent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def wrap_angle(\n",
    "        angle: torch.Tensor,\n",
    "        min_val: float = -math.pi,\n",
    "        max_val: float = math.pi) -> torch.Tensor:\n",
    "    return min_val + (angle + max_val) % (max_val - min_val)\n",
    "\n",
    "def interplating_polyline(polylines, heading, distance=0.5, split_distace=5):\n",
    "    # 多段线切分长度为5米，多段线内部点之间距离为2.5米，即每条多段线由3个点构成\n",
    "    # Calculate the cumulative distance along the path, up-sample the polyline to 0.5 meter\n",
    "    dist_along_path_list = [[0]]\n",
    "    polylines_list = [[polylines[0]]]\n",
    "    for i in range(1, polylines.shape[0]):\n",
    "        euclidean_dist = euclidean(polylines[i, :2], polylines[i - 1, :2])\n",
    "        heading_diff = min(abs(max(heading[i], heading[i - 1]) - min(heading[1], heading[i - 1])),\n",
    "                           abs(max(heading[i], heading[i - 1]) - min(heading[1], heading[i - 1]) + math.pi))\n",
    "        if heading_diff > math.pi / 4 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif heading_diff > math.pi / 8 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif heading_diff > 0.1 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif euclidean_dist > 10:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        else:\n",
    "            dist_along_path_list[-1].append(dist_along_path_list[-1][-1] + euclidean_dist)\n",
    "            polylines_list[-1].append(polylines[i])\n",
    "    # plt.plot(polylines[:, 0], polylines[:, 1])\n",
    "    # plt.savefig('tmp.jpg')\n",
    "    new_x_list = []\n",
    "    new_y_list = []\n",
    "    multi_polylines_list = []\n",
    "    for idx in range(len(dist_along_path_list)):\n",
    "        if len(dist_along_path_list[idx]) < 2:\n",
    "            continue\n",
    "        dist_along_path = np.array(dist_along_path_list[idx])\n",
    "        polylines_cur = np.array(polylines_list[idx])\n",
    "        # Create interpolation functions for x and y coordinates\n",
    "        fx = interp1d(dist_along_path, polylines_cur[:, 0])\n",
    "        fy = interp1d(dist_along_path, polylines_cur[:, 1])\n",
    "        # fyaw = interp1d(dist_along_path, heading)\n",
    "\n",
    "        # Create an array of distances at which to interpolate\n",
    "        new_dist_along_path = np.arange(0, dist_along_path[-1], distance)\n",
    "        new_dist_along_path = np.concatenate([new_dist_along_path, dist_along_path[[-1]]])\n",
    "        # Use the interpolation functions to generate new x and y coordinates\n",
    "        new_x = fx(new_dist_along_path)\n",
    "        new_y = fy(new_dist_along_path)\n",
    "        # new_yaw = fyaw(new_dist_along_path)\n",
    "        new_x_list.append(new_x)\n",
    "        new_y_list.append(new_y)\n",
    "\n",
    "        # Combine the new x and y coordinates into a single array\n",
    "        new_polylines = np.vstack((new_x, new_y)).T\n",
    "        polyline_size = int(split_distace / distance)\n",
    "        if new_polylines.shape[0] >= (polyline_size + 1):\n",
    "            padding_size = (new_polylines.shape[0] - (polyline_size + 1)) % polyline_size\n",
    "            final_index = (new_polylines.shape[0] - (polyline_size + 1)) // polyline_size + 1\n",
    "        else:\n",
    "            padding_size = new_polylines.shape[0]\n",
    "            final_index = 0\n",
    "        multi_polylines = None\n",
    "        new_polylines = torch.from_numpy(new_polylines)\n",
    "        new_heading = torch.atan2(new_polylines[1:, 1] - new_polylines[:-1, 1],\n",
    "                                  new_polylines[1:, 0] - new_polylines[:-1, 0])\n",
    "        new_heading = torch.cat([new_heading, new_heading[-1:]], -1)[..., None]\n",
    "        new_polylines = torch.cat([new_polylines, new_heading], -1)\n",
    "        if new_polylines.shape[0] >= (polyline_size + 1):\n",
    "            multi_polylines = new_polylines.unfold(dimension=0, size=polyline_size + 1, step=polyline_size)\n",
    "            multi_polylines = multi_polylines.transpose(1, 2)\n",
    "            multi_polylines = multi_polylines[:, ::5, :]\n",
    "        if padding_size >= 3:\n",
    "            last_polyline = new_polylines[final_index * polyline_size:]\n",
    "            last_polyline = last_polyline[torch.linspace(0, last_polyline.shape[0] - 1, steps=3).long()]\n",
    "            if multi_polylines is not None:\n",
    "                multi_polylines = torch.cat([multi_polylines, last_polyline.unsqueeze(0)], dim=0)\n",
    "            else:\n",
    "                multi_polylines = last_polyline.unsqueeze(0)\n",
    "        if multi_polylines is None:\n",
    "            continue\n",
    "        multi_polylines_list.append(multi_polylines)\n",
    "    if len(multi_polylines_list) > 0:\n",
    "        multi_polylines_list = torch.cat(multi_polylines_list, dim=0)\n",
    "    else:\n",
    "        multi_polylines_list = None\n",
    "    return multi_polylines_list\n",
    "\n",
    "def tokenize_map(data):\n",
    "    data['map_polygon']['type'] = data['map_polygon']['type'].to(torch.uint8)\n",
    "    data['map_point']['type'] = data['map_point']['type'].to(torch.uint8)\n",
    "    pt2pl = data[('map_point', 'to', 'map_polygon')]['edge_index']\n",
    "    pt_type = data['map_point']['type'].to(torch.uint8)\n",
    "    pt_side = torch.zeros_like(pt_type)\n",
    "    pt_pos = data['map_point']['position'][:, :2]\n",
    "    data['map_point']['orientation'] = wrap_angle(data['map_point']['orientation'])\n",
    "    pt_heading = data['map_point']['orientation']\n",
    "    split_polyline_type = []\n",
    "    split_polyline_pos = []\n",
    "    split_polyline_theta = []\n",
    "    split_polyline_side = []\n",
    "    pl_idx_list = []\n",
    "    split_polygon_type = []\n",
    "    data['map_point']['type'].unique()\n",
    "\n",
    "    # 对多段线进行便利\n",
    "    for i in sorted(np.unique(pt2pl[1])):\n",
    "        # 每一条多段线对应的点\n",
    "        index = pt2pl[0, pt2pl[1] == i]\n",
    "        polygon_type = data['map_polygon'][\"type\"][i]\n",
    "        cur_side = pt_side[index]\n",
    "        cur_type = pt_type[index]\n",
    "        cur_pos = pt_pos[index]\n",
    "        cur_heading = pt_heading[index]\n",
    "\n",
    "        for side_val in np.unique(cur_side):\n",
    "            for type_val in np.unique(cur_type):\n",
    "                if type_val == 13:\n",
    "                    continue\n",
    "                indices = np.where((cur_side == side_val) & (cur_type == type_val))[0]\n",
    "                if len(indices) <= 2:\n",
    "                    continue\n",
    "                split_polyline = interplating_polyline(cur_pos[indices].numpy(), cur_heading[indices].numpy())\n",
    "                if split_polyline is None:\n",
    "                    continue\n",
    "                new_cur_type = cur_type[indices][0]\n",
    "                new_cur_side = cur_side[indices][0]\n",
    "                map_polygon_type = polygon_type.repeat(split_polyline.shape[0])\n",
    "                new_cur_type = new_cur_type.repeat(split_polyline.shape[0])\n",
    "                new_cur_side = new_cur_side.repeat(split_polyline.shape[0])\n",
    "                cur_pl_idx = torch.Tensor([i])\n",
    "                new_cur_pl_idx = cur_pl_idx.repeat(split_polyline.shape[0])\n",
    "                split_polyline_pos.append(split_polyline[..., :2])\n",
    "                split_polyline_theta.append(split_polyline[..., 2])\n",
    "                split_polyline_type.append(new_cur_type)\n",
    "                split_polyline_side.append(new_cur_side)\n",
    "                pl_idx_list.append(new_cur_pl_idx)\n",
    "                split_polygon_type.append(map_polygon_type)\n",
    "\n",
    "    split_polyline_pos = torch.cat(split_polyline_pos, dim=0)\n",
    "    split_polyline_theta = torch.cat(split_polyline_theta, dim=0)\n",
    "    split_polyline_type = torch.cat(split_polyline_type, dim=0)\n",
    "    split_polyline_side = torch.cat(split_polyline_side, dim=0)\n",
    "    split_polygon_type = torch.cat(split_polygon_type, dim=0)\n",
    "    pl_idx_list = torch.cat(pl_idx_list, dim=0)\n",
    "    vec = split_polyline_pos[:, 1, :] - split_polyline_pos[:, 0, :]\n",
    "    data['map_save'] = {}\n",
    "    data['pt_token'] = {}\n",
    "    data['map_save']['traj_pos'] = split_polyline_pos\n",
    "    data['map_save']['traj_theta'] = split_polyline_theta[:, 0]  # torch.arctan2(vec[:, 1], vec[:, 0])\n",
    "    data['map_save']['pl_idx_list'] = pl_idx_list\n",
    "    data['pt_token']['type'] = split_polyline_type\n",
    "    data['pt_token']['side'] = split_polyline_side\n",
    "    data['pt_token']['pl_type'] = split_polygon_type\n",
    "    data['pt_token']['num_nodes'] = split_polyline_pos.shape[0]\n",
    "    return data\n",
    "\n",
    "token_data = tokenize_map(token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "del token_data['city']\n",
    "if 'polygon_is_intersection' in token_data['map_polygon']:\n",
    "    print(\"delete polygon_is_intersection\")\n",
    "    del token_data['map_polygon']['polygon_is_intersection']\n",
    "if 'route_type' in data['map_polygon']:\n",
    "    print(\"delete route_type\")\n",
    "    del token_data['map_polygon']['route_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 将字典转换成HeteroData类型数据\n",
    "\n",
    "通过dataloader加载数据时，会在批处理时自动添加batch和ptr字段\n",
    "\n",
    "+ `batch` 字段：表示每个节点或边属于哪个样本。对于每个节点（或边），batch 中的值表示该节点所属样本的索引。\n",
    "\n",
    "+ `ptr` 字段：用于记录每个样本的起始索引。这在生成批次时对边的连接（例如跨图连接）很有帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CustomHeteroDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(CustomHeteroDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        batch_data = HeteroData()\n",
    "\n",
    "        for node_type, node_data in self.data_list[idx].items():\n",
    "            if isinstance(node_type, str):  # 处理节点数据\n",
    "                if isinstance(node_data, dict):\n",
    "                    for attr, value in node_data.items():\n",
    "                        batch_data[node_type][attr] = value\n",
    "                else:\n",
    "                    batch_data[node_type] = [node_data]\n",
    "\n",
    "        for edge_type, edge_data in self.data_list[idx].items():\n",
    "            if isinstance(edge_type, tuple) and len(edge_type) == 3:  # 处理边数据\n",
    "                if isinstance(edge_data, dict):\n",
    "                    for attr, value in edge_data.items():\n",
    "                        batch_data[edge_type][attr] = value\n",
    "                else:\n",
    "                    batch_data[edge_type] = edge_data\n",
    "        return batch_data\n",
    "\n",
    "dataset = CustomHeteroDataset([token_data])\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "batch = next(iter(loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 模型内部匹配地图token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data**\n",
    "\n",
    "+ `scenario_id`: *str*, 场景id\n",
    "\n",
    "+ `agent`: *dict*, 场景中的代理信息\n",
    "\n",
    "  - `num_nodes`: *int*, 代理数量\n",
    "\n",
    "  - `av_index`: *int*, AV对应的代理编号\n",
    "\n",
    "  - `valid_mask`: *array([NA, NT])*, 各代理各时间步是否有效\n",
    "\n",
    "  - `predict_mask`: *array([NA, NT])*, 各代理需要被预测的时间步\n",
    "\n",
    "  - `id`: *list([NA])*, 代理ID \n",
    "\n",
    "  - `type`: *array([NA])*, 代理类型\n",
    "\n",
    "    > 0 'vehicle', 1 'pedestrian', 2 'cyclist', 3 'background'\n",
    "\n",
    "  - `category`: *array([NA])*, 代理类别\n",
    "\n",
    "    > 1 其他代理, 2 感兴趣代理, 3 被预测代理\n",
    "\n",
    "  - `position`: *array([NA, NT, 3])*, 代理位置 (x, y, z)\n",
    "\n",
    "  - `heading`: *array([NA, NT])*, 代理航向\n",
    "\n",
    "  - `velocity`: *array([NA, NT, 3])*, 代理速度 (vx, vy, 0)\n",
    "\n",
    "  - `shape`: *array([NA, NT, 3])*, 代理尺寸 (length, width, height)\n",
    "\n",
    "  - `token_idx`: *array([NA, 18])*, 每个代理在90帧中匹配到的18个token索引(5帧为间隔,18=90/5)\n",
    "\n",
    "  - `token_contour`: *array([NA, 18, 4, 2])*, 每个代理在90帧中匹配到的18个token对应的矩形信息\n",
    "\n",
    "  - `token_pos`: *array([NA, 18, 2])*, 每个代理在90帧中匹配到的18个token对应的矩形中心点全局坐标\n",
    "\n",
    "  - `token_heading`: *array([NA, 18])*, 每个代理在90帧中匹配到的18个token处对应的全局航向角\n",
    "\n",
    "  - `token_velocity`: *array([NA, 18, 2])*, 每个代理在90帧中匹配到的18个token处的速度(vx, vy)\n",
    "\n",
    "  - `agent_valid_mask`: *array([NA, 18])*, 每个代理在90帧中匹配到的18个token是否有效\n",
    "\n",
    "+ `map_save`: *dict*, 将多段线按5米进行拆分，多段线内点间距为2.5米重新存图\n",
    "\n",
    "  - `traj_pos`: *array([n_polyline, 3, 2])*, [多段线数量, 每个多段线中有3个点，点坐标xy]\n",
    "\n",
    "  - `traj_theta`: *array([n_polyline])*, 各多段线的朝向（起始段朝向作为代表）\n",
    "  \n",
    "  - `pl_idx_list`: *array([n_polyline])*, 划分后的多段线对应在划分前多段线的索引\n",
    "\n",
    "+ `pt_token`: *dict*, \n",
    "\n",
    "  - `type`: *array([n_polyline])*, 多段线中点的类型\n",
    "\n",
    "    > [ 'DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "    > 'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "    > 'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "    > 'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "\n",
    "  - `side`: *array([n_polyline])*, 多段线在道路哪一侧\n",
    "\n",
    "    > 0: left_side, 1: right_side, 2: center_side\n",
    "\n",
    "  - `pl_type`: *array([n_polyline])*, 多段线类型\n",
    "\n",
    "    > ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "\n",
    "  - `num_nodes`: *int*, 划分后多段线数量\n",
    "\n",
    "  - `position`: *array([n_polyline, 3])*, 各地图多段线的起始点坐标 x,y,z(z=0)\n",
    "\n",
    "  - `orientation`: *array([n_polyline])*, 各地图多段线的起始位置朝向（相对于正 x 轴的弧度值，范围为 [-π, π]）\n",
    "\n",
    "  - `height`: *array([n_polyline])*, 各地图多段线的起始点高度(0)\n",
    "\n",
    "  - `token_idx`: *array([n_polyline])*, 根据map_save['traj_pos']匹配到的地图token索引\n",
    "\n",
    "  - `traj_mask`: *array([n_map_poly, 3, max_token_num])*, 记录每个原始地图多段线在左侧、右侧、中心的轨迹掩码（针对每条多段线，从 0到该条多段线的token数 的下标区间为true，其余为false）\n",
    "\n",
    "  - `pt_valid_mask`: *array([n_polyline])*, 基于traj_mask，从每个原始多段线中随机选取1/3的traj值作为被预测对象掩码掉（置为false）\n",
    "\n",
    "  - `pt_pred_mask`: *array([n_polyline])*, 记录需要预测下一个地图token的索引（哪些点是需要预测的轨迹点）\n",
    "\n",
    "  - `pt_target_mask`: *array([n_polyline])*, 记录真实的下一个地图token的索引\n",
    "\n",
    "+ `map_polygon`: *dict*, 地图中多段线信息\n",
    "\n",
    "  - `num_nodes`: *int*, 多段线数量\n",
    "\n",
    "  - `type`: *array([num_nodes])*, 每条多段线对应的类型\n",
    "\n",
    "    > ['VEHICLE', 'BIKE', 'BUS', 'PEDESTRIAN']\n",
    "\n",
    "  - `light_type`: *array([num_nodes])*, 每条多段线对应的交通信号状态\n",
    "\n",
    "    > ['LANE_STATE_STOP', 'LANE_STATE_GO', 'LANE_STATE_CAUTION', 'LANE_STATE_UNKNOWN']\n",
    "\n",
    "+ `map_point`: *dict*, 地图中各点信息\n",
    "\n",
    "  - `num_nodes`: *int*, 点数量\n",
    "\n",
    "  - `position`: *array([num_nodes, 3])*, 点的坐标(x, y, z)\n",
    "\n",
    "  - `orientation`: *array([num_nodes])*, 各点对应向量的方向角（以弧度表示）\n",
    "\n",
    "  - `magnitude`: *array([num_nodes])*, 各点对应向量的大小（即距离）\n",
    "\n",
    "  - `height`: *array([num_nodes])*, 各点与下一点之间的高度差 *(dim=3时才存在)*\n",
    "\n",
    "  - `type`: *array([num_nodes])*, 各点所属类型\n",
    "\n",
    "    > [ 'DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "    > 'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "    > 'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "    > 'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "\n",
    "+ `'map_point', 'to', 'map_polygon'`: *dict*, 点与多段线之间的索引映射关系\n",
    "\n",
    "  - `edge_index`: *array([2, num_points])*, [point_idx, polygon_idx]\n",
    "\n",
    "+ `'map_polygon', 'to', 'map_polygon'`: *dict*, 车道与车道之间的拓扑关系\n",
    "\n",
    "  - `edge_index`: *array([2, num_edges])*, [polygon1_idx, polygon2_idx]\n",
    "\n",
    "  - `type`: *array([num_edges])*, 拓扑关系类型-polygon1是polygon2的前驱/后继/左邻居/右邻居\n",
    "\n",
    "    > ['NONE', 'PRED', 'SUCC', 'LEFT', 'RIGHT']\n",
    "\n",
    "+ `'pt_token', 'to', 'map_polygon'`: *dict*, pt_token['token_idx']与原多段线之间的索引映射关系\n",
    "\n",
    "  - `edge_index`: *array([2, n_polyline])*, [token_idx, polygon_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 加载轨迹token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**agent_token_data**\n",
    "\n",
    "聚类得到的token信息，即以[0,0]为第一帧中心坐标，五帧为时间间隔到达的终点位置\n",
    "\n",
    "+ `token`: *dict*, 每个token对应的终点位置矩形的四个角点坐标(x, y)，**角点顺序为-左前、右前、右后、左后**\n",
    "    - `veh`: *array([2048, 4, 2])*\n",
    "    - `ped`: *array([2048, 4, 2])*\n",
    "    - `cyc`: *array([2048, 4, 2])*\n",
    "+ `traj`: *dict*, 每个token对应的6帧完整轨迹中心坐标 (x, y ,z)\n",
    "    - `veh`: *array([2048, 6, 3])*\n",
    "    - `ped`: *array([2048, 6, 3])*\n",
    "    - `cyc`: *array([2048, 6, 3])*\n",
    "+ `token_all`: *dict*, 每个token对应的6帧完整轨迹各处矩形四个角点坐标\n",
    "    - `veh`: *array([2048, 6, 4, 2])*\n",
    "    - `ped`: *array([2048, 6, 4, 2])*\n",
    "    - `cyc`: *array([2048, 6, 4, 2])*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_token_path = \"/home/yangyh408/codes/SMART/smart/tokens/cluster_frame_5_2048.pkl\"\n",
    "agent_token_data = pickle.load(open(agent_token_path, 'rb'))\n",
    "trajectory_token = agent_token_data['token']\n",
    "trajectory_token_traj = agent_token_data['traj']\n",
    "trajectory_token_all = agent_token_data['token_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 加载地图token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map_token_data**\n",
    "\n",
    "聚类得到的地图token信息，即以[0,0]为初始位置，连续11个点的坐标\n",
    "\n",
    "+ `traj_src`: *array([1024, 11, 2])*, 每个地图token对应的多段线信息，即11个点的xy坐标\n",
    "+ `sample_pt`: *array([1024, 3, 2])*, 对地图token的多段线信息进行采样，仅保留索引为[0, 5, 10]的三个点信息\n",
    "+ `traj_end_theta`: *array([1024])*, 根据traj_src计算各地图token在最后一个位置处的朝向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin_sample_len = 3\n",
    "\n",
    "map_token_traj_path = \"/home/yangyh408/codes/SMART/smart/tokens/map_traj_token5.pkl\"\n",
    "map_token_traj = pickle.load(open(map_token_traj_path, 'rb'))\n",
    "\n",
    "map_token = {'traj_src': map_token_traj['traj_src'], }\n",
    "traj_end_theta = np.arctan2(map_token['traj_src'][:, -1, 1]-map_token['traj_src'][:, -2, 1],\n",
    "                            map_token['traj_src'][:, -1, 0]-map_token['traj_src'][:, -2, 0])\n",
    "# 生成从 start 到 end 的 steps 个等间隔值。\n",
    "indices = torch.linspace(0, map_token['traj_src'].shape[1]-1, steps=argmin_sample_len).long()\n",
    "map_token['sample_pt'] = torch.from_numpy(map_token['traj_src'][:, indices]).to(torch.float)\n",
    "map_token['traj_end_theta'] = torch.from_numpy(traj_end_theta).to(torch.float)\n",
    "map_token['traj_src'] = torch.from_numpy(map_token['traj_src']).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 匹配地图token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_token_map(data):\n",
    "    traj_pos = data['map_save']['traj_pos'].to(torch.float)\n",
    "    traj_theta = data['map_save']['traj_theta'].to(torch.float)\n",
    "    pl_idx_list = data['map_save']['pl_idx_list']\n",
    "    token_sample_pt = map_token['sample_pt'].to(traj_pos.device)\n",
    "    token_src = map_token['traj_src'].to(traj_pos.device)\n",
    "    max_traj_len = map_token['traj_src'].shape[1]\n",
    "    pl_num = traj_pos.shape[0]\n",
    "\n",
    "    # 各地图多段线的起始点坐标xy\n",
    "    pt_token_pos = traj_pos[:, 0, :].clone()\n",
    "    # 各地图多段线的起始位置朝向\n",
    "    pt_token_orientation = traj_theta.clone()\n",
    "    # 将地图多段线由全局坐标系转换为局部坐标系\n",
    "    cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "    rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "    rot_mat[..., 0, 0] = cos\n",
    "    rot_mat[..., 0, 1] = -sin\n",
    "    rot_mat[..., 1, 0] = sin\n",
    "    rot_mat[..., 1, 1] = cos\n",
    "    traj_pos_local = torch.bmm((traj_pos - traj_pos[:, 0:1]), rot_mat.view(-1, 2, 2))\n",
    "    # 将坐标转换后的多段线与地图map_token进行匹配\n",
    "    distance = torch.sum((token_sample_pt[None] - traj_pos_local.unsqueeze(1))**2, dim=(-2, -1))\n",
    "    pt_token_id = torch.argmin(distance, dim=1)\n",
    "\n",
    "    if noise:\n",
    "        topk_indices = torch.argsort(torch.sum((token_sample_pt[None] - traj_pos_local.unsqueeze(1))**2, dim=(-2, -1)), dim=1)[:, :8]\n",
    "        sample_topk = torch.randint(0, topk_indices.shape[-1], size=(topk_indices.shape[0], 1), device=topk_indices.device)\n",
    "        pt_token_id = torch.gather(topk_indices, 1, sample_topk).squeeze(-1)\n",
    "\n",
    "    cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "    rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "    rot_mat[..., 0, 0] = cos\n",
    "    rot_mat[..., 0, 1] = sin\n",
    "    rot_mat[..., 1, 0] = -sin\n",
    "    rot_mat[..., 1, 1] = cos\n",
    "    token_src_world = torch.bmm(token_src[None, ...].repeat(pl_num, 1, 1, 1).reshape(pl_num, -1, 2),\n",
    "                                rot_mat.view(-1, 2, 2)).reshape(pl_num, token_src.shape[0], max_traj_len, 2) + traj_pos[:, None, [0], :]\n",
    "    token_src_world_select = token_src_world.view(-1, 1024, 11, 2)[torch.arange(pt_token_id.view(-1).shape[0]), pt_token_id.view(-1)].view(pl_num, max_traj_len, 2)\n",
    "\n",
    "    pl_idx_full = pl_idx_list.clone()\n",
    "    token2pl = torch.stack([torch.arange(len(pl_idx_list), device=traj_pos.device), pl_idx_full.long()])\n",
    "    count_nums = []\n",
    "    for pl in pl_idx_full.unique():\n",
    "        pt = token2pl[0, token2pl[1, :] == pl]\n",
    "        left_side = (data['pt_token']['side'][pt] == 0).sum()\n",
    "        right_side = (data['pt_token']['side'][pt] == 1).sum()\n",
    "        center_side = (data['pt_token']['side'][pt] == 2).sum()\n",
    "        count_nums.append(torch.Tensor([left_side, right_side, center_side]))\n",
    "    # count_nums: [N_polyline, 3]分别记录每个原始多段线对应的左侧、右侧、中心token有多少\n",
    "    count_nums = torch.stack(count_nums, dim=0)\n",
    "    # 获取每个原始多段线对应的最多token数量\n",
    "    max_token_num = int(count_nums.max().item())\n",
    "    # 构建多段线的轨迹掩码 [N_polyline, 3, max_token_num]\n",
    "    traj_mask = torch.zeros((int(len(pl_idx_full.unique())), 3, max_token_num), dtype=bool)\n",
    "    idx_matrix = torch.arange(traj_mask.size(2)).unsqueeze(0).unsqueeze(0)\n",
    "    idx_matrix = idx_matrix.expand(traj_mask.size(0), traj_mask.size(1), -1)    #[N_polyline, 3, max_token_num]\n",
    "    counts_num_expanded = count_nums.unsqueeze(-1)                              #[N_polyline, 3, 1]\n",
    "    traj_mask[idx_matrix < counts_num_expanded] = True\n",
    "\n",
    "    data['pt_token']['traj_mask'] = traj_mask\n",
    "    data['pt_token']['position'] = torch.cat([pt_token_pos, torch.zeros((data['pt_token']['num_nodes'], 1),\n",
    "                                                                        device=traj_pos.device, dtype=torch.float)], dim=-1)\n",
    "    data['pt_token']['orientation'] = pt_token_orientation\n",
    "    data['pt_token']['height'] = data['pt_token']['position'][:, -1]\n",
    "    data[('pt_token', 'to', 'map_polygon')] = {}\n",
    "    data[('pt_token', 'to', 'map_polygon')]['edge_index'] = token2pl\n",
    "    data['pt_token']['token_idx'] = pt_token_id\n",
    "    return data\n",
    "\n",
    "batch = match_token_map(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 随机生成地图token预测掩码信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pt_pred(data):\n",
    "    # traj_mask: [n_map_poly, 3, max_token_num]\n",
    "    traj_mask = data['pt_token']['traj_mask']\n",
    "    # 从每个原始多段线中随机选取1/3的traj值被掩码掉\n",
    "    raw_pt_index = torch.arange(1, traj_mask.shape[2]).repeat(traj_mask.shape[0], traj_mask.shape[1], 1)\n",
    "    masked_pt_index = raw_pt_index.view(-1)[torch.randperm(raw_pt_index.numel())[:traj_mask.shape[0]*traj_mask.shape[1]*((traj_mask.shape[2]-1)//3)].reshape(traj_mask.shape[0], traj_mask.shape[1], (traj_mask.shape[2]-1)//3)]\n",
    "    masked_pt_index = torch.sort(masked_pt_index, -1)[0]\n",
    "    # 有效掩码\n",
    "    pt_valid_mask = traj_mask.clone()\n",
    "    pt_valid_mask.scatter_(2, masked_pt_index, False)\n",
    "    # 预测掩码\n",
    "    pt_pred_mask = traj_mask.clone()\n",
    "    pt_pred_mask.scatter_(2, masked_pt_index, False)\n",
    "    tmp_mask = pt_pred_mask.clone()\n",
    "    tmp_mask[:, :, :] = True\n",
    "    tmp_mask.scatter_(2, masked_pt_index-1, False)\n",
    "    pt_pred_mask.masked_fill_(tmp_mask, False)\n",
    "    pt_pred_mask = pt_pred_mask * torch.roll(traj_mask, shifts=-1, dims=2)\n",
    "    # 目标掩码\n",
    "    pt_target_mask = torch.roll(pt_pred_mask, shifts=1, dims=2)\n",
    "    # 通过traj_mask将生成的掩码向量从[n_map_poly, 3, max_token_num]转换为[n_polyline]的形式，使其与token信息对应\n",
    "    data['pt_token']['pt_valid_mask'] = pt_valid_mask[traj_mask]\n",
    "    data['pt_token']['pt_pred_mask'] = pt_pred_mask[traj_mask]\n",
    "    data['pt_token']['pt_target_mask'] = pt_target_mask[traj_mask]\n",
    "\n",
    "    return data\n",
    "\n",
    "batch = sample_pt_pred(batch)\n",
    "batch['agent']['av_index'] += batch['agent']['ptr'][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 使用batch数据进行模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 19:55:20,968-INFO-smart.py-Line:222-Message:==> Loading parameters from checkpoint ../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt to GPU\n",
      "2024-11-24 19:55:31,649-INFO-smart.py-Line:231-Message:The number of disk ckpt keys: 818\n",
      "2024-11-24 19:55:31,740-INFO-smart.py-Line:247-Message:Missing keys: []\n",
      "2024-11-24 19:55:31,741-INFO-smart.py-Line:248-Message:The number of missing keys: 0\n",
      "2024-11-24 19:55:31,742-INFO-smart.py-Line:249-Message:The number of unexpected keys: 0\n",
      "2024-11-24 19:55:31,742-INFO-smart.py-Line:250-Message:==> Done (total keys 818)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "# torch.manual_seed(12)\n",
    "\n",
    "from smart.model import SMART\n",
    "from smart.utils.config import load_config_act\n",
    "from smart.utils.log import Logging\n",
    "\n",
    "config = load_config_act(\"../configs/validation/validation_scalable.yaml\")\n",
    "pretrain_ckpt = \"../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt\"\n",
    "Predictor = SMART\n",
    "logger = Logging().log(level='DEBUG')\n",
    "model = Predictor(config.Model)\n",
    "model.load_params_from_file(filename=pretrain_ckpt, logger=logger)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pred = model(batch)\n",
    "    pred = model.inference(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import torch\n",
    "\n",
    "def plot_static_map(ax, batch):\n",
    "    # 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "    # 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'\n",
    "    _line_style = [['--', 2, 'yellow'], ['--', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'yellow'], ['--', 2, 'grey'],\n",
    "                ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 3, 'black'], [], [], [':', 2, 'blue'], []]\n",
    "    _center_colors = ['lightcoral', 'lightgreen', 'lightyellow', 'lightgray']\n",
    "\n",
    "    # 准备数据\n",
    "    polylines = []\n",
    "    polyline_type = []\n",
    "    for i in range(batch['map_polygon']['num_nodes']):\n",
    "        point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "        polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "        polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "    # 绘制每条地图线段\n",
    "    for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "        x = data[:, 0].numpy()\n",
    "        y = data[:, 1].numpy()\n",
    "        if (type == 13 or type == 14):\n",
    "            continue\n",
    "        elif (type == 16):\n",
    "            ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=_center_colors[batch['map_polygon']['light_type'][idx]], alpha=0.5)\n",
    "        else:\n",
    "            ax.plot(x, y, marker='', linestyle=_line_style[type][0], linewidth=_line_style[type][1], color=_line_style[type][2], alpha=0.8)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f\"Scene <{batch['scenario_id'][0][0]}>\")\n",
    "\n",
    "def cal_polygon_contour(x, y, theta, width, length):\n",
    "    left_front_x = x + 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_front_y = y + 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_front = np.column_stack((left_front_x, left_front_y))\n",
    "\n",
    "    right_front_x = x + 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_front_y = y + 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_front = np.column_stack((right_front_x, right_front_y))\n",
    "\n",
    "    right_back_x = x - 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_back_y = y - 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_back = np.column_stack((right_back_x, right_back_y))\n",
    "\n",
    "    left_back_x = x - 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_back_y = y - 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_back = np.column_stack((left_back_x, left_back_y))\n",
    "\n",
    "    polygon_contour = np.concatenate(\n",
    "        (left_front[:, None, :], right_front[:, None, :], right_back[:, None, :], left_back[:, None, :]), axis=1)\n",
    "\n",
    "    return polygon_contour\n",
    "\n",
    "fig, ax_map = plt.subplots(figsize=(20, 20))\n",
    "ax_agent = ax_map.twinx()\n",
    "\n",
    "plot_static_map(ax_map, batch)\n",
    "\n",
    "traj = torch.cat([batch['agent']['position'][:, :11, :2], pred['pred_traj']], dim=1)\n",
    "head = torch.cat([batch['agent']['heading'][:, :11], pred['pred_head']], dim=1)\n",
    "\n",
    "N, T, _ = traj.shape\n",
    "agent_traj_all = cal_polygon_contour(\n",
    "    traj.view(-1, 2)[..., 0], \n",
    "    traj.view(-1, 2)[..., 1], \n",
    "    head.view(-1), \n",
    "    batch['agent']['shape'].view(-1, 3)[..., 1], \n",
    "    batch['agent']['shape'].view(-1, 3)[..., 0]\n",
    ").reshape(N, T, 4, 2)\n",
    "\n",
    "def update(frame):\n",
    "    ax_agent.cla()\n",
    "    ax_agent.axis('off')\n",
    "    ax_agent.set_ylim(ax_map.get_ylim())\n",
    "    polygons = []\n",
    "    for agent_idx in range(agent_traj_all.shape[0]):\n",
    "        polygon = patches.Polygon(agent_traj_all[agent_idx, frame], closed=True, fill='blue', edgecolor=None, alpha=0.9)  # fill=None 使其不填充\n",
    "        ax_agent.add_patch(polygon)\n",
    "        polygons.append(polygon)\n",
    "    return polygons\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(T), blit=True)\n",
    "ani.save(f\"/home/yangyh408/codes/SMART/data/limsim/{batch.scenario_id[0][0]}.gif\", writer=PillowWriter(fps=10))\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 地图信息可视化工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 根据map_polygon和map_point绘制地图\n",
    "\n",
    "可以通过FILTER_TYPE指定突出绘制的地图线型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取当前可视化场景信息\n",
    "print(\"-\" * 100)\n",
    "print(f\"Scenario ID: {batch.scenario_id[0]}\")\n",
    "print(f\"不同多段线类型对应的多段线条数: {torch.bincount(batch['map_polygon']['type'], minlength=4).tolist()}\")\n",
    "# 0:'VEHICLE', 1:'BIKE', 2:'BUS', 3:'PEDESTRIAN'\n",
    "print(f\"不同信控信号对应的多段线条数: {torch.bincount(batch['map_polygon']['light_type'], minlength=4).tolist()}\")\n",
    "# 0:'LANE_STATE_STOP', 1:'LANE_STATE_GO', 2:'LANE_STATE_CAUTION', 3:'LANE_STATE_UNKNOWN'\n",
    "print(f\"不同的地图点类型对应的个数: {torch.bincount(batch['map_point']['type'], minlength=17).tolist()}\")\n",
    "# 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "# 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "\n",
    "# 突出显示的线形\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图和信息区域\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 9])  # 上下两部分，比例为4:1\n",
    "\n",
    "# 绘图区域\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "num_colors = len(colors)\n",
    "\n",
    "# 准备数据\n",
    "polylines = []\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 存储绘制的线段和其对应的数据\n",
    "lines = []\n",
    "line_data = []\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    if len(FILTER_TYPE) == 0 or type in FILTER_TYPE:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[type], picker=5)  # 启用 picker\n",
    "    else:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color='#F0F0F0', alpha=1, picker=5)\n",
    "    lines.append(line)\n",
    "    line_data.append((idx, type, x, y))\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.tab20, norm=mcolors.Normalize(vmin=0, vmax=num_colors - 1))\n",
    "sm.set_array([])  # 必须设置 array 以显示颜色条\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Color Index')\n",
    "cbar.set_ticks(range(num_colors))\n",
    "cbar.set_ticklabels(range(num_colors))\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 信息显示区域\n",
    "info_ax = fig.add_subplot(gs[0])\n",
    "info_ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 初始化显示信息\n",
    "info_text = info_ax.text(0.01, 0.5, \"Selected Line Info: None\", fontsize=12, verticalalignment='center')\n",
    "\n",
    "# 用于跟踪当前高亮的线段\n",
    "highlighted_line = None\n",
    "highlighted_prev_color = None\n",
    "\n",
    "# 鼠标点击事件\n",
    "def on_pick(event):\n",
    "    global highlighted_line\n",
    "    global highlighted_prev_color\n",
    "\n",
    "    # 获取被选中的线段\n",
    "    line = event.artist\n",
    "    idx = lines.index(line)\n",
    "    idx, pl_type, x, y = line_data[idx]\n",
    "\n",
    "    # 如果有高亮的线段，先恢复默认样式\n",
    "    if highlighted_line is not None:\n",
    "        highlighted_line.set_linewidth(2)\n",
    "        highlighted_line.set_color(highlighted_prev_color)\n",
    "    # 更新高亮的线段\n",
    "    highlighted_line = line\n",
    "    highlighted_prev_color = colors[pl_type] if len(FILTER_TYPE) == 0 or pl_type in FILTER_TYPE else '#F0F0F0'\n",
    "    line.set_linewidth(4)\n",
    "    line.set_color('red')\n",
    "\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    \n",
    "    # 更新信息显示区域\n",
    "    info = (f\"Selected Line Index: {idx}\\n\"\n",
    "            f\"Selected Line Type Index: {pl_type}\\n\"\n",
    "            f\"Selected Line Type: {_point_types[pl_type]}\\n\")\n",
    "            # f\"Coordinates: {list(zip(x, y))[:5]}... (truncated)\")\n",
    "    info_text.set_text(info)\n",
    "\n",
    "    # 刷新图像\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# 连接事件\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 绘制信控信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "\n",
    "# 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "# 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图，包含 Axes 对象\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "colors = ['red', 'green', 'yellow', 'lightgray']\n",
    "\n",
    "# 准备数据\n",
    "polylines = []\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[batch['map_polygon']['light_type'][idx]])\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 根据分段采样后的map_save数据绘制地图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "\n",
    "# 示例数据\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图和信息区域\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 9])  # 上下两部分，比例为4:1\n",
    "\n",
    "# 绘图区域\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "num_colors = len(colors)\n",
    "\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 存储绘制的线段和其对应的数据\n",
    "lines = []\n",
    "line_data = []\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, (pl_idx, data) in enumerate(zip(batch['map_save']['pl_idx_list'], batch['map_save']['traj_pos'])):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    type = polyline_type[int(pl_idx)]\n",
    "    if len(FILTER_TYPE) == 0 or type in FILTER_TYPE:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[type], picker=5)  # 启用 picker\n",
    "    else:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color='#F0F0F0', alpha=1, picker=5)\n",
    "    lines.append(line)\n",
    "    line_data.append((idx, type, x, y))\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.tab20, norm=mcolors.Normalize(vmin=0, vmax=num_colors - 1))\n",
    "sm.set_array([])  # 必须设置 array 以显示颜色条\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Color Index')\n",
    "cbar.set_ticks(range(num_colors))\n",
    "cbar.set_ticklabels(range(num_colors))\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 信息显示区域\n",
    "info_ax = fig.add_subplot(gs[0])\n",
    "info_ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 初始化显示信息\n",
    "info_text = info_ax.text(0.01, 0.5, \"Selected Line Info: None\", fontsize=12, verticalalignment='center')\n",
    "\n",
    "# 用于跟踪当前高亮的线段\n",
    "highlighted_line = None\n",
    "highlighted_prev_color = None\n",
    "\n",
    "# 鼠标点击事件\n",
    "def on_pick(event):\n",
    "    global highlighted_line\n",
    "    global highlighted_prev_color\n",
    "\n",
    "    # 获取被选中的线段\n",
    "    line = event.artist\n",
    "    idx = lines.index(line)\n",
    "    idx, pl_type, x, y = line_data[idx]\n",
    "\n",
    "    # 如果有高亮的线段，先恢复默认样式\n",
    "    if highlighted_line is not None:\n",
    "        highlighted_line.set_linewidth(2)\n",
    "        highlighted_line.set_color(highlighted_prev_color)\n",
    "    # 更新高亮的线段\n",
    "    highlighted_line = line\n",
    "    highlighted_prev_color = colors[pl_type] if len(FILTER_TYPE) == 0 or pl_type in FILTER_TYPE else '#F0F0F0'\n",
    "    line.set_linewidth(4)\n",
    "    line.set_color('red')\n",
    "\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    \n",
    "    # 更新信息显示区域\n",
    "    info = (f\"Selected Line Index: {idx}\\n\"\n",
    "            f\"Selected Line Head: {batch['map_save']['traj_theta'][idx]: .4f}\\n\"\n",
    "            f\"Selected Line Type Index: {pl_type}\\n\"\n",
    "            f\"Selected Line Type: {_point_types[pl_type]}\\n\")\n",
    "            # f\"Coordinates: {list(zip(x, y))[:5]}... (truncated)\")\n",
    "    info_text.set_text(info)\n",
    "\n",
    "    # 刷新图像\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# 连接事件\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 根据匹配的地图token进行地图可视化还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "\n",
    "# 创建绘图和信息区域\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 9])  # 上下两部分，比例为4:1\n",
    "\n",
    "# 绘图区域\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "num_colors = len(colors)\n",
    "\n",
    "# 准备数据\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "pl_num = batch['pt_token']['position'].shape[0]\n",
    "traj_theta = batch['pt_token']['orientation'].clone()\n",
    "traj_pos = batch['pt_token']['position'].clone()\n",
    "pt_token_id = batch['pt_token']['token_idx'].clone()\n",
    "\n",
    "cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "rot_mat[..., 0, 0] = cos\n",
    "rot_mat[..., 0, 1] = sin\n",
    "rot_mat[..., 1, 0] = -sin\n",
    "rot_mat[..., 1, 1] = cos\n",
    "\n",
    "map_token_traj_path = \"/home/yangyh408/codes/SMART/smart/tokens/map_traj_token5.pkl\"\n",
    "map_token_traj = pickle.load(open(map_token_traj_path, 'rb'))\n",
    "\n",
    "token_src = torch.from_numpy(map_token_traj['traj_src']).to(torch.float)\n",
    "token_src_world = torch.bmm(\n",
    "                        token_src[None, ...].repeat(pl_num, 1, 1, 1).reshape(pl_num, -1, 2),\n",
    "                        rot_mat.view(-1, 2, 2)\n",
    "                    ).reshape(pl_num, token_src.shape[0], -1, 2) + traj_pos[:, None, None, :2]\n",
    "token_src_world_select = token_src_world.view(-1, 1024, 11, 2)[torch.arange(pt_token_id.view(-1).shape[0]), pt_token_id.view(-1)].view(pl_num, -1, 2)\n",
    "\n",
    "# 存储绘制的线段和其对应的数据\n",
    "lines = []\n",
    "line_data = []\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, data in enumerate(token_src_world_select):\n",
    "    pl_idx = batch[('pt_token', 'to', 'map_polygon')]['edge_index'][1, idx].item()\n",
    "    token_idx = batch['pt_token']['token_idx'][idx].item()\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    type = polyline_type[int(pl_idx)]\n",
    "    line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[type], picker=5)\n",
    "    lines.append(line)\n",
    "    line_data.append((idx, token_idx, type, x, y))\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.tab20, norm=mcolors.Normalize(vmin=0, vmax=num_colors - 1))\n",
    "sm.set_array([])  # 必须设置 array 以显示颜色条\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Color Index')\n",
    "cbar.set_ticks(range(num_colors))\n",
    "cbar.set_ticklabels(range(num_colors))\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 信息显示区域\n",
    "info_ax = fig.add_subplot(gs[0])\n",
    "info_ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 初始化显示信息\n",
    "info_text = info_ax.text(0.01, 0.5, \"Selected Line Info: None\", fontsize=12, verticalalignment='center')\n",
    "\n",
    "# 用于跟踪当前高亮的线段\n",
    "highlighted_line = None\n",
    "highlighted_prev_color = None\n",
    "\n",
    "# 鼠标点击事件\n",
    "def on_pick(event):\n",
    "    global highlighted_line\n",
    "    global highlighted_prev_color\n",
    "\n",
    "    # 获取被选中的线段\n",
    "    line = event.artist\n",
    "    idx = lines.index(line)\n",
    "    idx, token_idx, pl_type, x, y = line_data[idx]\n",
    "\n",
    "    # 如果有高亮的线段，先恢复默认样式\n",
    "    if highlighted_line is not None:\n",
    "        highlighted_line.set_linewidth(2)\n",
    "        highlighted_line.set_color(highlighted_prev_color)\n",
    "    # 更新高亮的线段\n",
    "    highlighted_line = line\n",
    "    highlighted_prev_color = colors[pl_type] if len(FILTER_TYPE) == 0 or pl_type in FILTER_TYPE else '#F0F0F0'\n",
    "    line.set_linewidth(4)\n",
    "    line.set_color('red')\n",
    "\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    \n",
    "    # 更新信息显示区域\n",
    "    info = (f\"Selected Line Index: {idx}\\n\"\n",
    "            f\"Selected Token Index: {token_idx}\\n\"\n",
    "            f\"Selected Line Type Index: {pl_type}\\n\"\n",
    "            f\"Selected Line Type: {_point_types[pl_type]}\\n\")\n",
    "            # f\"Coordinates: {list(zip(x, y))[:5]}... (truncated)\")\n",
    "    info_text.set_text(info)\n",
    "\n",
    "    # 刷新图像\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# 连接事件\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 batch轨迹信息可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "\n",
    "# 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "# 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图，包含 Axes 对象\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "_line_style = [['--', 2, 'yellow'], ['--', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'yellow'], ['--', 2, 'grey'],\n",
    "                ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 3, 'black'], [], [], [':', 2, 'blue'], []]\n",
    "_center_colors = ['lightcoral', 'lightgreen', 'lightyellow', 'lightgray']\n",
    "\n",
    "# 准备数据\n",
    "polylines = []\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 绘制每条地图线段\n",
    "for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    if (type == 13 or type == 14):\n",
    "        continue\n",
    "    elif (type == 16):\n",
    "        ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=_center_colors[batch['map_polygon']['light_type'][idx]], alpha=0.5)\n",
    "    else:\n",
    "        ax.plot(x, y, marker='', linestyle=_line_style[type][0], linewidth=_line_style[type][1], color=_line_style[type][2], alpha=0.8)\n",
    "\n",
    "history_step = 11\n",
    "alphas = np.linspace(0.1, 1.0, history_step)\n",
    "for agent_info in batch['agent']['position'][:, :history_step, :2]:\n",
    "    x = agent_info[:, 0].numpy()\n",
    "    y = agent_info[:, 1].numpy()\n",
    "    plt.scatter(x, y, alpha=alphas)\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-limsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
