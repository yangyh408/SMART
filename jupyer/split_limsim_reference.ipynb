{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 LimSim预处理文件读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于LimSim环境中的代理和地图信息提取过程，详见`MARL-LimSim/map_parse.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scenario_id': 'limsim_meta_inter',\n",
       " 'city': 10086,\n",
       " 'map_polygon': {'num_nodes': 75,\n",
       "  'type': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0], dtype=torch.uint8),\n",
       "  'light_type': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 3, 0, 0, 0, 1, 3,\n",
       "          1, 3, 1, 3, 0, 1, 3, 1, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 1, 0, 0, 3, 0, 3,\n",
       "          3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "          3, 3, 3], dtype=torch.uint8)},\n",
       " 'map_point': {'num_nodes': 3675,\n",
       "  'position': tensor([[44.3700, 89.5200,  0.0000],\n",
       "          [42.8982, 89.5190,  0.0000],\n",
       "          [41.4263, 89.5180,  0.0000],\n",
       "          ...,\n",
       "          [77.2985, 91.5404,  0.0000],\n",
       "          [75.7439, 91.5369,  0.0000],\n",
       "          [74.1892, 91.5335,  0.0000]]),\n",
       "  'orientation': tensor([-3.1409, -3.1409, -3.1409,  ..., -3.1394, -3.1394, -3.1394]),\n",
       "  'magnitude': tensor([1.4718, 1.4718, 1.4718,  ..., 1.5547, 1.5547, 1.5547]),\n",
       "  'height': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'type': tensor([16., 16., 16.,  ...,  2.,  2.,  2.])},\n",
       " ('map_point',\n",
       "  'to',\n",
       "  'map_polygon'): {'edge_index': tensor([[   0,    1,    2,  ..., 3672, 3673, 3674],\n",
       "          [   0,    0,    0,  ...,   74,   74,   74]])},\n",
       " 'agent': {'num_nodes': 5,\n",
       "  'av_index': [],\n",
       "  'valid_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False]]),\n",
       "  'predict_mask': tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True]]),\n",
       "  'id': [3, 4, 2, 0, 1],\n",
       "  'type': tensor([0, 0, 0, 0, 0], dtype=torch.uint8),\n",
       "  'category': tensor([3, 3, 3, 3, 3], dtype=torch.uint8),\n",
       "  'position': tensor([[[-15.9591,  85.4814,   0.0000],\n",
       "           [-15.3133,  85.4821,   0.0000],\n",
       "           [-14.6491,  85.4827,   0.0000],\n",
       "           ...,\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000]],\n",
       "  \n",
       "          [[131.3846,  89.6611,   0.0000],\n",
       "           [130.4888,  89.6591,   0.0000],\n",
       "           [129.5636,  89.6570,   0.0000],\n",
       "           ...,\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000]],\n",
       "  \n",
       "          [[ 56.8337, 105.1888,   0.0000],\n",
       "           [ 56.8337, 105.1888,   0.0000],\n",
       "           [ 56.8337, 105.1888,   0.0000],\n",
       "           ...,\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000]],\n",
       "  \n",
       "          [[ 61.0433,  45.0207,   0.0000],\n",
       "           [ 61.0421,  46.4521,   0.0000],\n",
       "           [ 61.0408,  47.9103,   0.0000],\n",
       "           ...,\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000]],\n",
       "  \n",
       "          [[ 61.0496,  37.4476,   0.0000],\n",
       "           [ 61.0486,  38.6385,   0.0000],\n",
       "           [ 61.0476,  39.8277,   0.0000],\n",
       "           ...,\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000],\n",
       "           [  0.0000,   0.0000,   0.0000]]]),\n",
       "  'heading': tensor([[ 9.7060e-04,  9.7060e-04,  9.7060e-04,  9.7060e-04,  9.7060e-04,\n",
       "            9.7060e-04,  9.7060e-04,  9.7060e-04,  9.7060e-04,  9.7060e-04,\n",
       "            9.7060e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00],\n",
       "          [-3.1394e+00, -3.1394e+00, -3.1394e+00, -3.1394e+00, -3.1394e+00,\n",
       "           -3.1394e+00, -3.1394e+00, -3.1394e+00, -3.1394e+00, -3.1394e+00,\n",
       "           -3.1394e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00],\n",
       "          [-1.5684e+00, -1.5684e+00, -1.5684e+00, -1.5684e+00, -1.5684e+00,\n",
       "           -1.5684e+00, -1.5684e+00, -1.5684e+00, -1.5684e+00, -1.5684e+00,\n",
       "           -1.5684e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00],\n",
       "          [-4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00,\n",
       "           -4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00,\n",
       "           -4.7116e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00],\n",
       "          [-4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00,\n",
       "           -4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00, -4.7116e+00,\n",
       "           -4.7116e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00]]),\n",
       "  'velocity': tensor([[[ 5.1017e+00,  4.9517e-03,  0.0000e+00],\n",
       "           [ 5.2821e+00,  5.1269e-03,  0.0000e+00],\n",
       "           [ 5.4329e+00,  5.2732e-03,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "          [[-5.4472e+00, -1.2156e-02,  0.0000e+00],\n",
       "           [-5.6869e+00, -1.2690e-02,  0.0000e+00],\n",
       "           [-5.8728e+00, -1.3105e-02,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "          [[ 0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "          [[-8.9839e-03,  1.0742e+01,  0.0000e+00],\n",
       "           [-9.1433e-03,  1.0932e+01,  0.0000e+00],\n",
       "           [-9.3145e-03,  1.1137e+01,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "          [[-7.7363e-03,  9.2500e+00,  0.0000e+00],\n",
       "           [-7.6070e-03,  9.0953e+00,  0.0000e+00],\n",
       "           [-7.5957e-03,  9.0818e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]),\n",
       "  'shape': tensor([[[5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           ...,\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000]],\n",
       "  \n",
       "          [[5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           ...,\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000]],\n",
       "  \n",
       "          [[5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           ...,\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000]],\n",
       "  \n",
       "          [[5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           ...,\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000]],\n",
       "  \n",
       "          [[5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           ...,\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000],\n",
       "           [5.0000, 1.8000, 0.0000]]])}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"../data/limsim/limsim_meta_inter_straight_red.pkl\", 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 数据token化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与`split_inference.ipynb`中第二节到第四节的内容相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "current_step = 10\n",
    "shift = 5\n",
    "noise = True\n",
    "training = False\n",
    "\n",
    "argmin_sample_len = 3\n",
    "\n",
    "map_token_traj_path = \"../smart/tokens/map_traj_token5.pkl\"\n",
    "map_token_traj = pickle.load(open(map_token_traj_path, 'rb'))\n",
    "\n",
    "map_token = {'traj_src': map_token_traj['traj_src'], }\n",
    "traj_end_theta = np.arctan2(map_token['traj_src'][:, -1, 1]-map_token['traj_src'][:, -2, 1],\n",
    "                            map_token['traj_src'][:, -1, 0]-map_token['traj_src'][:, -2, 0])\n",
    "# 生成从 start 到 end 的 steps 个等间隔值。\n",
    "indices = torch.linspace(0, map_token['traj_src'].shape[1]-1, steps=argmin_sample_len).long()\n",
    "map_token['sample_pt'] = torch.from_numpy(map_token['traj_src'][:, indices]).to(torch.float)\n",
    "map_token['traj_end_theta'] = torch.from_numpy(traj_end_theta).to(torch.float)\n",
    "map_token['traj_src'] = torch.from_numpy(map_token['traj_src']).to(torch.float)\n",
    "\n",
    "agent_token_path = \"../smart/tokens/cluster_frame_5_2048.pkl\"\n",
    "agent_token_data = pickle.load(open(agent_token_path, 'rb'))\n",
    "trajectory_token = agent_token_data['token']\n",
    "trajectory_token_traj = agent_token_data['traj']\n",
    "trajectory_token_all = agent_token_data['token_all']\n",
    "# 对所有token依据倒数第二帧的状态为基准状态对最后一帧进行归一化\n",
    "token_last_all = {}\n",
    "\n",
    "for k, v in trajectory_token_all.items():\n",
    "    # 计算每个 agent 的最终 token 朝向\n",
    "    token_last = torch.from_numpy(v[:, -2:]).to(torch.float)    # [2048, 2, 4, 2]\n",
    "    diff_xy = token_last[:, 0, 0] - token_last[:, 0, 3]         # 倒数第二帧 左前-左后\n",
    "    theta = torch.arctan2(diff_xy[:, 1], diff_xy[:, 0])         # 倒数第二帧的航向角\n",
    "    cos, sin = theta.cos(), theta.sin()\n",
    "    # 生成旋转矩阵\n",
    "    rot_mat = theta.new_zeros(token_last.shape[0], 2, 2)\n",
    "    rot_mat[:, 0, 0] = cos\n",
    "    rot_mat[:, 0, 1] = -sin\n",
    "    rot_mat[:, 1, 0] = sin\n",
    "    rot_mat[:, 1, 1] = cos\n",
    "    # 应用旋转矩阵并归一化 token 数据\n",
    "    agent_token = torch.bmm(token_last[:, 1], rot_mat)\n",
    "    agent_token -= token_last[:, 0].mean(1)[:, None, :]\n",
    "    token_last_all[k] = agent_token.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_heading(data):\n",
    "    \"\"\"\n",
    "        这个函数 clean_heading 的主要功能是对“heading” (朝向角度) 进行清理，以修复明显异常或突然变化的朝向角度\n",
    "        （例如，当相邻帧之间的朝向差异超过一定阈值时），从而平滑朝向数据。\n",
    "        具体而言，代码通过对相邻帧的朝向差异进行检测和修正，使得朝向变化更连贯。\n",
    "    \"\"\"\n",
    "    heading = data['agent']['heading']\n",
    "    valid = data['agent']['valid_mask']\n",
    "    pi = torch.tensor(torch.pi)\n",
    "    n_vehicles, n_frames = heading.shape\n",
    "\n",
    "    heading_diff_raw = heading[:, :-1] - heading[:, 1:]\n",
    "    heading_diff = torch.remainder(heading_diff_raw + pi, 2 * pi) - pi\n",
    "    heading_diff[heading_diff > pi] -= 2 * pi\n",
    "    heading_diff[heading_diff < -pi] += 2 * pi\n",
    "\n",
    "    valid_pairs = valid[:, :-1] & valid[:, 1:]\n",
    "\n",
    "    for i in range(n_frames - 1):\n",
    "        change_needed = (torch.abs(heading_diff[:, i:i + 1]) > 1.0) & valid_pairs[:, i:i + 1]\n",
    "\n",
    "        heading[:, i + 1][change_needed.squeeze()] = heading[:, i][change_needed.squeeze()]\n",
    "\n",
    "        if i < n_frames - 2:\n",
    "            heading_diff_raw = heading[:, i + 1] - heading[:, i + 2]\n",
    "            heading_diff[:, i + 1] = torch.remainder(heading_diff_raw + pi, 2 * pi) - pi\n",
    "            heading_diff[heading_diff[:, i + 1] > pi] -= 2 * pi\n",
    "            heading_diff[heading_diff[:, i + 1] < -pi] += 2 * pi\n",
    "\n",
    "def cal_polygon_contour(x, y, theta, width, length):\n",
    "    \"\"\"\n",
    "        函数功能：计算一个矩形多边形的四个顶点坐标（轮廓）\n",
    "        返回值：返回一个形状为 [n, 4, 2] 的数组 polygon_contour，表示每个矩形的四个顶点的坐标，方便后续用作绘制或碰撞检测等应用。\n",
    "    \"\"\"\n",
    "    left_front_x = x + 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_front_y = y + 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_front = np.column_stack((left_front_x, left_front_y))\n",
    "\n",
    "    right_front_x = x + 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_front_y = y + 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_front = np.column_stack((right_front_x, right_front_y))\n",
    "\n",
    "    right_back_x = x - 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_back_y = y - 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_back = np.column_stack((right_back_x, right_back_y))\n",
    "\n",
    "    left_back_x = x - 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_back_y = y - 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_back = np.column_stack((left_back_x, left_back_y))\n",
    "\n",
    "    polygon_contour = np.concatenate(\n",
    "        (left_front[:, None, :], right_front[:, None, :], right_back[:, None, :], left_back[:, None, :]), axis=1)\n",
    "\n",
    "    return polygon_contour\n",
    "\n",
    "def match_token(pos, valid_mask, heading, category, agent_category, extra_mask):\n",
    "    \"\"\"\n",
    "        将轨迹位置和朝向数据与预定义的 token 数据进行匹配，以便在场景中的每个时间步中都能追踪到正确的 token。\n",
    "    \"\"\"\n",
    "    agent_token_src = trajectory_token[category]\n",
    "    token_last = token_last_all[category]\n",
    "    if shift <= 2:\n",
    "        if category == 'veh':\n",
    "            width = 1.0\n",
    "            length = 2.4\n",
    "        elif category == 'cyc':\n",
    "            width = 0.5\n",
    "            length = 1.5\n",
    "        else:\n",
    "            width = 0.5\n",
    "            length = 0.5\n",
    "    else:\n",
    "        if category == 'veh':\n",
    "            width = 2.0\n",
    "            length = 4.8\n",
    "        elif category == 'cyc':\n",
    "            width = 1.0\n",
    "            length = 2.0\n",
    "        else:\n",
    "            width = 1.0\n",
    "            length = 1.0\n",
    "\n",
    "    prev_heading = heading[:, 0]\n",
    "    prev_pos = pos[:, 0]\n",
    "    agent_num, num_step, feat_dim = pos.shape   # [NA, 91, 2]\n",
    "    token_num, token_contour_dim, feat_dim = agent_token_src.shape  # [2048, 4, 2]\n",
    "    agent_token_src = agent_token_src.reshape(1, token_num * token_contour_dim, feat_dim).repeat(agent_num, 0)\n",
    "    token_last = token_last.reshape(1, token_num * token_contour_dim, feat_dim).repeat(extra_mask.sum(), 0)\n",
    "    token_index_list = []\n",
    "    token_contour_list = []\n",
    "    prev_token_idx = None\n",
    "\n",
    "    for i in range(shift, pos.shape[1], shift):\n",
    "        # 上一token所在位置航向角（5帧前）\n",
    "        theta = prev_heading\n",
    "        # 当前航向角和位置\n",
    "        cur_heading = heading[:, i]\n",
    "        cur_pos = pos[:, i]\n",
    "        # 将归一化的原始token信息以上一时刻位置和航向状态为基准调整到全局坐标系\n",
    "        cos, sin = theta.cos(), theta.sin()\n",
    "        rot_mat = theta.new_zeros(agent_num, 2, 2)\n",
    "        rot_mat[:, 0, 0] = cos\n",
    "        rot_mat[:, 0, 1] = sin\n",
    "        rot_mat[:, 1, 0] = -sin\n",
    "        rot_mat[:, 1, 1] = cos\n",
    "        agent_token_world = torch.bmm(torch.from_numpy(agent_token_src).to(torch.float), rot_mat).reshape(agent_num,\n",
    "                                                                                                            token_num,\n",
    "                                                                                                            token_contour_dim,\n",
    "                                                                                                            feat_dim)\n",
    "        agent_token_world += prev_pos[:, None, None, :]\n",
    "\n",
    "        # 获取当前所在位置的矩形四角信息\n",
    "        cur_contour = cal_polygon_contour(cur_pos[:, 0], cur_pos[:, 1], cur_heading, width, length)\n",
    "        # 找出与当前距离最近的token作为匹配对象，记录该tokenid\n",
    "        agent_token_index = torch.from_numpy(np.argmin(\n",
    "            np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)), axis=2),\n",
    "            axis=-1))\n",
    "        if prev_token_idx is not None and noise:\n",
    "            same_idx = prev_token_idx == agent_token_index\n",
    "            same_idx[:] = True\n",
    "            topk_indices = np.argsort(\n",
    "                np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)),\n",
    "                        axis=2), axis=-1)[:, :5]\n",
    "            sample_topk = np.random.choice(range(0, topk_indices.shape[1]), topk_indices.shape[0])\n",
    "            agent_token_index[same_idx] = \\\n",
    "                torch.from_numpy(topk_indices[np.arange(topk_indices.shape[0]), sample_topk])[same_idx]\n",
    "        # 将匹配的tokenid转换为矩形四角坐标\n",
    "        token_contour_select = agent_token_world[torch.arange(agent_num), agent_token_index]\n",
    "\n",
    "        # 将当前帧信息更新为上一帧信息\n",
    "        diff_xy = token_contour_select[:, 0, :] - token_contour_select[:, 3, :]\n",
    "        # 数据集中原航向角\n",
    "        prev_heading = heading[:, i].clone()\n",
    "        # 如果是这一帧被预测的对象，则用当前token所在状态更新航向和位置信息\n",
    "        prev_heading[valid_mask[:, i - shift]] = torch.arctan2(diff_xy[:, 1], diff_xy[:, 0])[\n",
    "            valid_mask[:, i - shift]]\n",
    "\n",
    "        prev_pos = pos[:, i].clone()\n",
    "        prev_pos[valid_mask[:, i - shift]] = token_contour_select.mean(dim=1)[valid_mask[:, i - shift]]\n",
    "        prev_token_idx = agent_token_index\n",
    "        token_index_list.append(agent_token_index[:, None])\n",
    "        token_contour_list.append(token_contour_select[:, None, ...])\n",
    "\n",
    "    token_index = torch.cat(token_index_list, dim=1)\n",
    "    token_contour = torch.cat(token_contour_list, dim=1)\n",
    "\n",
    "    # extra matching（如果在第十一帧存在但第六帧不存在的代理，则根据第十帧的状态来匹配token信息）\n",
    "    if not training:\n",
    "        theta = heading[extra_mask, current_step - 1]\n",
    "        prev_pos = pos[extra_mask, current_step - 1]\n",
    "        cur_pos = pos[extra_mask, current_step]\n",
    "        cur_heading = heading[extra_mask, current_step]\n",
    "        cos, sin = theta.cos(), theta.sin()\n",
    "        rot_mat = theta.new_zeros(extra_mask.sum(), 2, 2)\n",
    "        rot_mat[:, 0, 0] = cos\n",
    "        rot_mat[:, 0, 1] = sin\n",
    "        rot_mat[:, 1, 0] = -sin\n",
    "        rot_mat[:, 1, 1] = cos\n",
    "        agent_token_world = torch.bmm(torch.from_numpy(token_last).to(torch.float), rot_mat).reshape(\n",
    "            extra_mask.sum(), token_num, token_contour_dim, feat_dim)\n",
    "        agent_token_world += prev_pos[:, None, None, :]\n",
    "\n",
    "        cur_contour = cal_polygon_contour(cur_pos[:, 0], cur_pos[:, 1], cur_heading, width, length)\n",
    "        agent_token_index = torch.from_numpy(np.argmin(\n",
    "            np.mean(np.sqrt(np.sum((cur_contour[:, None, ...] - agent_token_world.numpy()) ** 2, axis=-1)), axis=2),\n",
    "            axis=-1))\n",
    "        token_contour_select = agent_token_world[torch.arange(extra_mask.sum()), agent_token_index]\n",
    "\n",
    "        token_index[extra_mask, 1] = agent_token_index\n",
    "        token_contour[extra_mask, 1] = token_contour_select\n",
    "\n",
    "    return token_index, token_contour\n",
    "\n",
    "def tokenize_agent(data):\n",
    "    if data['agent'][\"velocity\"].shape[1] == 90:\n",
    "        print(data['scenario_id'], data['agent'][\"velocity\"].shape)\n",
    "    \n",
    "    # 创建插值掩码 interplote_mask，用于标记那些当前时间步为无效但坐标非零的位置，以确定需要插值的数据点\n",
    "    interplote_mask = (data['agent']['valid_mask'][:, current_step] == False) * (\n",
    "            data['agent']['position'][:, current_step, 0] != 0)\n",
    "    # 通过检查当前时间步中无效但位置非零的轨迹点，将其前一个时间步的位置、速度、航向等信息进行估算和填充，确保轨迹数据连续性\n",
    "    if data['agent'][\"velocity\"].shape[-1] == 2:\n",
    "        data['agent'][\"velocity\"] = torch.cat([data['agent'][\"velocity\"],\n",
    "                                                torch.zeros(data['agent'][\"velocity\"].shape[0],\n",
    "                                                            data['agent'][\"velocity\"].shape[1], 1)], dim=-1)\n",
    "    vel = data['agent'][\"velocity\"][interplote_mask, current_step]\n",
    "    # 插值前一个时间步的位置、航向、速度\n",
    "    data['agent']['position'][interplote_mask, current_step - 1, :3] = data['agent']['position'][\n",
    "                                                                            interplote_mask, current_step,\n",
    "                                                                            :3] - vel * 0.1\n",
    "    data['agent']['heading'][interplote_mask, current_step - 1] = data['agent']['heading'][\n",
    "        interplote_mask, current_step]\n",
    "    data['agent'][\"velocity\"][interplote_mask, current_step - 1] = data['agent'][\"velocity\"][\n",
    "        interplote_mask, current_step]\n",
    "    data['agent']['valid_mask'][interplote_mask, current_step - 1:current_step + 1] = True\n",
    "\n",
    "    data['agent']['type'] = data['agent']['type'].to(torch.uint8)\n",
    "\n",
    "    clean_heading(data)\n",
    "    matching_extra_mask = (data['agent']['valid_mask'][:, current_step] == True) * (\n",
    "            data['agent']['valid_mask'][:, current_step - 5] == False)\n",
    "\n",
    "    interplote_mask_first = (data['agent']['valid_mask'][:, 0] == False) * (data['agent']['position'][:, 0, 0] != 0)\n",
    "    data['agent']['valid_mask'][interplote_mask_first, 0] = True\n",
    "\n",
    "    agent_pos = data['agent']['position'][:, :, :2]\n",
    "    valid_mask = data['agent']['valid_mask']\n",
    "    # 以下标1为起点，长度为6，间隔为5创建滑动窗口\n",
    "    valid_mask_shift = valid_mask.unfold(1, shift + 1, shift)         # [NA, 18, 6]\n",
    "    # 每个滑动窗口的起止都为true时窗口才有效\n",
    "    token_valid_mask = valid_mask_shift[:, :, 0] * valid_mask_shift[:, :, -1]   # [NA, 18]\n",
    "    agent_type = data['agent']['type']\n",
    "    agent_category = data['agent']['category']\n",
    "    agent_heading = data['agent']['heading']\n",
    "    vehicle_mask = agent_type == 0\n",
    "    cyclist_mask = agent_type == 2\n",
    "    ped_mask = agent_type == 1\n",
    "\n",
    "    veh_pos = agent_pos[vehicle_mask, :, :]\n",
    "    veh_valid_mask = valid_mask[vehicle_mask, :]\n",
    "    cyc_pos = agent_pos[cyclist_mask, :, :]\n",
    "    cyc_valid_mask = valid_mask[cyclist_mask, :]\n",
    "    ped_pos = agent_pos[ped_mask, :, :]\n",
    "    ped_valid_mask = valid_mask[ped_mask, :]\n",
    "\n",
    "    veh_token_index, veh_token_contour = match_token(veh_pos, veh_valid_mask, agent_heading[vehicle_mask],\n",
    "                                                            'veh', agent_category[vehicle_mask],\n",
    "                                                            matching_extra_mask[vehicle_mask])\n",
    "    ped_token_index, ped_token_contour = match_token(ped_pos, ped_valid_mask, agent_heading[ped_mask], 'ped',\n",
    "                                                            agent_category[ped_mask], matching_extra_mask[ped_mask])\n",
    "    cyc_token_index, cyc_token_contour = match_token(cyc_pos, cyc_valid_mask, agent_heading[cyclist_mask],\n",
    "                                                            'cyc', agent_category[cyclist_mask],\n",
    "                                                            matching_extra_mask[cyclist_mask])\n",
    "\n",
    "    # token_index: [NA, 18(90/5)] 每个代理在90帧中匹配到的18个token索引\n",
    "    token_index = torch.zeros((agent_pos.shape[0], veh_token_index.shape[1])).to(torch.int64)\n",
    "    token_index[vehicle_mask] = veh_token_index\n",
    "    token_index[ped_mask] = ped_token_index\n",
    "    token_index[cyclist_mask] = cyc_token_index\n",
    "\n",
    "    # token_contour: [NA, 18, 4, 2] 每个代理在90帧中匹配到的18个token对应的矩形信息\n",
    "    token_contour = torch.zeros((agent_pos.shape[0], veh_token_contour.shape[1],\n",
    "                                    veh_token_contour.shape[2], veh_token_contour.shape[3]))\n",
    "    token_contour[vehicle_mask] = veh_token_contour\n",
    "    token_contour[ped_mask] = ped_token_contour\n",
    "    token_contour[cyclist_mask] = cyc_token_contour\n",
    "\n",
    "    # trajectory_token_veh = torch.from_numpy(trajectory_token['veh']).clone().to(torch.float)\n",
    "    # trajectory_token_ped = torch.from_numpy(trajectory_token['ped']).clone().to(torch.float)\n",
    "    # trajectory_token_cyc = torch.from_numpy(trajectory_token['cyc']).clone().to(torch.float)\n",
    "\n",
    "    # agent_token_traj = torch.zeros((agent_pos.shape[0], trajectory_token_veh.shape[0], 4, 2))\n",
    "    # agent_token_traj[vehicle_mask] = trajectory_token_veh\n",
    "    # agent_token_traj[ped_mask] = trajectory_token_ped\n",
    "    # agent_token_traj[cyclist_mask] = trajectory_token_cyc\n",
    "\n",
    "    if not training:\n",
    "        token_valid_mask[matching_extra_mask, 1] = True\n",
    "\n",
    "    data['agent']['token_idx'] = token_index            # [NA, 18]\n",
    "    data['agent']['token_contour'] = token_contour      # [NA, 18, 4, 2]\n",
    "    token_pos = token_contour.mean(dim=2)               \n",
    "    data['agent']['token_pos'] = token_pos              # [NA, 18, 2]\n",
    "    diff_xy = token_contour[:, :, 0, :] - token_contour[:, :, 3, :]\n",
    "    data['agent']['token_heading'] = torch.arctan2(diff_xy[:, :, 1], diff_xy[:, :, 0])  # [NA, 18]\n",
    "    data['agent']['agent_valid_mask'] = token_valid_mask                                # [NA, 18]\n",
    "\n",
    "    vel = torch.cat([token_pos.new_zeros(data['agent']['num_nodes'], 1, 2),\n",
    "                        ((token_pos[:, 1:] - token_pos[:, :-1]) / (0.1 * shift))], dim=1)\n",
    "    vel_valid_mask = torch.cat([torch.zeros(token_valid_mask.shape[0], 1, dtype=torch.bool),\n",
    "                                (token_valid_mask * token_valid_mask.roll(shifts=1, dims=1))[:, 1:]], dim=1)\n",
    "    vel[~vel_valid_mask] = 0\n",
    "    vel[data['agent']['valid_mask'][:, current_step], 1] = data['agent']['velocity'][\n",
    "                                                                data['agent']['valid_mask'][:, current_step],\n",
    "                                                                current_step, :2]\n",
    "\n",
    "    data['agent']['token_velocity'] = vel\n",
    "\n",
    "    return data\n",
    "\n",
    "token_data = tokenize_agent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def wrap_angle(\n",
    "        angle: torch.Tensor,\n",
    "        min_val: float = -math.pi,\n",
    "        max_val: float = math.pi) -> torch.Tensor:\n",
    "    return min_val + (angle + max_val) % (max_val - min_val)\n",
    "\n",
    "def interplating_polyline(polylines, heading, distance=0.5, split_distace=5):\n",
    "    # 多段线切分长度为5米，多段线内部点之间距离为2.5米，即每条多段线由3个点构成\n",
    "    # Calculate the cumulative distance along the path, up-sample the polyline to 0.5 meter\n",
    "    dist_along_path_list = [[0]]\n",
    "    polylines_list = [[polylines[0]]]\n",
    "    for i in range(1, polylines.shape[0]):\n",
    "        euclidean_dist = euclidean(polylines[i, :2], polylines[i - 1, :2])\n",
    "        heading_diff = min(abs(max(heading[i], heading[i - 1]) - min(heading[1], heading[i - 1])),\n",
    "                           abs(max(heading[i], heading[i - 1]) - min(heading[1], heading[i - 1]) + math.pi))\n",
    "        if heading_diff > math.pi / 4 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif heading_diff > math.pi / 8 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif heading_diff > 0.1 and euclidean_dist > 3:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        elif euclidean_dist > 10:\n",
    "            dist_along_path_list.append([0])\n",
    "            polylines_list.append([polylines[i]])\n",
    "        else:\n",
    "            dist_along_path_list[-1].append(dist_along_path_list[-1][-1] + euclidean_dist)\n",
    "            polylines_list[-1].append(polylines[i])\n",
    "    # plt.plot(polylines[:, 0], polylines[:, 1])\n",
    "    # plt.savefig('tmp.jpg')\n",
    "    new_x_list = []\n",
    "    new_y_list = []\n",
    "    multi_polylines_list = []\n",
    "    for idx in range(len(dist_along_path_list)):\n",
    "        if len(dist_along_path_list[idx]) < 2:\n",
    "            continue\n",
    "        dist_along_path = np.array(dist_along_path_list[idx])\n",
    "        polylines_cur = np.array(polylines_list[idx])\n",
    "        # Create interpolation functions for x and y coordinates\n",
    "        fx = interp1d(dist_along_path, polylines_cur[:, 0])\n",
    "        fy = interp1d(dist_along_path, polylines_cur[:, 1])\n",
    "        # fyaw = interp1d(dist_along_path, heading)\n",
    "\n",
    "        # Create an array of distances at which to interpolate\n",
    "        new_dist_along_path = np.arange(0, dist_along_path[-1], distance)\n",
    "        new_dist_along_path = np.concatenate([new_dist_along_path, dist_along_path[[-1]]])\n",
    "        # Use the interpolation functions to generate new x and y coordinates\n",
    "        new_x = fx(new_dist_along_path)\n",
    "        new_y = fy(new_dist_along_path)\n",
    "        # new_yaw = fyaw(new_dist_along_path)\n",
    "        new_x_list.append(new_x)\n",
    "        new_y_list.append(new_y)\n",
    "\n",
    "        # Combine the new x and y coordinates into a single array\n",
    "        new_polylines = np.vstack((new_x, new_y)).T\n",
    "        polyline_size = int(split_distace / distance)\n",
    "        if new_polylines.shape[0] >= (polyline_size + 1):\n",
    "            padding_size = (new_polylines.shape[0] - (polyline_size + 1)) % polyline_size\n",
    "            final_index = (new_polylines.shape[0] - (polyline_size + 1)) // polyline_size + 1\n",
    "        else:\n",
    "            padding_size = new_polylines.shape[0]\n",
    "            final_index = 0\n",
    "        multi_polylines = None\n",
    "        new_polylines = torch.from_numpy(new_polylines)\n",
    "        new_heading = torch.atan2(new_polylines[1:, 1] - new_polylines[:-1, 1],\n",
    "                                  new_polylines[1:, 0] - new_polylines[:-1, 0])\n",
    "        new_heading = torch.cat([new_heading, new_heading[-1:]], -1)[..., None]\n",
    "        new_polylines = torch.cat([new_polylines, new_heading], -1)\n",
    "        if new_polylines.shape[0] >= (polyline_size + 1):\n",
    "            multi_polylines = new_polylines.unfold(dimension=0, size=polyline_size + 1, step=polyline_size)\n",
    "            multi_polylines = multi_polylines.transpose(1, 2)\n",
    "            multi_polylines = multi_polylines[:, ::5, :]\n",
    "        if padding_size >= 3:\n",
    "            last_polyline = new_polylines[final_index * polyline_size:]\n",
    "            last_polyline = last_polyline[torch.linspace(0, last_polyline.shape[0] - 1, steps=3).long()]\n",
    "            if multi_polylines is not None:\n",
    "                multi_polylines = torch.cat([multi_polylines, last_polyline.unsqueeze(0)], dim=0)\n",
    "            else:\n",
    "                multi_polylines = last_polyline.unsqueeze(0)\n",
    "        if multi_polylines is None:\n",
    "            continue\n",
    "        multi_polylines_list.append(multi_polylines)\n",
    "    if len(multi_polylines_list) > 0:\n",
    "        multi_polylines_list = torch.cat(multi_polylines_list, dim=0)\n",
    "    else:\n",
    "        multi_polylines_list = None\n",
    "    return multi_polylines_list\n",
    "\n",
    "def tokenize_map(data):\n",
    "    data['map_polygon']['type'] = data['map_polygon']['type'].to(torch.uint8)\n",
    "    data['map_point']['type'] = data['map_point']['type'].to(torch.uint8)\n",
    "    pt2pl = data[('map_point', 'to', 'map_polygon')]['edge_index']\n",
    "    pt_type = data['map_point']['type'].to(torch.uint8)\n",
    "    pt_side = torch.zeros_like(pt_type)\n",
    "    pt_pos = data['map_point']['position'][:, :2]\n",
    "    data['map_point']['orientation'] = wrap_angle(data['map_point']['orientation'])\n",
    "    pt_heading = data['map_point']['orientation']\n",
    "    split_polyline_type = []\n",
    "    split_polyline_pos = []\n",
    "    split_polyline_theta = []\n",
    "    split_polyline_side = []\n",
    "    pl_idx_list = []\n",
    "    split_polygon_type = []\n",
    "    data['map_point']['type'].unique()\n",
    "\n",
    "    # 对多段线进行便利\n",
    "    for i in sorted(np.unique(pt2pl[1])):\n",
    "        # 每一条多段线对应的点\n",
    "        index = pt2pl[0, pt2pl[1] == i]\n",
    "        polygon_type = data['map_polygon'][\"type\"][i]\n",
    "        cur_side = pt_side[index]\n",
    "        cur_type = pt_type[index]\n",
    "        cur_pos = pt_pos[index]\n",
    "        cur_heading = pt_heading[index]\n",
    "\n",
    "        for side_val in np.unique(cur_side):\n",
    "            for type_val in np.unique(cur_type):\n",
    "                if type_val == 13:\n",
    "                    continue\n",
    "                indices = np.where((cur_side == side_val) & (cur_type == type_val))[0]\n",
    "                if len(indices) <= 2:\n",
    "                    continue\n",
    "                split_polyline = interplating_polyline(cur_pos[indices].numpy(), cur_heading[indices].numpy())\n",
    "                if split_polyline is None:\n",
    "                    continue\n",
    "                new_cur_type = cur_type[indices][0]\n",
    "                new_cur_side = cur_side[indices][0]\n",
    "                map_polygon_type = polygon_type.repeat(split_polyline.shape[0])\n",
    "                new_cur_type = new_cur_type.repeat(split_polyline.shape[0])\n",
    "                new_cur_side = new_cur_side.repeat(split_polyline.shape[0])\n",
    "                cur_pl_idx = torch.Tensor([i])\n",
    "                new_cur_pl_idx = cur_pl_idx.repeat(split_polyline.shape[0])\n",
    "                split_polyline_pos.append(split_polyline[..., :2])\n",
    "                split_polyline_theta.append(split_polyline[..., 2])\n",
    "                split_polyline_type.append(new_cur_type)\n",
    "                split_polyline_side.append(new_cur_side)\n",
    "                pl_idx_list.append(new_cur_pl_idx)\n",
    "                split_polygon_type.append(map_polygon_type)\n",
    "\n",
    "    split_polyline_pos = torch.cat(split_polyline_pos, dim=0)\n",
    "    split_polyline_theta = torch.cat(split_polyline_theta, dim=0)\n",
    "    split_polyline_type = torch.cat(split_polyline_type, dim=0)\n",
    "    split_polyline_side = torch.cat(split_polyline_side, dim=0)\n",
    "    split_polygon_type = torch.cat(split_polygon_type, dim=0)\n",
    "    pl_idx_list = torch.cat(pl_idx_list, dim=0)\n",
    "    vec = split_polyline_pos[:, 1, :] - split_polyline_pos[:, 0, :]\n",
    "    data['map_save'] = {}\n",
    "    data['pt_token'] = {}\n",
    "    data['map_save']['traj_pos'] = split_polyline_pos\n",
    "    data['map_save']['traj_theta'] = split_polyline_theta[:, 0]  # torch.arctan2(vec[:, 1], vec[:, 0])\n",
    "    data['map_save']['pl_idx_list'] = pl_idx_list\n",
    "    data['pt_token']['type'] = split_polyline_type\n",
    "    data['pt_token']['side'] = split_polyline_side\n",
    "    data['pt_token']['pl_type'] = split_polygon_type\n",
    "    data['pt_token']['num_nodes'] = split_polyline_pos.shape[0]\n",
    "    return data\n",
    "\n",
    "token_data = tokenize_map(token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'city' in token_data:\n",
    "    del token_data['city']\n",
    "if 'polygon_is_intersection' in token_data['map_polygon']:\n",
    "    print(\"delete polygon_is_intersection\")\n",
    "    del token_data['map_polygon']['polygon_is_intersection']\n",
    "if 'route_type' in data['map_polygon']:\n",
    "    print(\"delete route_type\")\n",
    "    del token_data['map_polygon']['route_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CustomHeteroDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(CustomHeteroDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        batch_data = HeteroData()\n",
    "\n",
    "        for node_type, node_data in self.data_list[idx].items():\n",
    "            if isinstance(node_type, str):  # 处理节点数据\n",
    "                if isinstance(node_data, dict):\n",
    "                    for attr, value in node_data.items():\n",
    "                        batch_data[node_type][attr] = value\n",
    "                else:\n",
    "                    batch_data[node_type] = [node_data]\n",
    "\n",
    "        for edge_type, edge_data in self.data_list[idx].items():\n",
    "            if isinstance(edge_type, tuple) and len(edge_type) == 3:  # 处理边数据\n",
    "                if isinstance(edge_data, dict):\n",
    "                    for attr, value in edge_data.items():\n",
    "                        batch_data[edge_type][attr] = value\n",
    "                else:\n",
    "                    batch_data[edge_type] = edge_data\n",
    "        return batch_data\n",
    "\n",
    "dataset = CustomHeteroDataset([token_data])\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "batch = next(iter(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_token_map(data):\n",
    "    traj_pos = data['map_save']['traj_pos'].to(torch.float)\n",
    "    traj_theta = data['map_save']['traj_theta'].to(torch.float)\n",
    "    pl_idx_list = data['map_save']['pl_idx_list']\n",
    "    token_sample_pt = map_token['sample_pt'].to(traj_pos.device)\n",
    "    token_src = map_token['traj_src'].to(traj_pos.device)\n",
    "    max_traj_len = map_token['traj_src'].shape[1]\n",
    "    pl_num = traj_pos.shape[0]\n",
    "\n",
    "    # 各地图多段线的起始点坐标xy\n",
    "    pt_token_pos = traj_pos[:, 0, :].clone()\n",
    "    # 各地图多段线的起始位置朝向\n",
    "    pt_token_orientation = traj_theta.clone()\n",
    "    # 将地图多段线由全局坐标系转换为局部坐标系\n",
    "    cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "    rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "    rot_mat[..., 0, 0] = cos\n",
    "    rot_mat[..., 0, 1] = -sin\n",
    "    rot_mat[..., 1, 0] = sin\n",
    "    rot_mat[..., 1, 1] = cos\n",
    "    traj_pos_local = torch.bmm((traj_pos - traj_pos[:, 0:1]), rot_mat.view(-1, 2, 2))\n",
    "    # 将坐标转换后的多段线与地图map_token进行匹配\n",
    "    distance = torch.sum((token_sample_pt[None] - traj_pos_local.unsqueeze(1))**2, dim=(-2, -1))\n",
    "    pt_token_id = torch.argmin(distance, dim=1)\n",
    "\n",
    "    if noise:\n",
    "        topk_indices = torch.argsort(torch.sum((token_sample_pt[None] - traj_pos_local.unsqueeze(1))**2, dim=(-2, -1)), dim=1)[:, :8]\n",
    "        sample_topk = torch.randint(0, topk_indices.shape[-1], size=(topk_indices.shape[0], 1), device=topk_indices.device)\n",
    "        pt_token_id = torch.gather(topk_indices, 1, sample_topk).squeeze(-1)\n",
    "\n",
    "    cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "    rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "    rot_mat[..., 0, 0] = cos\n",
    "    rot_mat[..., 0, 1] = sin\n",
    "    rot_mat[..., 1, 0] = -sin\n",
    "    rot_mat[..., 1, 1] = cos\n",
    "    token_src_world = torch.bmm(token_src[None, ...].repeat(pl_num, 1, 1, 1).reshape(pl_num, -1, 2),\n",
    "                                rot_mat.view(-1, 2, 2)).reshape(pl_num, token_src.shape[0], max_traj_len, 2) + traj_pos[:, None, [0], :]\n",
    "    token_src_world_select = token_src_world.view(-1, 1024, 11, 2)[torch.arange(pt_token_id.view(-1).shape[0]), pt_token_id.view(-1)].view(pl_num, max_traj_len, 2)\n",
    "\n",
    "    pl_idx_full = pl_idx_list.clone()\n",
    "    token2pl = torch.stack([torch.arange(len(pl_idx_list), device=traj_pos.device), pl_idx_full.long()])\n",
    "    count_nums = []\n",
    "    for pl in pl_idx_full.unique():\n",
    "        pt = token2pl[0, token2pl[1, :] == pl]\n",
    "        left_side = (data['pt_token']['side'][pt] == 0).sum()\n",
    "        right_side = (data['pt_token']['side'][pt] == 1).sum()\n",
    "        center_side = (data['pt_token']['side'][pt] == 2).sum()\n",
    "        count_nums.append(torch.Tensor([left_side, right_side, center_side]))\n",
    "    # count_nums: [N_polyline, 3]分别记录每个原始多段线对应的左侧、右侧、中心token有多少\n",
    "    count_nums = torch.stack(count_nums, dim=0)\n",
    "    # 获取每个原始多段线对应的最多token数量\n",
    "    max_token_num = int(count_nums.max().item())\n",
    "    # 构建多段线的轨迹掩码 [N_polyline, 3, max_token_num]\n",
    "    traj_mask = torch.zeros((int(len(pl_idx_full.unique())), 3, max_token_num), dtype=bool)\n",
    "    idx_matrix = torch.arange(traj_mask.size(2)).unsqueeze(0).unsqueeze(0)\n",
    "    idx_matrix = idx_matrix.expand(traj_mask.size(0), traj_mask.size(1), -1)    #[N_polyline, 3, max_token_num]\n",
    "    counts_num_expanded = count_nums.unsqueeze(-1)                              #[N_polyline, 3, 1]\n",
    "    traj_mask[idx_matrix < counts_num_expanded] = True\n",
    "\n",
    "    data['pt_token']['traj_mask'] = traj_mask\n",
    "    data['pt_token']['position'] = torch.cat([pt_token_pos, torch.zeros((data['pt_token']['num_nodes'], 1),\n",
    "                                                                        device=traj_pos.device, dtype=torch.float)], dim=-1)\n",
    "    data['pt_token']['orientation'] = pt_token_orientation\n",
    "    data['pt_token']['height'] = data['pt_token']['position'][:, -1]\n",
    "    data[('pt_token', 'to', 'map_polygon')] = {}\n",
    "    data[('pt_token', 'to', 'map_polygon')]['edge_index'] = token2pl\n",
    "    data['pt_token']['token_idx'] = pt_token_id\n",
    "    return data\n",
    "\n",
    "batch = match_token_map(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pt_pred(data):\n",
    "    # traj_mask: [n_map_poly, 3, max_token_num]\n",
    "    traj_mask = data['pt_token']['traj_mask']\n",
    "    # 从每个原始多段线中随机选取1/3的traj值被掩码掉\n",
    "    raw_pt_index = torch.arange(1, traj_mask.shape[2]).repeat(traj_mask.shape[0], traj_mask.shape[1], 1)\n",
    "    masked_pt_index = raw_pt_index.view(-1)[torch.randperm(raw_pt_index.numel())[:traj_mask.shape[0]*traj_mask.shape[1]*((traj_mask.shape[2]-1)//3)].reshape(traj_mask.shape[0], traj_mask.shape[1], (traj_mask.shape[2]-1)//3)]\n",
    "    masked_pt_index = torch.sort(masked_pt_index, -1)[0]\n",
    "    # 有效掩码\n",
    "    pt_valid_mask = traj_mask.clone()\n",
    "    pt_valid_mask.scatter_(2, masked_pt_index, False)\n",
    "    # 预测掩码\n",
    "    pt_pred_mask = traj_mask.clone()\n",
    "    pt_pred_mask.scatter_(2, masked_pt_index, False)\n",
    "    tmp_mask = pt_pred_mask.clone()\n",
    "    tmp_mask[:, :, :] = True\n",
    "    tmp_mask.scatter_(2, masked_pt_index-1, False)\n",
    "    pt_pred_mask.masked_fill_(tmp_mask, False)\n",
    "    pt_pred_mask = pt_pred_mask * torch.roll(traj_mask, shifts=-1, dims=2)\n",
    "    # 目标掩码\n",
    "    pt_target_mask = torch.roll(pt_pred_mask, shifts=1, dims=2)\n",
    "    # 通过traj_mask将生成的掩码向量从[n_map_poly, 3, max_token_num]转换为[n_polyline]的形式，使其与token信息对应\n",
    "    data['pt_token']['pt_valid_mask'] = pt_valid_mask[traj_mask]\n",
    "    data['pt_token']['pt_pred_mask'] = pt_pred_mask[traj_mask]\n",
    "    data['pt_token']['pt_target_mask'] = pt_target_mask[traj_mask]\n",
    "\n",
    "    return data\n",
    "\n",
    "batch = sample_pt_pred(batch)\n",
    "batch['agent']['av_index'] += batch['agent']['ptr'][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型推理\n",
    "\n",
    "使用处理后的limsim数据进行仿真推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 18:02:48,336-INFO-smart.py-Line:222-Message:==> Loading parameters from checkpoint ../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt to GPU\n",
      "2024-12-02 18:02:48,634-INFO-smart.py-Line:231-Message:The number of disk ckpt keys: 818\n",
      "2024-12-02 18:02:48,713-INFO-smart.py-Line:247-Message:Missing keys: []\n",
      "2024-12-02 18:02:48,713-INFO-smart.py-Line:248-Message:The number of missing keys: 0\n",
      "2024-12-02 18:02:48,714-INFO-smart.py-Line:249-Message:The number of unexpected keys: 0\n",
      "2024-12-02 18:02:48,714-INFO-smart.py-Line:250-Message:==> Done (total keys 818)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "# torch.manual_seed(12)\n",
    "\n",
    "from smart.model import SMART\n",
    "from smart.utils.config import load_config_act\n",
    "from smart.utils.log import Logging\n",
    "\n",
    "config = load_config_act(\"../configs/validation/validation_scalable.yaml\")\n",
    "pretrain_ckpt = \"../ckpt/20241021_1037/epoch=07-step=30440-val_loss=2.52.ckpt\"\n",
    "Predictor = SMART\n",
    "logger = Logging().log(level='DEBUG')\n",
    "model = Predictor(config.Model)\n",
    "model.load_params_from_file(filename=pretrain_ckpt, logger=logger)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pred = model(batch)\n",
    "    pred = model.inference(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import torch\n",
    "\n",
    "def plot_static_map(ax, batch):\n",
    "    # 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "    # 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'\n",
    "    _line_style = [['--', 2, 'yellow'], ['--', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'yellow'], ['--', 2, 'grey'],\n",
    "                ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 3, 'black'], [], [], [':', 2, 'blue'], []]\n",
    "    _center_colors = ['lightcoral', 'lightgreen', 'lightyellow', 'lightgray']\n",
    "\n",
    "    # 准备数据\n",
    "    polylines = []\n",
    "    polyline_type = []\n",
    "    for i in range(batch['map_polygon']['num_nodes']):\n",
    "        point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "        polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "        polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "    # 绘制每条地图线段\n",
    "    for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "        x = data[:, 0].numpy()\n",
    "        y = data[:, 1].numpy()\n",
    "        if (type == 13 or type == 14):\n",
    "            continue\n",
    "        elif (type == 16):\n",
    "            ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=_center_colors[batch['map_polygon']['light_type'][idx]], alpha=0.5)\n",
    "        else:\n",
    "            ax.plot(x, y, marker='', linestyle=_line_style[type][0], linewidth=_line_style[type][1], color=_line_style[type][2], alpha=0.8)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f\"Scene <{batch['scenario_id'][0][0]}>\")\n",
    "\n",
    "def cal_polygon_contour(x, y, theta, width, length):\n",
    "    left_front_x = x + 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_front_y = y + 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_front = np.column_stack((left_front_x, left_front_y))\n",
    "\n",
    "    right_front_x = x + 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_front_y = y + 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_front = np.column_stack((right_front_x, right_front_y))\n",
    "\n",
    "    right_back_x = x - 0.5 * length * np.cos(theta) + 0.5 * width * np.sin(theta)\n",
    "    right_back_y = y - 0.5 * length * np.sin(theta) - 0.5 * width * np.cos(theta)\n",
    "    right_back = np.column_stack((right_back_x, right_back_y))\n",
    "\n",
    "    left_back_x = x - 0.5 * length * np.cos(theta) - 0.5 * width * np.sin(theta)\n",
    "    left_back_y = y - 0.5 * length * np.sin(theta) + 0.5 * width * np.cos(theta)\n",
    "    left_back = np.column_stack((left_back_x, left_back_y))\n",
    "\n",
    "    polygon_contour = np.concatenate(\n",
    "        (left_front[:, None, :], right_front[:, None, :], right_back[:, None, :], left_back[:, None, :]), axis=1)\n",
    "\n",
    "    return polygon_contour\n",
    "\n",
    "fig, ax_map = plt.subplots(figsize=(20, 20))\n",
    "ax_agent = ax_map.twinx()\n",
    "\n",
    "plot_static_map(ax_map, batch)\n",
    "\n",
    "traj = torch.cat([batch['agent']['position'][:, :11, :2], pred['pred_traj']], dim=1)\n",
    "head = torch.cat([batch['agent']['heading'][:, :11], pred['pred_head']], dim=1)\n",
    "\n",
    "N, T, _ = traj.shape\n",
    "agent_traj_all = cal_polygon_contour(\n",
    "    traj.view(-1, 2)[..., 0], \n",
    "    traj.view(-1, 2)[..., 1], \n",
    "    head.view(-1), \n",
    "    batch['agent']['shape'].view(-1, 3)[..., 1], \n",
    "    batch['agent']['shape'].view(-1, 3)[..., 0]\n",
    ").reshape(N, T, 4, 2)\n",
    "\n",
    "def update(frame):\n",
    "    ax_agent.cla()\n",
    "    ax_agent.axis('off')\n",
    "    ax_agent.set_ylim(ax_map.get_ylim())\n",
    "    polygons = []\n",
    "    for agent_idx in range(agent_traj_all.shape[0]):\n",
    "        polygon = patches.Polygon(agent_traj_all[agent_idx, frame], closed=True, fill='blue', edgecolor=None, alpha=0.9)  # fill=None 使其不填充\n",
    "        ax_agent.add_patch(polygon)\n",
    "        polygons.append(polygon)\n",
    "    return polygons\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(T), blit=True)\n",
    "\n",
    "# ani.save(f\"/home/yangyh408/codes/SMART/data/limsim/{batch.scenario_id[0][0]}.gif\", writer=PillowWriter(fps=10))\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 地图信息可视化工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 根据map_polygon和map_point绘制地图\n",
    "\n",
    "可以通过FILTER_TYPE指定突出绘制的地图线型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取当前可视化场景信息\n",
    "print(\"-\" * 100)\n",
    "print(f\"Scenario ID: {batch.scenario_id[0]}\")\n",
    "print(f\"不同多段线类型对应的多段线条数: {torch.bincount(batch['map_polygon']['type'], minlength=4).tolist()}\")\n",
    "# 0:'VEHICLE', 1:'BIKE', 2:'BUS', 3:'PEDESTRIAN'\n",
    "print(f\"不同信控信号对应的多段线条数: {torch.bincount(batch['map_polygon']['light_type'], minlength=4).tolist()}\")\n",
    "# 0:'LANE_STATE_STOP', 1:'LANE_STATE_GO', 2:'LANE_STATE_CAUTION', 3:'LANE_STATE_UNKNOWN'\n",
    "print(f\"不同的地图点类型对应的个数: {torch.bincount(batch['map_point']['type'], minlength=17).tolist()}\")\n",
    "# 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "# 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "\n",
    "# 突出显示的线形\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图和信息区域\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 9])  # 上下两部分，比例为4:1\n",
    "\n",
    "# 绘图区域\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "num_colors = len(colors)\n",
    "\n",
    "# 准备数据\n",
    "polylines = []\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 存储绘制的线段和其对应的数据\n",
    "lines = []\n",
    "line_data = []\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    if len(FILTER_TYPE) == 0 or type in FILTER_TYPE:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[type], picker=5)  # 启用 picker\n",
    "    else:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color='#F0F0F0', alpha=1, picker=5)\n",
    "    lines.append(line)\n",
    "    line_data.append((idx, type, x, y))\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.tab20, norm=mcolors.Normalize(vmin=0, vmax=num_colors - 1))\n",
    "sm.set_array([])  # 必须设置 array 以显示颜色条\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Color Index')\n",
    "cbar.set_ticks(range(num_colors))\n",
    "cbar.set_ticklabels(range(num_colors))\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 信息显示区域\n",
    "info_ax = fig.add_subplot(gs[0])\n",
    "info_ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 初始化显示信息\n",
    "info_text = info_ax.text(0.01, 0.5, \"Selected Line Info: None\", fontsize=12, verticalalignment='center')\n",
    "\n",
    "# 用于跟踪当前高亮的线段\n",
    "highlighted_line = None\n",
    "highlighted_prev_color = None\n",
    "\n",
    "# 鼠标点击事件\n",
    "def on_pick(event):\n",
    "    global highlighted_line\n",
    "    global highlighted_prev_color\n",
    "\n",
    "    # 获取被选中的线段\n",
    "    line = event.artist\n",
    "    idx = lines.index(line)\n",
    "    idx, pl_type, x, y = line_data[idx]\n",
    "\n",
    "    # 如果有高亮的线段，先恢复默认样式\n",
    "    if highlighted_line is not None:\n",
    "        highlighted_line.set_linewidth(2)\n",
    "        highlighted_line.set_color(highlighted_prev_color)\n",
    "    # 更新高亮的线段\n",
    "    highlighted_line = line\n",
    "    highlighted_prev_color = colors[pl_type] if len(FILTER_TYPE) == 0 or pl_type in FILTER_TYPE else '#F0F0F0'\n",
    "    line.set_linewidth(4)\n",
    "    line.set_color('red')\n",
    "\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    \n",
    "    # 更新信息显示区域\n",
    "    info = (f\"Selected Line Index: {idx}\\n\"\n",
    "            f\"Selected Line Type Index: {pl_type}\\n\"\n",
    "            f\"Selected Line Type: {_point_types[pl_type]}\\n\")\n",
    "            # f\"Coordinates: {list(zip(x, y))[:5]}... (truncated)\")\n",
    "    info_text.set_text(info)\n",
    "\n",
    "    # 刷新图像\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# 连接事件\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 绘制信控信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "\n",
    "# 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "# 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图，包含 Axes 对象\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "colors = ['red', 'green', 'yellow', 'lightgray']\n",
    "\n",
    "# 准备数据\n",
    "polylines = []\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[batch['map_polygon']['light_type'][idx]])\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 根据分段采样后的map_save数据绘制地图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "\n",
    "# 示例数据\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图和信息区域\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 9])  # 上下两部分，比例为4:1\n",
    "\n",
    "# 绘图区域\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "num_colors = len(colors)\n",
    "\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 存储绘制的线段和其对应的数据\n",
    "lines = []\n",
    "line_data = []\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, (pl_idx, data) in enumerate(zip(batch['map_save']['pl_idx_list'], batch['map_save']['traj_pos'])):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    type = polyline_type[int(pl_idx)]\n",
    "    if len(FILTER_TYPE) == 0 or type in FILTER_TYPE:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[type], picker=5)  # 启用 picker\n",
    "    else:\n",
    "        line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color='#F0F0F0', alpha=1, picker=5)\n",
    "    lines.append(line)\n",
    "    line_data.append((idx, type, x, y))\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.tab20, norm=mcolors.Normalize(vmin=0, vmax=num_colors - 1))\n",
    "sm.set_array([])  # 必须设置 array 以显示颜色条\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Color Index')\n",
    "cbar.set_ticks(range(num_colors))\n",
    "cbar.set_ticklabels(range(num_colors))\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 信息显示区域\n",
    "info_ax = fig.add_subplot(gs[0])\n",
    "info_ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 初始化显示信息\n",
    "info_text = info_ax.text(0.01, 0.5, \"Selected Line Info: None\", fontsize=12, verticalalignment='center')\n",
    "\n",
    "# 用于跟踪当前高亮的线段\n",
    "highlighted_line = None\n",
    "highlighted_prev_color = None\n",
    "\n",
    "# 鼠标点击事件\n",
    "def on_pick(event):\n",
    "    global highlighted_line\n",
    "    global highlighted_prev_color\n",
    "\n",
    "    # 获取被选中的线段\n",
    "    line = event.artist\n",
    "    idx = lines.index(line)\n",
    "    idx, pl_type, x, y = line_data[idx]\n",
    "\n",
    "    # 如果有高亮的线段，先恢复默认样式\n",
    "    if highlighted_line is not None:\n",
    "        highlighted_line.set_linewidth(2)\n",
    "        highlighted_line.set_color(highlighted_prev_color)\n",
    "    # 更新高亮的线段\n",
    "    highlighted_line = line\n",
    "    highlighted_prev_color = colors[pl_type] if len(FILTER_TYPE) == 0 or pl_type in FILTER_TYPE else '#F0F0F0'\n",
    "    line.set_linewidth(4)\n",
    "    line.set_color('red')\n",
    "\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    \n",
    "    # 更新信息显示区域\n",
    "    info = (f\"Selected Line Index: {idx}\\n\"\n",
    "            f\"Selected Line Head: {batch['map_save']['traj_theta'][idx]: .4f}\\n\"\n",
    "            f\"Selected Line Type Index: {pl_type}\\n\"\n",
    "            f\"Selected Line Type: {_point_types[pl_type]}\\n\")\n",
    "            # f\"Coordinates: {list(zip(x, y))[:5]}... (truncated)\")\n",
    "    info_text.set_text(info)\n",
    "\n",
    "    # 刷新图像\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# 连接事件\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 根据匹配的地图token进行地图可视化还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "\n",
    "# 创建绘图和信息区域\n",
    "fig = plt.figure(figsize=(18, 20))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 9])  # 上下两部分，比例为4:1\n",
    "\n",
    "# 绘图区域\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "num_colors = len(colors)\n",
    "\n",
    "# 准备数据\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "pl_num = batch['pt_token']['position'].shape[0]\n",
    "traj_theta = batch['pt_token']['orientation'].clone()\n",
    "traj_pos = batch['pt_token']['position'].clone()\n",
    "pt_token_id = batch['pt_token']['token_idx'].clone()\n",
    "\n",
    "cos, sin = traj_theta.cos(), traj_theta.sin()\n",
    "rot_mat = traj_theta.new_zeros(pl_num, 2, 2)\n",
    "rot_mat[..., 0, 0] = cos\n",
    "rot_mat[..., 0, 1] = sin\n",
    "rot_mat[..., 1, 0] = -sin\n",
    "rot_mat[..., 1, 1] = cos\n",
    "\n",
    "map_token_traj_path = \"/home/yangyh408/codes/SMART/smart/tokens/map_traj_token5.pkl\"\n",
    "map_token_traj = pickle.load(open(map_token_traj_path, 'rb'))\n",
    "\n",
    "token_src = torch.from_numpy(map_token_traj['traj_src']).to(torch.float)\n",
    "token_src_world = torch.bmm(\n",
    "                        token_src[None, ...].repeat(pl_num, 1, 1, 1).reshape(pl_num, -1, 2),\n",
    "                        rot_mat.view(-1, 2, 2)\n",
    "                    ).reshape(pl_num, token_src.shape[0], -1, 2) + traj_pos[:, None, None, :2]\n",
    "token_src_world_select = token_src_world.view(-1, 1024, 11, 2)[torch.arange(pt_token_id.view(-1).shape[0]), pt_token_id.view(-1)].view(pl_num, -1, 2)\n",
    "\n",
    "# 存储绘制的线段和其对应的数据\n",
    "lines = []\n",
    "line_data = []\n",
    "\n",
    "# 绘制每条线段\n",
    "for idx, data in enumerate(token_src_world_select):\n",
    "    pl_idx = batch[('pt_token', 'to', 'map_polygon')]['edge_index'][1, idx].item()\n",
    "    token_idx = batch['pt_token']['token_idx'][idx].item()\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    type = polyline_type[int(pl_idx)]\n",
    "    line, = ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=colors[type], picker=5)\n",
    "    lines.append(line)\n",
    "    line_data.append((idx, token_idx, type, x, y))\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.tab20, norm=mcolors.Normalize(vmin=0, vmax=num_colors - 1))\n",
    "sm.set_array([])  # 必须设置 array 以显示颜色条\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Color Index')\n",
    "cbar.set_ticks(range(num_colors))\n",
    "cbar.set_ticklabels(range(num_colors))\n",
    "\n",
    "# 设置图例、标题和网格\n",
    "ax.set_xlabel('X-coordinate')\n",
    "ax.set_ylabel('Y-coordinate')\n",
    "ax.set_title('Multiple Line Segments')\n",
    "ax.grid(True)\n",
    "\n",
    "# 信息显示区域\n",
    "info_ax = fig.add_subplot(gs[0])\n",
    "info_ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 初始化显示信息\n",
    "info_text = info_ax.text(0.01, 0.5, \"Selected Line Info: None\", fontsize=12, verticalalignment='center')\n",
    "\n",
    "# 用于跟踪当前高亮的线段\n",
    "highlighted_line = None\n",
    "highlighted_prev_color = None\n",
    "\n",
    "# 鼠标点击事件\n",
    "def on_pick(event):\n",
    "    global highlighted_line\n",
    "    global highlighted_prev_color\n",
    "\n",
    "    # 获取被选中的线段\n",
    "    line = event.artist\n",
    "    idx = lines.index(line)\n",
    "    idx, token_idx, pl_type, x, y = line_data[idx]\n",
    "\n",
    "    # 如果有高亮的线段，先恢复默认样式\n",
    "    if highlighted_line is not None:\n",
    "        highlighted_line.set_linewidth(2)\n",
    "        highlighted_line.set_color(highlighted_prev_color)\n",
    "    # 更新高亮的线段\n",
    "    highlighted_line = line\n",
    "    highlighted_prev_color = colors[pl_type] if len(FILTER_TYPE) == 0 or pl_type in FILTER_TYPE else '#F0F0F0'\n",
    "    line.set_linewidth(4)\n",
    "    line.set_color('red')\n",
    "\n",
    "    _point_types = ['DASH_SOLID_YELLOW', 'DASH_SOLID_WHITE', 'DASHED_WHITE', 'DASHED_YELLOW',\n",
    "                'DOUBLE_SOLID_YELLOW', 'DOUBLE_SOLID_WHITE', 'DOUBLE_DASH_YELLOW', 'DOUBLE_DASH_WHITE',\n",
    "                'SOLID_YELLOW', 'SOLID_WHITE', 'SOLID_DASH_WHITE', 'SOLID_DASH_YELLOW', 'EDGE',\n",
    "                'NONE', 'UNKNOWN', 'CROSSWALK', 'CENTERLINE']\n",
    "    \n",
    "    # 更新信息显示区域\n",
    "    info = (f\"Selected Line Index: {idx}\\n\"\n",
    "            f\"Selected Token Index: {token_idx}\\n\"\n",
    "            f\"Selected Line Type Index: {pl_type}\\n\"\n",
    "            f\"Selected Line Type: {_point_types[pl_type]}\\n\")\n",
    "            # f\"Coordinates: {list(zip(x, y))[:5]}... (truncated)\")\n",
    "    info_text.set_text(info)\n",
    "\n",
    "    # 刷新图像\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# 连接事件\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 batch轨迹信息可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "\n",
    "# 0:'DASH_SOLID_YELLOW', 1:'DASH_SOLID_WHITE', 2:'DASHED_WHITE', 3:'DASHED_YELLOW', 4:'DOUBLE_SOLID_YELLOW', 5:'DOUBLE_SOLID_WHITE', 6:'DOUBLE_DASH_YELLOW', 7:'DOUBLE_DASH_WHITE',\n",
    "# 8:'SOLID_YELLOW', 9:'SOLID_WHITE', 10:'SOLID_DASH_WHITE', 11:'SOLID_DASH_YELLOW', 12:'EDGE', 13:'NONE', 14:'UNKNOWN', 15:'CROSSWALK', 16:'CENTERLINE'\n",
    "FILTER_TYPE = [16]\n",
    "FILTER_TYPE = []\n",
    "\n",
    "# 创建绘图，包含 Axes 对象\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "_line_style = [['--', 2, 'yellow'], ['--', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'yellow'], ['--', 2, 'grey'],\n",
    "                ['-', 2, 'yellow'], ['-', 2, 'grey'], ['--', 2, 'grey'], ['--', 2, 'yellow'], ['-', 3, 'black'], [], [], [':', 2, 'blue'], []]\n",
    "_center_colors = ['lightcoral', 'lightgreen', 'lightyellow', 'lightgray']\n",
    "\n",
    "# 准备数据\n",
    "polylines = []\n",
    "polyline_type = []\n",
    "for i in range(batch['map_polygon']['num_nodes']):\n",
    "    point_idx = batch[('map_point', 'to', 'map_polygon')]['edge_index'][0, batch[('map_point', 'to', 'map_polygon')]['edge_index'][1] == i]\n",
    "    polylines.append(torch.gather(batch['map_point']['position'][:, :2], dim=0, index=point_idx[..., None].repeat(1, 2)))\n",
    "    polyline_type.append(batch['map_point']['type'][point_idx[0]])\n",
    "\n",
    "# 绘制每条地图线段\n",
    "for idx, (type, data) in enumerate(zip(polyline_type, polylines)):\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    if (type == 13 or type == 14):\n",
    "        continue\n",
    "    elif (type == 16):\n",
    "        ax.plot(x, y, marker='', linestyle='-', linewidth=2, color=_center_colors[batch['map_polygon']['light_type'][idx]], alpha=0.5)\n",
    "    else:\n",
    "        ax.plot(x, y, marker='', linestyle=_line_style[type][0], linewidth=_line_style[type][1], color=_line_style[type][2], alpha=0.8)\n",
    "\n",
    "history_step = 11\n",
    "alphas = np.linspace(0.1, 1.0, history_step)\n",
    "for agent_info in batch['agent']['position'][:, :history_step, :2]:\n",
    "    x = agent_info[:, 0].numpy()\n",
    "    y = agent_info[:, 1].numpy()\n",
    "    plt.scatter(x, y, alpha=alphas)\n",
    "\n",
    "# 设置轴比例相同\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-ntp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
